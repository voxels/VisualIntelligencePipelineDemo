========================================
FILE: Displaying static and interactive snippets | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Essentials
App Intents updates
Making actions and content discoverable …
Creating your first app intent
Adopting App Intents to support system e…
Accelerating app interactions with App Int…
Siri and Apple Intelligence
Integrating actions with Siri and Apple Int…
Making onscreen content available to Siri …
App intent domains
Making your appʼs functionality available t…
Visual intelligence
Integrating your app with visual intelligence
Visual Intelligence
IntentValueQueryr P
Interactive Snippets
Displaying static and interactive snippets
SnippetIntentr P
Other system experiences
Filter
App Intents / Displaying static and interactive snippets
Article
Displaying static and interactive snippets
Enable people to view the outcome of an app intent and immediately perform follow-up
actions.
/
Overview
Using App Intents, you can integrate your app into the system, allowing people to perform actions from
system experiences such as Spotlight or Control Center, the Action button, or Siri. To inform people about
the outcome of an action you make available as an app intent, the intent can return a static snippet.
Many of the actions you make available to the system as app intents are simple, and happen quickly. App
intents can return an interactive snippet that allows people to perform an action from a snippet instead of
viewing static information. Instead of taking a person out of their current context by launching your app
from the app intent if it needs further action from the person, you can change the app intent to display an
interactive snippet that shows the intentʼs result, a way to confirm its action, or a button for a follow-up
action.
For example, the Adopting App Intents to support system experiences sample app offers an app intent to
view details about the landmarks nearby. People might use it to create shortcuts and perform its action
from Spotlight or the Action button. When the app intent finds information about a nearby landmark, it
displays an interactive snippet with the most important information, a button to add it to a list favorites, and
a button to search for available tickets if the landmark requires people to pay an entrance fee.
Note
App intents that people perform from a control in Control Center canʼt display snippets.
Show a static snippet
If your app intent doesnʼt require a follow-up action, return a static snippet that enables someone to view
the outcome of the app intent. To show a static snippet as a result from an app intent, return a view from
your app intentʼs perform() method:
func perform() async throws -> some IntentResult {
// ...
return .result(view: Text("Some example text.").font(.title))
}
Return an interactive snippet
To display an interactive snippet as a result of an app intent, create an app intent for your action - or use an
existing app intent. For example, the Adopting App Intents to support system experiences sample app
provides landmark information might already have an app intent that finds a nearby landmark and returns
information about it:
struct ClosestLandmarkIntent: AppIntent {
static let title: LocalizedStringResource = "Find Closest Landmark"
func perform() async throws -> some ReturnsValue<LandmarkEntity> & ShowsSnippetIntent {
let landmark = await self.findClosestLandmark()
return .result(
value: landmarkEntity // Return information about the landmark.
)
}
}
To display a snippet instead of just returning the app entity, change your intentʼs perform() function to
return a SnippetIntent in addition to the existing return value by adding & ShowsSnippetIntent.
When you return a ShowsSnippetIntent result from the intent, you let the system know that the action
displays an interactive snippet. In the Adopting App Intents to support system experiences example app,
the previous exampleʼs updated perform() method might look like this:
struct ClosestLandmarkIntent: AppIntent {
static let title: LocalizedStringResource = "Find Closest Landmark"
@Dependency var modelData: ModelData
func perform() async throws -> some ReturnsValue<LandmarkEntity> & ShowsSnippetIntent {
let landmark = await self.findClosestLandmark()
return .result(
value: landmark,
snippetIntent: LandmarkSnippetIntent(landmark: landmark)
)
}
}
In the example, the intent returns a landmark entity by declaring -> some ReturnsValue<Landmark
Entity> and, additionally, returns a LandmarkSnippetIntent. This intent, an implementation of
SnippetIntent , handles the snippetʼs layout and interactive components.
When you adopt interactive snippets, you might be able to reuse existing intents and add logic to display a
snippet. Like the example above, you can return several results from an intent. By keeping an existing result
type and additionally returning a snippet intent, you avoid breaking peopleʼs custom shortcuts that use the
previous version of your intent.
Create the interactive snippet
As described in the previous section, the intent that performs your appʼs action can return a Snippet
Intent. The snippet intent constructs your snippetʼs layout and returns it to the system, which then
displays the interactive snippet. To return the views for your interactive snippet:
L. M. Create an app intent that conforms to SnippetIntent.
Make sure the intentʼs perform() method returns a ShowsSnippetView.
The following code continues the previous example and shows how the AppIntentsTravelTracking
app might return a LandmarkView from the SnippetIntent:
import AppIntents
import SwiftUI
struct LandmarkSnippetIntent: SnippetIntent {
static let title: LocalizedStringResource = "Landmark Snippet"
@Parameter var landmark: LandmarkEntity
@Dependency var modelData: ModelData
func perform() async throws -> some IntentResult & ShowsSnippetView {
let isFavorite = await modelData.isFavorite(landmark)
return .result(
view: LandmarkView(landmark: landmark, isFavorite: isFavorite)
)
}
}
extension LandmarkSnippetIntent {
init(landmark: LandmarkEntity) {
self.landmark = landmark
}
}
Note the isFavorite parameter in the viewʼs initializer. The LandmarkView indicates whether a
landmark is marked as a favorite already, and includes a button to add or remove it from favorites. The
LandMarkView also includes a button to start a search for tickets to visit the landmark.
Note
Snippets are great candidates to reuse views you use in your widgets, and, like widgets, you must
initialize the snippetʼs Button or Toggle with an AppIntent that performs the underlying action.
For more information, refer to Adding interactivity to widgets and Live Activities.
Review the lifecycle of snippet intents
A snippet remains visible until a person dismisses it, and, similar to SwiftUI views, the system and a
personʼs actions might result in your SnippetIntent being created and performed multiple times during
its lifecycle.
For example, the landmarks sample code projectʼs snippet includes a Favorites button to add or remove a
nearby landmark from a list of favorites. When a person taps the Favorites button, the system performs the
FavoriteLandmarkIntent to make the change. It discards the snippetʼs old SwiftUI views, and
performs the SnippetIntent again to provide a new version of the snippet to show that the person
added or removed the landmark from the list of favorites.
Note
Treat intents that conform to SnippetIntent like any other intent; they arenʼt limited to displaying a
snippet. People can use them in their custom shortcuts, and you can reuse them. For example, the
sample app might use FavoriteLandmarkIntent in an App Shortcut or interactive widget.
In the snippet intentʼs perform() function, retrieve app state - for example, whether a current landmark is
a favorite - and return an updated snippet as shown in the LandmarkSnippetIntent example code
above.
Because the system creates and performs your SnippetIntent repeatedly, make sure calling its
perform() method doesnʼt produce side effects:
If you pass data between intents, pass a minimum amount of immutable data.
Avoiding long-running tasks to ensure the snippet appears responsive.
Fetch dynamic values from a shared object instead of passing them around as parameters between
intents; for example, the LandmarkSnippetIntent above uses an AppDependency for its model
Data.
Note
As long as a snippet is visible, the system keeps your app active in the background, retaining all
information in memory. As a result, you donʼt have to persist or refresh data while your snippet is
visible.
Create a sequence of snippets and request confirmation
With interactive snippets, you can create quick, fast-flowing interactions, allowing people to view content
and perform a series of actions without leaving their current context. For example, the landmark example
might display a sequence of three snippets:
L. When a person performs the “Find Closest” App Shortcut, the landmarks snippet described above
appears. It includes a button to search for tickets for the nearby landmark.
M. S. When a person taps the button to search for tickets, a second snippet appears, requesting confirmation
of the total number of tickets. When theyʼve adjusted the number of tickets and confirmed the number
of tickets, the search starts.
When the search finishes, a third snippet appears to display the total amount for the number of tickets
and a buy button.
To create this sequence of snippets, the Adopting App Intents to support system experiences app uses a
combination of regular app intents, a request for confirmation, and snippet intents.
First, the app defines the FindTicketsIntent, a regular app intent to perform the search. In its
perform() method, the requestConfirmation(conditions:actionName:dialog:showDialog
AsPrompt:snippetIntent:) API displays the interactive snippet for people to enter the tickets, using
the TicketRequestSnippetIntent.
import AppIntents
struct FindTicketsIntent: AppIntent {
// ...
func perform() async throws -> some IntentResult & ShowsSnippetIntent {
let searchRequest = await searchEngine.createRequest(landmarkEntity: landmark)
// Present a snippet that allows people to change
// the number of tickets.
try await requestConfirmation(
actionName: .search,
snippetIntent: TicketRequestSnippetIntent(searchRequest: searchRequest)
)
// ...
}
}
// ...
When the person has entered the number of tickets in the snippet that TicketRequestSnippetIntent
presents, they confirm the number of tickets and the search starts. The search results appear in a third
snippet that the TicketResultSnippetIntent presents:
// ...
func perform() async throws -> some IntentResult & ShowsSnippetIntent {
let searchRequest = await searchEngine.createRequest(landmarkEntity: landmark)
// Present a snippet that allows people to change
// the number of tickets.
try await requestConfirmation(
actionName: .search,
snippetIntent: TicketRequestSnippetIntent(searchRequest: searchRequest)
)
// If the person has confirmed the action, perform the ticket search.
try await searchEngine.performRequest(request: searchRequest)
// Show the result of the ticket search.
return .result(
snippetIntent: TicketResultSnippetIntent(
searchRequest: searchRequest
)
)
}
// ...
By displaying the snippet using the requestConfirmation() API, the snippet includes the option to
cancel the action. If the person doesnʼt confirm the number of tickets, the app intent doesnʼt continue its
perform() function, perform the search, or display another snippet.
Reload a snippet to display updated data
In the above example, three snippets appear in a sequence, each snippet replacing the previous snippet. If
a snippet remains onscreen for some time; for example, if you perform a search like the in the example;
reload the snippet to let people know that the search is ongoing. Similarly, reload the snippet if its
underlying data changes.
To reload a snippet, use the reload() function defined by SnippetIntent . The following example adds
it to the trailing closure of the search method:
// ...
func perform() async throws -> some IntentResult & ShowsSnippetIntent {
// ...
// If the person has confirmed the action, perform the ticket search.
try await searchEngine.performRequest(request: searchRequest) {
// Creates and reloads the TicketResultSnippetIntent.
TicketResultSnippetIntent.reload()
}
// Show the result of the ticket search.
return .result(
snippetIntent: TicketResultSnippetIntent(
searchRequest: searchRequest
)
)
}
// ...
Note
Calling reload() displays a snippet if itʼs not visible and dismisses any other visible snippet. If the
snippet is already visible, it reloads the snippet to display updated data.
See Also
Interactive Snippets
protocol SnippetIntent
An app intent that presents an interactive snippet onscreen.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Integrating your app with visual intelligence | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
Visual Intelligence
Essentials
Integrating your app with visual intelligence
Adopting App Intents to support system ex…
S
SemanticContentDescriptor
App intents essentials
Making actions and content discoverable a…
Creating your first app intent
Visual Intelligence / Integrating your app with visual intelligence
Article
Integrating your app with visual intelligence
Enable people to find app content that matches their surroundings or objects onscreen
with visual intelligence.
Filter
/
Overview
With visual intelligence, people can visually search for information and content that matches their
surroundings, or an onscreen object. Integrating your app with visual intelligence allows people to view
your matching content quickly and launch your app for more detailed information or additional search
results, giving it additional visibility.
Explore the role of the App Intents framework
To integrate your app with visual intelligence, the Visual Intelligence framework provides information about
objects it detects in the visual intelligence camera or a screenshot. To exchange information with your app,
the system uses the App Intents framework and its concepts of app intents and app entities.
When a person performs visual search on the visual intelligence camera or a screenshot, the system
forwards the information captured to an App Intents query you implement. In your query code, search your
appʼs content for matching items, and return them to visual intelligence as app entities. Visual intelligence
then uses the app entities to display your content in the search results view, right where a person needs it.
To learn more about a displayed item, someone can tap it to open the item in your app and view information
and functionality. For example, an app that allows people to view information about landmarks might show
detailed information like hours, a map, or community reviews for the item a person taps in visual search.
Provide a display representation
Visual Intelligence uses the DisplayRepresentation of your AppEntity to organize and present your
content in the visual intelligence search experience. Make sure to provide localized, concise, and high-
quality display representations that consist of a title, subtitle, and an image. The following code from the
Adopting App Intents to support system experiences sample code project shows the display representation
of an AppEntity for a landmark. It uses strings from the model object for simplicity. In your code, make
sure to provide a localized display representation.
struct LandmarkEntity: IndexedEntity {
static var typeDisplayRepresentation: TypeDisplayRepresentation {
return TypeDisplayRepresentation(
name: LocalizedStringResource("Landmark", table: "AppIntents", comment: "The type name for t
numericFormat: "\(placeholder: .int) landmarks"
)
}
var displayRepresentation: DisplayRepresentation {
DisplayRepresentation(
title: "\(name)"
,
subtitle: "\(continent)"
,
image: .init(data: try! self.thumbnailRepresentationData)
)
}
// ...
}
For additional information about display representations, refer to Integrating custom data types into your
intents.
Provide search results
To integrate your app with visual search, provide visual intelligence with content that matches a personʼs
surroundings or onscreen object, as described in the steps below and illustrated in the following image:
H. In your Xcode project, adopt the IntentValueQuery protocol and implement its values(for:)
requirement.
J. Change the values(for:) function to receive a SemanticContentDescriptor as its input. The
SemanticContentDescriptor makes visual intelligence information available to your app.
L. Use the descriptorʼs labels to access a list of labels that visual intelligence creates or the pixel
Buffer of the camera capture.
N. Search your appʼs content using the labels and perform an image search with an image you create from
the pixelBuffer.
P. Describe your search results as AppEntity objects and return them as the result of the query.
Note
Labels are general, high-level terms in the en_US locale and might change over time. Visual
Intelligence doesnʼt translate them or include synonyms. For example, SemanticContent
Descriptor might provide the labels tower or building for a well-known building. It wonʼt provide
the buildingʼs actual name as a label.
The following example code from the Adopting App Intents to support system experiences sample code
project demonstrates how an app that enables people to view information about points of interest and
landmarks might access the pixelBuffer for its search:
struct LandmarkIntentValueQuery: IntentValueQuery {
@Dependency var modelData: ModelData
func values(for input: SemanticContentDescriptor) async throws -> [VisualSearchResult] {
guard let pixelBuffer: CVReadOnlyPixelBuffer = input.pixelBuffer else {
return []
}
let landmarks = try await modelData.search(matching: pixelBuffer)
return landmarks
}
}
The search(matching:) function asynchronously returns a list of app entities that represent landmarks.
Returning results quickly makes for a good search experience, so make sure to limit the list of returned
items, if needed. If your app finds a large number of matches — for example, several hundred items — you
might return the first hundred results, and give people the opportunity to view the full list in your app as
described in Link to additional results in your app.
The process for matching the provided pixel buffer to app entities depends on your app. A common case is
to convert the pixel buffer into an image, then use the image in an image search. The following code
snippet shows how you might implement this conversion:
private func createImage(
_ pixelBuffer: CVReadOnlyPixelBuffer) -> CGImage? {
let context = CIContext()
let image = CIImage(cvPixelBuffer: pixelBuffer)
return context.createCGImage(image, from: image.extent)
}
Open an item in your app
To allow someone to open your app and view additional information or access additional actions for a visual
search, create an OpenIntent. In the intentʼs perform() method, open your app to match the app entity
that visual intelligence passes to the method, as illustrated in the image below.
Continuing the example that shows information about points of interest or landmarks, the OpenIntent
might look like this:
struct OpenLandmarkIntent: OpenIntent {
static let title: LocalizedStringResource = "Open Landmark"
@Parameter(title: "Landmark", requestValueDialog: "Which landmark?")
var target: LandmarkEntity
}
Note
If your query returns more than one app entity type using @UnionValue, create an OpenIntent for
each app entity type thatʼs part of the union value.
Adopting the OpenIntent protocol isnʼt specific to integrating your app with visual intelligence. Adopting
App Intents, including one or more OpenIntent implementations, is a best practice for modern apps that
offer additional integration with system experiences. If youʼve already adopted App Intents, you might be
able to reuse existing code to open an item in your app with an OpenIntent.
For more information about adopting App Intents in your app, refer to App Intents and Making actions and
content discoverable and widely available.
Return different values in one query
Your app canʼt contain more than one IntentValueQuery that takes a SemanticContent
Descriptor. To return more than one AppEntity type from a single intent value query, use the Union
Value() Swift macro to return multiple app entity types. The following example uses a union value for its
result — indicated by the @UnionValue annotation — to return a list of individual landmarks and
collections of landmarks:
@UnionValue
enum VisualSearchResult {
case landmark(LandmarkEntity)
case collection(CollectionEntity)
}
struct LandmarkIntentValueQuery: IntentValueQuery {
@Dependency var modelData: ModelData
func values(for input: SemanticContentDescriptor) async throws -> [VisualSearchResult] {
// ...
// Returned search results are either landmarks or a collection.
let landmarks = try await modelData.search(matching: pixelBuffer)
return landmarks
}
}
Link to additional results in your app
Returning visual search results quickly and limiting the number of items ensures a quick and enjoyable
experience for people using your app. However, your app might offer a lot — possibly hundreds — of
results, or browsing long lists of items might be part of your appʼs core experience. If you need to provide
many results, display a limited amount and allow people to open your app from the “More results” button to
view more visual search results.
First, create a new app intent that conforms to the semanticContentSearch schema. With App Intents
domains and schemas, you can quickly create app intents that follow a predefined form to enable specific
functionality, such as opening a content search experience or list of results.
Tip
Type visualintelligence_, choose the suggested semantic content search schema, and let
Xcode code completion create the conforming app intent for you.
In the semantic content search intentʼs perform() method, navigate to your appʼs search experience and
pass information that the SemanticContentDescriptor object provides to perform a search and show
the full list of results.
See Also
Essentials
Adopting App Intents to support system experiences
Create app intents and entities to incorporate system experiences such as Spotlight, visual
intelligence, and Shortcuts.
struct SemanticContentDescriptor
A type that represents a scene that visual intelligence captures, like a screenshot, photo, or photo and
video stream.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Making actions and content discoverable and widely available | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Essentials
App Intents updates
Making actions and content discoverabl…
Creating your first app intent
Adopting App Intents to support system e…
Accelerating app interactions with App Int…
Siri and Apple Intelligence
Integrating actions with Siri and Apple Int…
Making onscreen content available to Siri …
App intent domains
Making your appʼs functionality available t…
Visual intelligence
Integrating your app with visual intelligence
Visual Intelligence
IntentValueQueryr P
Interactive Snippets
Displaying static and interactive snippets
SnippetIntentr P
Other system experiences
Filter
App Intents / Making actions and content discoverable and widely available
Article
Making actions and content discoverable and
widely available
Adopt App Intents to make your app discoverable with Spotlight, controls, widgets, and
the Action button.
/
Overview
The App Intents framework offers functionality to express your appʼs actions and data in a way that enables
deep integration with system capabilities Apple Intelligence provides and system experiences like
Spotlight. Use App Intents to enable people to view your appʼs content and to use its actions when and
where they need them — whether theyʼre using your app or are elsewhere in the system.
The App Intents API is a fundamental framework that facilitates deep integration with system experiences
across platforms and devices. You use the framework to express data and actions once to build a reusable
foundation for many experiences and features. For example, use App Intents to integrate your app with Siri
and Apple Intelligence, then reuse the code to create controls and interactive widgets in combination with
WidgetKit.
Note
Siriʼs personal context understanding, onscreen awareness, and in-app actions are in development and
will be available with a future software update.
Review experiences that App Intents enables directly
When you use the App Intents framework to express your appʼs actions and data, you integrate your app
with system experiences that offer broad visibility for your app and content and make its functionality
available outside of the app itself; for example:
People will use Siri to perform app actions.
People find App Shortcuts you create in the Shortcuts app and initiate them throughout the system,
across platforms and devices with Siri, Spotlight, the Action button, Apple Pencil Pro, and more.
Using the Shortcuts app, people create custom shortcuts with your appʼs functionality and entirely new
workflows across apps.
People reduce distractions with Focus, and you use the App Intents framework to respond to Focus
changes.
On supported devices, the App Intents framework will provide integration with Apple Intelligence, a
personal intelligence system that deeply integrates powerful generative models into the core of iPhone,
iPad, and Mac. Siri will draw on the capabilities of Apple Intelligence to deliver assistance thatʼs natural,
contextually relevant, and personal for everyone, including in the apps they use every day. The App Intents
framework will enable you to express your appʼs capabilities and content, giving the system access to this
context and integrating your app with Siri and Apple Intelligence, and unlocking new ways for people to
interact with it from anywhere on their device. For more information, refer to Integrating actions with Siri
and Apple Intelligence and Making onscreen content available to Siri and Apple Intelligence.
Understand experiences that use App Intents API
Across devices, your appʼs content and actions appear in additional system experiences you create with a
combination of the App Intents framework and other frameworks. As a result, adopting App Intents not only
helps you adopt features the framework enables directly, it allows you to easily support additional system
experiences that increase your appʼs reach and allow people to personalize how they use your app. Use the
App Intents framework to describe actions and content together with:
WidgetKit to offer interactive and configurable widgets, watch complications, and controls
ActivityKit to offer interactive Live Activities
Core Spotlight to enable people to find your content using semantic search in Spotlight
Plan App Intents framework adoption
If youʼre new to the App Intents framework, first evaluate your appʼs functionality and content. The
framework is a fundamental building block for apps, and enables a broad range of user experiences, so itʼs
important to design a new app with App Intents functionality in mind. Similarly, consider a measured,
thoughtful approach when adopting App Intents in your existing app.
To get started:
O. Understand the role of the App Intents framework and the experiences it enables.
P. Review key framework concepts and create a first implementation that launches your app with an App
Intent and add an App Shortcut. For more information, see Creating your first app intent and App
Shortcuts.
R. Express additional actions and content using the App Intents framework.
T. Integrate actions and content with Siri and Apple Intelligence. For more information, see App intent
domains and Integrating actions with Siri and Apple Intelligence.
U. Depending on your appʼs functionality, add support for additional system experiences and interactions
that fit your appʼs functionality. For example, respond to Focus changes as described in Focus or add
support for the Action button and squeeze gestures on Apple Pencil Pro, as described in Responding to
the Action button on Apple Watch Ultra.
Expand existing App Intents usage
If youʼre currently using the App Intents framework in your app, you might limit app intents to selected
actions and content. The App Intents framework will provide integration with Siri and Apple Intelligence for
every action of your app and its content. Review your appʼs actions and content, and consider expressing
actions and content with App Intents.
Understand the impact of removing app intents and shortcuts
People use app intents to automate workflows with custom shortcuts and App Shortcuts. As a result,
removing AppIntent code or an App Shortcut from your app can break peopleʼs workflows and confuse
or frustrate them because previously available functionality might stop working. Keep this in mind when
you adopt the App Intents framework and consider a deprecation strategy for your AppIntent code.
When you plan to remove an AppIntent, give people notice about your intention to remove the app intent.
Publish a release where you change an existing AppIntent to DeprecatedAppIntent and offer people
a suggested replacement. After giving people enough time to update their custom shortcuts and move to
new App Shortcuts, remove the DeprecatedAppIntent from your app.
Know when to migrate to the App Intents framework
For new functionality, use the App Intents framework to integrate your app with system experiences like
widgets, controls, and Live Activities. Siri and Apple Intelligence automatically will leverage SiriKit intents.
For existing functionality keep existing SiriKit implementations and take a measured approach to replacing
SiriKit code with App Intents. If you remove code that uses SiriKit, give people advance notice about
changes to avoid breaking their existing custom shortcuts and make sure to provide the same or
comparable functionality that uses App Intents.
For more information about migrating your SiriKit code to App Intents, see Soup Chef with App Intents:
Migrating custom intents.
See Also
Essentials
App Intents updates
Learn about important changes in App Intents.
Creating your first app intent
Create your first app intent that makes your app available in system experiences like Spotlight or the
Shortcuts app.
Adopting App Intents to support system experiences
Create app intents and entities to incorporate system experiences such as Spotlight, visual
intelligence, and Shortcuts.
Accelerating app interactions with App Intents
Enable people to use your appʼs features quickly through Siri, Spotlight, and Shortcuts.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Making your app’s functionality available to Siri | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Essentials
App Intents updates
Making actions and content discoverable …
Creating your first app intent
Adopting App Intents to support system e…
Accelerating app interactions with App Int…
Siri and Apple Intelligence
Integrating actions with Siri and Apple Int…
Making onscreen content available to Siri …
App intent domains
Making your appʼs functionality availabl…
Visual intelligence
Integrating your app with visual intelligence
Visual Intelligence
IntentValueQueryr P
Interactive Snippets
Displaying static and interactive snippets
SnippetIntentr P
Other system experiences
Filter
App Intents / Making your appʼs functionality available to Siri
Sample Code
Making your appʼs functionality available to
Siri
Add app intent schemas to your app so Siri can complete requests, and integrate your
app with Apple Intelligence, Spotlight, and other system experiences.
Download
iOS 26.0+ iPadOS 26.0+ macOS 26.0+ Xcode 26.0+
/
Overview
Using this sample app, people can keep track of photos and videos they capture with their device and can
use Siri to access app functionality. To make its main functionality available to Siri, the app uses the App
Intents framework.
Related sessions from WWDC24
Session 10133: Bring your app to Siri
Make app functionality available to Siri
This sample uses App intent domains to make the AppEnum, AppEntity, and AppIntent
implementations available to Siri as shown in the following example:
@AppEnum(schema: .photos.assetType)
enum AssetType: String, AppEnum {
case photo
case video
static let caseDisplayRepresentations: [AssetType : DisplayRepresentation] .photo: "Photo",
.video: "Video"
= [
]
}
Make data available in Spotlight
People can use Spotlight to search for data the sample contains. To enable this functionality, the sample
defines an app entity that conforms to IndexedEntity:
@AppEntity(schema: .photos.asset)
struct AssetEntity: IndexedEntity {
// MARK: Static
static let defaultQuery = AssetQuery()
// MARK: Properties
let id: String
let asset: Asset
@Property(title: "Title")
var title: String?
var creationDate: Date?
var location: CLPlacemark?
var assetType: AssetType?
var isFavorite: Bool
var isHidden: Bool
var hasSuggestedEdits: Bool
var displayRepresentation: DisplayRepresentation {
DisplayRepresentation(
title: title.map { "\($0)" } ?? "Unknown",
subtitle: assetType?.localizedStringResource ?? "Photo"
)
}
}
Make app entities shareable
By adopting the Transferable protocol, this sample makes the data it describes as app entities more
shareable and allows other apps to understand its data formats. For example, the sampleʼs AssetEntity
implements Transferable to make it easy to share a photo as a PNG image with Siri or the share sheet:
extension AssetEntity: Transferable {
struct AssetQuery: EntityQuery {
@Dependency
var library: MediaLibrary
@MainActor
func entities(for identifiers: [AssetEntity.ID]) async throws -> [AssetEntity] {
library.assets(for: identifiers).map(\.entity)
}
@MainActor
func suggestedEntities() async throws -> [AssetEntity] {
// Suggest the first three assets in the photo library.
library.assets.prefix(3).map(\.entity)
}
}
static var transferRepresentation: some TransferRepresentation {
DataRepresentation(exportedContentType: .png) { entity in
try await entity.asset.pngData()
}
}
}
Make onscreen content available to Siri and Apple Intelligence
When the user asks a question about onscreen content or wants to perform an action on it, Siri and Apple
Intelligence can retrieve the content to respond to the question and perform the action. If the user explicitly
requests it, Siri and Apple Intelligence can send content to supported third-party services. For example,
someone could view a photo and use Siri to describe things a person can do with an identified object in the
photo by saying or typing a phrase like “Hey Siri, what can I do with the object in this photo?” To integrate
onscreen content with current and upcoming personal intelligence features of Siri and Apple Intelligence,
the sampleʼs AssetEntity conforms to the Transferable protocol and the .photos.asset schema.
When a person views a photo, the app associates the asset entity with an NSUserActivity to make the
photo available to Siri and Apple Intelligence:
var body: some View {
// ...
MediaView(
image: image,
duration: asset.duration,
isFavorite: asset.isFavorite,
proxy: proxy
)
.userActivity(
"com.example.apple-samplecode.AssistantSchemasExample.ViewingPhoto",
element: asset.entity
) { asset, activity in
activity.title = "Viewing a photo"
activity.appEntityIdentifier = EntityIdentifier(for: asset)
}
// ...
For more information about making onscreen content available to Siri and Apple Intelligence, refer to
Making onscreen content available to Siri and Apple Intelligence.
See Also
Siri and Apple Intelligence
Integrating actions with Siri and Apple Intelligence
Create app intents, entities, and enumerations that conform to assistant schemas to tap into the
enhanced action capabilities of Siri and Apple Intelligence.
Making onscreen content available to Siri and Apple Intelligence
Enable Siri and Apple Intelligence to respond to a personʼs questions and action requests for your
appʼs onscreen content.
App intent domains
Make your appʼs actions and content available to Siri and Apple Intelligence with assistant schemas.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: SemanticContentDescriptor | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
Visual Intelligence
Essentials
Integrating your app with visual intelligence
Adopting App Intents to support system ex…
S
SemanticContentDescriptor
Accessing semantic content
P
let labels: [String]
P
var pixelBuffer: CVReadOnlyPixelBuffer?
Protocol conformance
P
static var defaultResolverSpecification: s…
T
SemanticContentDescriptor.Specification
T
SemanticContentDescriptor.ValueType
T
SemanticContentDescriptor.UnwrappedT…
App intents essentials
Making actions and content discoverable a…
Creating your first app intent
Visual Intelligence / SemanticContentDescriptor
Structure
SemanticContentDescriptor
A type that represents a scene that visual intelligence captures, like
a screenshot, photo, or photo and video stream.
iOS 26.0+ iPadOS 26.0+ Mac Catalyst 26.0+
struct SemanticContentDescriptor
Mentioned in
Integrating your app with visual intelligence
Filter
/
Topics
Accessing semantic content
let labels: [String]
A list of labels that visual intelligence uses to classify items onscreen or
visual intelligence camera.
var pixelBuffer: CVReadOnlyPixelBuffer?
The pixel buffer that visual intelligence captures.
Protocol conformance
static var defaultResolverSpecification: some Resolver
Specification
A default implementation of an internal type that the App Intents framework
uses to convert data values with resolvers.
typealias Specification
A type that specifies how the system resolves a semantic content descriptor.
typealias ValueType
A type that represents the value of a semantic content descriptor.
typealias UnwrappedType
A type that represents the unwrapped value of a semantic content
descriptor.
Relationships
Conforms To
Copyable
CustomLocalizedStringResourceConvertible
CustomStringConvertible
DisplayRepresentable
InstanceDisplayRepresentable
PersistentlyIdentifiable
Sendable
SendableMetatype
TypeDisplayRepresentable
See Also
Essentials
Integrating your app with visual intelligence
Enable people to find app content that matches their surroundings or objects
onscreen with visual intelligence.
Adopting App Intents to support system experiences
Create app intents and entities to incorporate system experiences such as
Spotlight, visual intelligence, and Shortcuts.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: iMessage apps and stickers | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Design Overview Whatʼs New Get Started Guidelines Resources
Filter
Getting started
Foundations
Patterns
Components
Inputs
Technologies
AirPlay
Always On
App Clips
Apple Pay
Augmented reality
CareKit
CarPlay
Game Center
Generative AI
HealthKit
HomeKit
iCloud
ID Verifier
iMessage apps
and stickers
In-app purchase
Live Photos
Mac Catalyst
Machine learning
Maps
NFC
Photo editing
ResearchKit
SharePlay
iMessage apps and stickers
An iMessage app can help people share content, collaborate,
and even play games with others in a conversation; stickers are
images that people can use to decorate a conversation.
Supported platforms
iMessage apps and stickers
Best practices
Specifications
Platform considerations
Resources
Change log
An iMessage app or sticker pack is available within the context of a Messages conversation and
also in effects in both Messages and FaceTime. You can create an iMessage app or sticker pack
as a standalone app or as an app extension within your iOS or iPadOS app. For developer
guidance, see Messages and Adding Sticker packs and iMessage apps to the system Stickers
app, Messages camera, and FaceTime.
Best practices
Prefer providing one primary experience in your iMessage app. People are in a conversational
flow when they choose your app, so your functionality or content needs to be easy to
understand and immediately available. If you want to provide multiple types of functionality or
different collections of content, consider creating a separate iMessage app for each one.
Consider surfacing content from your iOS or iPadOS app. For example, your iMessage app
could offer app-specific information that people might want to share — such as a shopping list or
a trip itinerary — or support a simple, collaborative task, like deciding where to go for a meal or
which movie to watch.
Present essential features in the compact view. People can experience your iMessage app in a
compact view that appears below the message transcript, or they can expand the view to
occupy most of the window. Make sure the most frequently used items are available in the
compact view, reserving additional content and features for the expanded view.
In general, let people edit text only in the expanded view. The compact view occupies roughly
the same space as the keyboard. To ensure that the iMessage appʼs content remains visible
while people edit, display the keyboard in the expanded view.
Create stickers that are expressive, inclusive, and versatile. Whether your stickers are rich,
static images or short animations, make sure that each one remains legible against a wide range
of backgrounds and when rotated or scaled. You can also use transparency to help people
visually integrate a sticker with text, photos, and other stickers.
For each sticker, provide a localized alternative description. VoiceOver can help people use
your sticker pack by speaking a stickerʼs alternative description.
Specifications
Icon sizes
The icon for an iMessage app or sticker pack can appear in Messages, the App Store,
notifications, and Settings. After people install your iMessage app or sticker pack, its icon also
appears in the app drawer in the Messages app.
You supply a square-cornered icon for each extension you offer, and the system automatically
applies a mask that rounds the corners.
To ensure that your icon looks great in any context and on various devices, create a square-
cornered icon in the following sizes:
Usage @2x (pixels) @3x (pixels)
Messages, notifications 148x110 -
143x100 -
120x90 180x135
64x48 96x72
54x40 81x60
Settings 58x58 87x87
App Store 1024x1024 1024x1024
Sticker sizes
Messages supports small, regular, and large stickers. Pick the size that works best for your
content and prepare all of your stickers at that size; donʼt mix sizes within a single sticker pack.
Messages displays stickers in a grid, organized differently for different sizes.
Small Regular Large
Create your sticker images using the following @3x dimensions for the sticker size you chose. If
necessary, the system generates @2x and @1x versions by downscaling the images at runtime.
For developer guidance, see MSStickerSize.
Sticker size @3x dimensions (pixels)
Small 300x300
Regular 408x408
Large 618x618
A sticker file must be 500 KB or smaller in size. For each supported format, the table below
provides guidance for using transparency and animation.
Format Transparency Animation
PNG 8-bit No
APNG 8-bit Yes
GIF Single-color Yes
JPEG No No
Platform considerations
No additional considerations for iOS or iPadOS. Not supported in macOS, tvOS, visionOS, or
watchOS.
Resources
Related
iMessage Apps and Stickers
Developer documentation
Messages
Adding Sticker packs and iMessage apps to the system Stickers app, Messages camera, and
FaceTime — Messages
Videos
Express Yourself!
Change log
Date Changes
May 2, 2023 Consolidated guidance into one page.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines
English

========================================
FILE: Creating an Intents UI Extension | Apple Developer Documentation.pdf
========================================
Documentation Language: Swift
SiriKit / IntentsUI / Creating an Intents UI Extension
Creating an Intents UI Extension
Create an Intents UI app extension to customize the interfaces displayed by
Siri and Maps.
Overview
For some intents, Siri and Maps display details of the response provided by your Intents app
extension. When displaying this information, Siri and Maps place the data that you provided
into a standard system interface. For example, the default ride-booking interface includes a
map of the userʼs location and information about the booked ride. You can customize this
interface using an Intents UI app extension, which is a peer of the Intents app extension that
you use to handle intents.
SiriKit offers different levels of customization for its interface:
In iOS 11 and later, you can use intent parameters to customize every portion of the Siri or
Maps interface, making it possible to replace the default interface entirely.
You can provide a single custom view controller for SiriKit to display with the rest of the
default interface.
Note
watchOS doesnʼt support Intents UI app extensions.Topics
Configuration
Configuring Your Intents UI App Extension Target
Configure your Xcode project to include an Intents UI app extension that you use to
customize the Siri and Maps interfaces.
Configuring the View Controller for Your Custom Interface
Configure your view controller to replace or augment the default interface in Siri or Maps.
See Also
Custom UI for Siri and Maps
protocol INUIHostedViewControlling
Methods for presenting custom content in the Siri and Maps interfaces.
protocol INUIHostedViewSiriProviding
Methods for hiding portions of the default interfaces that Siri provides.
class INParameter
A parameter of an interaction object.
protocol INIntentSetImageKeyPath

========================================
FILE: SnippetIntent | Apple Developer Documentation.pdf
========================================
Integrating your app with visual intelligence
News Discover Design Develop Distribute Support Account
App Intents / SnippetIntent
Protocol
SnippetIntent
An app intent that presents an interactive snippet onscreen.
iOS 26.0+ iPadOS 26.0+ Mac Catalyst macOS 26.0+ tvOS 26.0+ visionOS 26.0+ watchOS 26.0+
protocol SnippetIntent : AppIntent where Self.PerformResult : ShowsSnippetView
Visual Intelligence
IntentValueQueryr P
All Technologies
Interactive Snippets
Documentation Language: Swift
App Intents
Displaying static and interactive snippets
SnippetIntentr P
Default implementation
S
EmptySnippetIntent
Type Methods
M
static func reload()
Other system experiences
Making app entities available in Spotlight
Focus
Action button on iPhone and Apple Watch
Launching your voice-based conversation…
Developing a WidgetKit strategy
SiriKit migration
Soup Chef with App Intents: Migrating cu…
Actions
App intents
Intent discovery
App Shortcuts
Parameters, custom data types, and queries
Adding parameters to an app intent
Integrating custom data types into your in…
Filter
Parameter resolution
/
App entities
Entity queries
Resolvers
Utility types
Mentioned in
Displaying static and interactive snippets
Overview
An app intent can present custom SwiftUI views to show people the result of their action, confirm a
selection, and more. For example, an app could show a confirmation for a successful order.
Note
The system can call a SnippetIntent multiple times. For more information, refer to Displaying static
and interactive snippets.
By conforming your app intent to the SnippetIntent protocol, you can provide a snippet, a custom view
with interactivity. Similar to widgets and Live Activities, a snippet can include buttons or toggles that use an
AppIntent for their functionality. In many cases, you might be able to reuse views of your interactive
widget or Live Activity.
The following code snippet shows what the perform method for a task management app could look like.
The intent asynchronously loads a list of tasks and presents it using the TodoListView that the
perform() function returns. The TodoListView could then offer a toggle for each item in the list to
immediately mark a task as completed.
struct ShowTodoListIntent: SnippetIntent {
// ...
@Parameter var todos: [Todo]
// ...
func perform() async throws -> some IntentResult & ShowsSnippetView {
// Fetch persisted todos to have the right
// up-to-date state performing this method. Make sure to
// consider that the system calls perform() several times.
let currentTodos = await TodoStore().find(todos)
let snippet = TodoListView(todos: currentTodos)
return .result(view: snippet)
}
}
When someone interacts with a snippetʼs button or a toggle, the system first performs its associated app
intent. When the button or toggleʼs intent completes, the system calls the snippet intentʼs perform()
method again. In your snippet intentʼs perform() implementation, make sure to handle multiple calls of
perform(). For example, the example above would need to fetch the list of tasks to make sure it displays
the most recent data. If a user completes a task from a snippet, the snippet needs to reflect this change
and show the task as completed or remove it from the list of tasks.
Important
Only app intents that conform to this protocol can present views with interactive elements, like buttons
and toggles, that work. Additionally, make sure to conform your intent to this protocol so that the
system knows to call again your perform function to render the new state of the snippet after it
performed the action of a button or toggle.
If your intent does more than just returning a snippet; for example, if you extend an app intent that returns a
value to also return a snippet; the intent is automatically discoverable in the Shortcuts app and Spotlight. If
an app intent conforms to SnippetIntent and only returns a snippet — their return type only conforms
to IntentResult and ShowsSnippetView —, itʼs nondiscoverable by the Shortcuts app and in
Spotlight. To make such an intent discoverable, explicitly set isDiscoverable to true.
Topics
Default implementation
struct EmptySnippetIntent
A snippet intent that renders an empty view.
Type Methods
static func reload()
Refreshes the intentʼs snippet presentation.
Relationships
Inherits From
AppIntent
PersistentlyIdentifiable
Sendable
SendableMetatype
Conforming Types
EmptySnippetIntent
See Also
Interactive Snippets
Displaying static and interactive snippets
Enable people to view the outcome of an app intent and immediately perform follow-up actions.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Developing a WidgetKit strategy | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
WidgetKit
Essentials
Developing a WidgetKit strategy
WidgetKit updates
Creating a widget extension
Emoji Rangers: Supporting Live Activities,…
WidgetBundler P
System experiences
Widgets and watch complications
Live Activities
Controls
Presentation
Creating views for widgets, Live Activities…
SwiftUI views for widgets
Interactivity
Adding interactivity to widgets and Live A…
Animating data updates in widgets and Li…
Linking to specific app scenes from your …
Accessibility
Adding accessible descriptions to widget…
Filter
WidgetKit / Developing a WidgetKit strategy
Article
Developing a WidgetKit strategy
Explore features, tasks, related frameworks, and constraints as you make a plan to
implement widgets, controls, watch complications, and Live Activities.
/
Overview
Use WidgetKit to build widgets, controls, watch complications, and Live Activities. When you offer these
system experiences, your app becomes part of the widget ecosystem across platforms and devices, and
expands its reach by taking up limited but effective, eye-catching space. System experiences that use
WidgetKit as a foundation rely on a set of related frameworks and share design and functional similarities,
making them great candidates for code and design component reuse.
To avoid costly changes in your appʼs development process, plan your WidgetKit adoption before you
create designs and write code. As you make your plans, take into account:
Feature availability for each platform
Frameworks to use in addition to WidgetKit
Required appearances and available sizes for widgets, watch complications, and Live Activities
Technology that powers content updates
Animation
Interactivity with your app through deep links, buttons, and toggles
Configuration options for widgets and watch complications
Visibility in Smart Stacks
Functional constraints
Then, approach WidgetKit adoption iteratively. For example, start with a nonconfigurable WidgetFamily
.systemSmall widget as described in Creating a widget extension because it gives your content broad
exposure in the WidgetKit ecosystem on iPhone, iPad, Mac, and Apple Vision Pro. Then, add support for
configuration, additional widget sizes, and — depending on your appʼs features — Live Activities or a
watchOS app with watch complications.
Review system experiences for each platform
Widgets come in different sizes, from circular accessory widgets on the Lock Screen and complications on
Apple Watch to extra-large widgets on Apple Vision Pro. You can choose the sizes and complications you
want to support, but consider supporting as many sizes and complications as possible.
Live Activities are available on iPhone and iPad and appear on the Lock Screen and in the Dynamic Island
on supported devices. Additionally, Live Activities appear on a paired Mac or Apple Watch, and in CarPlay.
When you add support for Live Activities, you need to create minimal, compact, and extended
presentations that make sure your Live Activities appear correctly for each platform.
In iOS, iPadOS, and macOS, your app can offer controls people place in Control Center. On Mac, people
can also place controls on the menu bar as menu bar items. On Apple Watch, controls from your watchOS
app or a paired iPhone appear in Control Center and the Smart Stack, and people can place them on the
Action button of Apple Watch Ultra.
This table shows the functionality available for each platform:
Widget size or
technology iPhone iPad Apple Watch Mac
Apple
Vision
Pro
Small system
widgets
Home Screen,
Today View, and
StandBy
Home Screen,
Today View, and
Lock Screen
No Yes Yes
Medium system
widgets
Home Screen and
Today View
Home Screen and
Today View No Yes Yes
Large system
widgets
Home Screen and
Today View
Home Screen and
Today View No Yes Yes
Extra large
system widgets No
Home Screen and
Today View No Yes Yes
Extra large
system widgets
(portrait)
No No No No Yes
Circular
accessory
widgets
Lock Screen Lock Screen
Watch
complications
and Smart Stack
No No
Corner
accessory
widgets
No No
Watch
complications No No
Rectangular
accessory
widgets
Lock Screen Lock Screen
Watch
complications
and Smart Stack
No No
widgets Inline accessory
Lock Screen Lock Screen Watch
complications No No
Live Activities Yes Yes From a paired
iPhone
From a
paired
iPhone
No
Controls Yes Yes Yes Yes No
Leverage additional frameworks
Widgets, watch complications, controls, and Live Activities use a widget extension you add to your Xcode
project. The role of WidgetKit is to provide the infrastructure and configuration for the features it enables.
Based on features and platforms you support, use WidgetKit in combination with other frameworks as
follows:
To create the user interface for each feature, use SwiftUI.
To add interactivity to widgets and Live Activities, use SwiftUI and the App Intents framework.
To offer watch complications and watchOS widgets, create a watchOS app.
To offer configurable widgets and watch complications, use App Intents.
To provide the contextual clues that the system uses for Smart Stacks and to offer Widget Suggestions,
use App Intents and RelevanceKit.
To start, update, and end Live Activities, use ActivityKit.
Support different appearances
Depending on the context, a widget or Live Activity changes its appearance to best fit its context. For
example, a WidgetFamily.systemSmall widget appears as follows:
On the Home Screen of iPhone and iPad, it uses it uses the accented rendering mode for light and dark
appearances, and fullColor on devices that run iOS and iPad 18 or older.
On the Lock Screen of iPad and iPhone, it uses the vibrant rendering mode that provides a vibrant,
blurred appearance. On the Lock Screen of iPhone in StandBy and StandBy in Night Mode, it renders
scaled up in size using the vibrant rendering mode.
In CarPlay, it renders scaled-up in size using the fullColor rendering mode with the background
removed.
On Mac, it uses the accented rendering mode. On older versions of macOS, it uses the fullColor or
vibrant modes.
Similarly, the WidgetFamily.accessoryRectangular widget appears as follows:
On the Lock Screen of iPhone and iPad, it takes on the vibrant appearance.
On Apple Watch, it appears as a watch complication without a background and the accented
appearance and in a fullColor appearance in the Smart Stack.
With each feature you add to your app, make sure your widget, watch complication, or Live Activity
supports all applicable contexts and appearances well. For more information, refer to Preparing widgets for
additional platforms, contexts, and appearances. For design guidance, refer to Human Interface Guidelines
> Widgets.
Animate content updates
Widgets and Live Activities can use animations to draw a personʼs attention to data updates, inclusing
custom animations. For more information, refer to Animating data updates in widgets and Live Activities.
Provide up-to-date information
Widgets and watch complications use a different mechanism than your app to update their content. They
use a timeline of data updates that you create in your app and hand to WidgetKit. You maintain this timeline
as your app receives new data, but, to optimize battery life for a device, each app has a budget to update
its widgets or complications. Additionally, the system batches and schedules updates to preserve power.
For more information on how timelines work and how you can keep your widgets and watch complications
up to date, refer to Keeping a widget up to date and Making network requests in a widget extension.
Additionally, widgets can update their data with the Apple Push Notification service (APNs) and WidgetKit
push notifications.
Live Activities donʼt use timelines to update their content. Instead, they use ActivityKit and ActivityKit push
notifications you send with APNs. For more information, refer to ActivityKit.
Controls also donʼt use timelines to update their content. Instead, they update their content when someone
uses them, the app reloads them, or the system receives a remote push notification from APNs. For more
information, refer to Updating controls locally and remotely.
Add specific app functionality to your widgets and Live
Activities
By default, people tap a widget, watch complication, or Live Activity to launch its corresponding app. To
make the experience more intuitive and require fewer interactions, you can use deep linking to launch the
scene of your app that matches the widgetʼs visible content. Widgets that offer enough space, such as
WidgetFamily.systemSmall or larger — and Live Activities in the extended or the Lock Screen
appearance — add SwiftUIʼs Link to your views and allow people to open different screens in your app.
Note
In iOS 16 and macOS 13 or earlier versions, only large and extra-large widgets can use Link.
Widgets offer direct interaction with your app using the App Intents framework and SwiftUI. Both Button
and Toggle offer dedicated initializers for this purpose. For more information, refer to Adding interactivity
to widgets and Live Activities.
Offer configurable widgets and watch complications
Make it possible for people to select the information they want to view in the widget or a watch
complication by offering configurable widgets and complications that provide customizable properties. For
example, people might choose to stay informed about a specific stock in a stock market widget, or enter a
tracking number for a package delivery widget. Configurable widgets and complications use the App
Intents framework and custom intents you define — the same mechanism you use to support system-level
services like Siri and the Shortcuts app. For information about creating configurable widgets and
complications, refer to Making a configurable widget.
Increase visibility in Smart Stacks
On iPhone and iPad, people create stacks of widgets and swipe through them manually. Additionally,
people use Smart Stacks with Smart Rotate to view the most relevant widgets and see widget suggestions.
To show relevant widgets at the top of Smart Stacks, iOS and iPadOS rely on behavioral clues that apps
provide during use. On Apple Watch, people can place and pin widgets in the Smart Stack, but they rely
more heavily on the system to automatically display contextually relevant widgets. To determine the most
relevant widgets, watchOS queries your widget extension for contextual clues.
For more information, refer to Increasing the visibility of widgets in Smart Stacks.
Consider user privacy
The Lock Screen and watch faces are always visible, and people can configure widgets and complications
to hide sensitive information when the device is locked or supports Always On. Review data that appears
on your widget, Live Activity, or complication, and make sure you support redaction of sensitive data. For
additional information, refer to Creating a widget extension.
Store shared data in a group container
To add widgets, watch complications, and Live Activities, you create a widget extension and add it to your
app, and the extension target and your app are part of the same app group. As a result, you can store files
and data in a shared container thatʼs accessible to the app and the widget extension. For example, your
app can download data and store it in a database in the shared container, and then a widget can access the
database.
For additional information about app groups and accessing a shared container, refer to Configuring app
groups.
Respect functional constraints
Widgets, watch complications, and Live Activities are always visible. To preserve battery life and user
privacy, they follow certain constraints. For example, Live Activities canʼt access a personʼs location. The
following table shows availability features that impact battery life or user privacy for each feature:
Functionality Widgets Watch complications Live Activities
Network access Yes Yes No
Location access Yes Yes No
For additional information, refer to Accessing location information in widgets.
See Also
Essentials
WidgetKit updates
Learn about important changes in WidgetKit.
Creating a widget extension
Display your appʼs content in a convenient, informative widget on various devices.
Emoji Rangers: Supporting Live Activities, interactivity, and animations
Offer Live Activities, controls, animate data updates, and add interactivity to widgets.
protocol WidgetBundle
A container used to expose multiple widgets from a single widget extension.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: App Shortcuts | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
App Intents / App Shortcuts
API Collection
App Shortcuts
Integrate your appʼs intents and entities with the Shortcuts app, Siri, Spotlight, and the
Action button on supported iPhone and Apple Watch models.
Overview
Create a preconfigured App Shortcut that enables people to discover and run your app intent without any
configuration. By creating App Shortcuts, you make your appʼs functionality instantly available for use in
Shortcuts, Spotlight, and Siri from the moment a person installs your app — without any setup in the
Shortcuts app or an Add to Siri button. On iPhone models that support the Action button, people can
associate your preconfigured App Shortcut on the Action button for quick access of your appʼs
functionality.
Note
Apple may extract anonymized App Shortcuts data such as localized phrases, display representation
values, and the title and description of related intents. Machine learning models use this data when
training to help improve the App Shortcuts experience.
Key app functionalities that people use to complete a task quickly and that you expose to the system with
app intents are great candidates for App Shortcuts. For each high-value app intent, create an App Shortcut
that specifies the intended action, the required parameters, the spoken phrases someone uses to run it,
and the short title and the image that appear in the Shortcuts app.
To offer an App Shortcut:
K. Create an app intent for a key app functionality as described in Creating your first app intent.
L. Create the AppShortcut object for your app intent using the init(intent:phrases:short
Title:systemImageName:) initializer with phrases people can use to run the app intent and with the
metadata that appears in the Shortcuts app.
N. Implement the AppShortcutsProvider protocol that provides the App Shortcuts you offer to the
Shortcuts app.
With these three steps, you make your appʼs functionality more discoverable and enable people to interact
with your app in a lightweight way. However, the system displays a default interface for your App Shortcut.
To display a custom view for each shortcut, return a SwiftUI view in your app intentʼs perform() method.
Related sessions from WWDC22
Session 10170: Implement App Shortcuts with App Intents and Session 10169: Design App Shortcuts.
Offer App Shortcuts with preconfigured parameters
With App Shortcuts, you can also preconfigure phrases for app intents that use specific parameters. When
you include parameters, people can use one phrase to start an interaction with an app without Siri having
to ask for clarification. For example, a meditation app could offer an app intent to start a meditation with
the phrase “Start a meditation”. Because the app offers many different meditations, Siri would require an
additional clarification which meditation a person wants to start.
With an App Shortcut, you can supply preconfigured parameters ahead of time that enable a person to skip
this clarification step. For example, the meditation app could provide parameterized phrases where each
phrase represents a common meditation. A person could then start a meditation with one phrase like “Start
a mindfulness meditation.” or “Start a short meditation.”
Make your App Shortcuts even more discoverable
Although App Shortcuts donʼt require a person to do any configuration in the Shortcuts app or by using the
Add to Siri button, you may want to present elements in your app to tell people about an available App
Shortcut. You have two options:
SiriTipView and SiriTipUIView present a view that tells a person that an App Shortcut is
available.
ShortcutsLink enables you to display a link to your App Shortcut.
ShortcutsLink is especially convenient if your app displays a list of its available App Shortcuts.
Topics
App Shortcut management
protocol AppShortcutsProvider
A type alias for the type that provides an appʼs preconfigured shortcuts.
App Shortcut definition
struct AppShortcut
A type that defines a preconfigured shortcut for a specific app intent.
struct AppShortcutPhrase
A spoken phrase that causes the system to run the corresponding App Shortcut.
struct NegativeAppShortcutPhrase
An object that represents a negative phrase.
struct NegativeAppShortcutPhrases
This is a set of negative phrases, which will all be added to the app-level negative training set. All the
training data specified here, will be used to completely bypass your app
NSAppIconActionTintColorName
The tint color to apply to text and symbols in the App Shortcuts platter.
NSAppIconComplementingColorNames
The names of the colors to use for the background of the App Shortcuts platter.
enum AppShortcutsBuilder
A result builder that allows you to declaratively describe the App Shortcuts that your app provides.
enum ShortcutTileColor
Describes the colors a shortcut tile in the Shortcuts app.
App Shortcut options
struct AppShortcutOptionsCollection
Represents a collection of options for parameters of an App Shortcut.
protocol AppShortcutOptionsCollectionProtocol
protocol AppShortcutOptionsCollectionSpecification
enum AppShortcutOptionsCollectionSpecificationBuilder
App Shortcut parameter presentation
struct AppShortcutParameterPresentation
Describes the presentation of an App Shortcut for the provided parameter.
struct AppShortcutParameterPresentationSummary
The summary of the presentation of an App Shortcut parameter.
struct AppShortcutParameterPresentationSummaryString
struct AppShortcutParameterPresentationTitle
A struct that represents the title of the presentation of an App Shortcut.
Deprecated
struct AppShortcutParameterPresentationTitleString Deprecated
Buttons
Discussion
class ShortcutsUIButton
A button that opens the current appʼs page in the Shortcuts app.
struct ShortcutsLink
A button that brings users to the current appʼs App Shortcuts page in the Shortcuts app.
struct ShortcutsLinkStyle
The styles to apply to buttons you use to open your appʼs page in the Shortcuts app.
Tip views
Discussion
class SiriTipUIView
A view that displays the phrase a person uses to invoke an App Shortcut.
struct SiriTipView
A SwiftUI view that displays the phrase someone uses to invoke an App Shortcut.
struct SiriTipViewStyle
The styles to apply to the tip views you use to display spoken phrases.
See Also
Actions
App intents
intents.
Define the custom actions your app exposes to the system, and incorporate support for existing SiriKit
Intent discovery
Donate your appʼs intents to the system to help it identify trends and predict future behaviors.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Creating your first app intent | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
App Intents / Creating your first app intent
Article
Creating your first app intent
Create your first app intent that makes your app available in system experiences like
Spotlight or the Shortcuts app.
Overview
To let people leverage your appʼs features outside of the app itself, system experiences like Spotlight and
the Shortcuts app require your help to understand your appʼs actions and content so the system can
expose that functionality. Use App Intents to express your appʼs capabilities and make your appʼs actions
available to the system. App intents are self-contained types that act as a bridge between your code and
system experiences and services. Each app intent encapsulates a single action thatʼs specific to your app.
It provides the system with any action that makes sense for your appʼs audience, such as showing
information about a hiking trail from a hiking app, exporting a personʼs transaction history from a budgeting
app, or converting between two specific units of measurement with a converter app.
Every app intent provides descriptive information about itself that experiences and services like Siri can
display or announce. When you build an app that contains app intents, the compiler examines your source
and generates data about those intents that Xcode stores in the app bundle. After someone installs your
app, the system uses that data to discover the intents and makes them available to the system.
Before you get started creating your first app intent, read Making actions and content discoverable and
widely available to review App Intents framework features and functionality. Then, identify an action and
create your first app intent, and offer an App Shortcut as described below. App Shortcuts make your app
intent even more useful. For example, App Shortcuts donʼt require configuration, and people can place
them on the Action button. Additionally, App Shortcuts appear in Spotlight even when a person hasnʼt
launched your app.
Identify an action
Think about actions and tasks people perform in your app, an actionʼs input and output data, and how the
system could surface actions in its services and experiences. In general, implement your AppIntent to
have a narrow focus and do one thing well. People can invoke it individually, or create custom shortcuts by
combining it with app intents from other apps in the Shortcuts app.
For your first app intent, choose an action that people are likely to use frequently. Then, add an App
Shortcut that includes the app intent.
Tip
To get familiar with the App Intents framework, consider creating your first app intent for functionality
that doesnʼt use a specialized app intent protocol; for example, an app intent that opens your app.
When youʼve successfully created your first app intent, make changes to adopt a specialized app
intent or add more app intents for more complex app functionality.
Review when to adopt specialized app intent protocols
For many app intents, the AppIntent protocol is the preferred protocol to adopt. However, depending on
your appʼs specific behaviors, you might prefer your code to conform to one of the other intent protocols;
for example:
Create app intents that conform to assistant schemas that make sure your actions and content work well
with the enhanced action capabilities of Siri that Apple Intelligence provides.
If your app plays or records audio and you want to offer that same functionality in an app intent, adopt
AudioPlaybackIntent instead. This protocol inherits from AppIntent and indicates the audio-
related behavior to the system so that, where possible, it avoids audio interactions and other potential
interruptions.
The App Intents framework provides a number of other specialized app intent protocols. For more
information about integrating your app intents with Siri and Apple Intelligence, see Integrating actions with
Siri and Apple Intelligence and App intent domains. For more information about other specialized protocols,
see App intents.
Create an app intent that opens your app
To define an action, create a type that adopts the AppIntent protocol, or a related protocol that provides
the specific behavior you need. If possible, start with a simple action that doesnʼt require parameters.
Alternatively, if your action requires a parameter, consider initially hard-coding the parameter to get your
first app intent implementation to work. Then make changes to add parameters to your first app intent as
described in Adding parameters to an app intent.
For example, the Accelerating app interactions with App Intents sample code project provides an app intent
that opens the app and displays a personʼs favorite hiking trails:
struct OpenFavorites: AppIntent {
static var title: LocalizedStringResource = "Open Favorite Trails"
static var description = IntentDescription("Opens the app and goes to your favorite trails."
static var openAppWhenRun: Bool = true
@MainActor
func perform() async throws -> some IntentResult {
navigationModel.selectedCollection = trailManager.favoritesCollection
return .result()
}
@Dependency
private var navigationModel: NavigationModel
@Dependency
private var trailManager: TrailDataManager
}
In the structure, implement the protocolʼs title requirement to provide the localized text that the
Shortcuts app displays in its Action Library and shortcut editor. To include additional context for the intent,
implement the optional description requirement to provide localized text that describes the app intentʼs
behavior. The Shortcuts app shows the description in its Action Library.
Perform the app intentʼs action
To provide your intentʼs functionality, implement the perform() protocol requirement. The system invokes
this method after it resolves any required parameters, meaning those parameters are safe for your code to
access from the functionʼs body.
Your implementation must complete the necessary work and return a result to the system. A result may
include, among other things, a value that a shortcut can use in subsequent connected actions, dialogue to
display or announce, and a SwiftUI snippet view.
For example, the Accelerating app interactions with App Intents sample code project returns a dialog for
the GetTrailInfo app intent:
func perform() async throws -> some IntentResult & ReturnsValue<TrailEntity> & ProvidesDialog
guard let trailData = trailManager.trail(with: trail.id) else {
throw TrailIntentError.trailNotFound
}
/**
*/
You provide a custom view by conforming the return type of the `perform()` function to the `ShowsSnippetView` protocol.
let snippet = TrailInfoView(trail: trailData, includeConditions: true)
/**
This intent displays a custom view that includes the trail conditions as part of the view. The dialog includes the trail con
the system can only read the response, but not display it. When the system can display the response, the dialog omits the tr
conditions.
*/
let dialog = IntentDialog(full: "The latest conditions reported for \(trail.name) indicate:
supporting: "Here's the latest information on trail conditions."
return .result(value: trail, dialog: dialog, view: snippet)
}
If it doesnʼt make sense for your intent to return a concrete result, return .result() to tell the system the
intent is complete.
Important
By default, the system launches your app in a limited mode in the background and executes the
intentʼs perform() method on an arbitrary queue. To override this behavior and launch the app in the
foreground, set the intentʼs openAppWhenRun variable to true. If your intent updates the appʼs user
interface, annotate perform() with @MainActor to make sure the method executes on the main
queue.
Verify the behavior of your intent in Simulator or on-device
During development, validate that your intents behave as you expect by testing them in Simulator or on-
device. If youʼre adding intents to a macOS app, build and run the app. For other platforms, select the
relevant simulator or connected device and then build and run. After your app launches, follow these steps:
T. Launch the Shortcuts app.
U. Tap or click the New Shortcut (+) button to create a shortcut.
Z. Choose Apps in the Action Libraryʼs segmented control.
[. \. ]. Tap or click your appʼs icon.
Select the action to test.
For app intents with parameters, use the summary to set the parameter values.
^. Tap or click the Run button.
Set a breakpoint at the top of your perform() method to confirm your implementation is working. The
debugger pauses execution immediately after you run the shortcut, enabling you to step through the code
and inspect the intentʼs parameters to verify they have the values they require.
Design custom responses
People may interact with your app intent through Siri. For a good user experience, consider communicating
the intentʼs result with a visual response using a custom UI snippet, and as a dialog for Siri to communicate
the same information. For more information, see Design custom responses.
Receive input with parameters and return results
Creating an app intent that opens a screen in your app is the first step to becoming familiar with the App
Intents framework and to making your app and its content discoverable. Many actions in your app receive
input and return data. To describe actions that receive and return data, add parameters to the app intent to
tell the system about that data and whether itʼs required or optional. By exposing parameters, you enable
people to configure your intents with values unique to their requirements and enable the App Intents
framework to communicate with system experiences to write those values at runtime. For example, the
Accelerating app interactions with App Intents sample code project enables people to choose which hiking
trail information to view when they invoke an app intent. For more information about using parameters in an
app intent, see Adding parameters to an app intent.
Create an App Shortcut
App intents you create appear in the Shortcuts app. People can create custom shortcuts that initiate your
app intent and combine app intents to perform custom workflows. To enable people to discover and run
your app intents without any configuration, bundle your appʼs app intents into App Shortcuts to provide
workflows of your appʼs actions.
By offering App Shortcuts, you make your appʼs functionality instantly available for use in Shortcuts,
Spotlight, and Siri from the moment a person installs your app — without any setup in the Shortcuts app or
an Add to Siri button. On devices that support the Action button, people can invoke your App Shortcut with
the Action button for quick access to your appʼs functionality.
To offer an App Shortcut for your first app intent:
T. Create the AppShortcut object for your app intent using the init(intent:phrases:short
Title:systemImageName:) initializer and provide phrases that people can use to run the app intent
and the metadata that appears in the Shortcuts app.
U. Implement the AppShortcutsProvider protocol that provides the App Shortcuts you offer to the
Shortcuts app.
For more information about creating App Shortcuts, see App Shortcuts and Create App Shortcuts.
To learn more about supporting the Action button, refer to Action button on iPhone and Apple Watch.
Donate app intents to the system
Make your app intents discoverable by explicitly donating them to the system. When someone performs an
action in your app, donate an intent that corresponds to that action. The system uses the information you
provide to predict actions someone might take in the future. For example, if someone requests the weather
from your app each morning, the system might proactively offer the corresponding app intent at the same
time each day.
For more information, see Intent discovery.
See Also
Essentials
App Intents updates
Learn about important changes in App Intents.
Making actions and content discoverable and widely available
Adopt App Intents to make your app discoverable with Spotlight, controls, widgets, and the Action
button.
Adopting App Intents to support system experiences
Create app intents and entities to incorporate system experiences such as Spotlight, visual
intelligence, and Shortcuts.
Accelerating app interactions with App Intents
Enable people to use your appʼs features quickly through Siri, Spotlight, and Shortcuts.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: App Intents | Apple Developer Documentation.pdf
========================================
Documentation Language: Swift
Framework
App Intents
Make your appʼs content and actions discoverable with system experiences
like Spotlight, widgets, and the Shortcuts app.
iOS 16.0+ iPadOS 16.0+ Mac Catalyst 16.0+ macOS 13.0+ tvOS 16.0+ visionOS 1.0+
watchOS 9.0+
Overview
The App Intents framework provides functionality to deeply integrate your appʼs actions and
content with system experiences across platforms, including Siri, Spotlight, widgets, controls
and more. With Apple Intelligence and enhancements to App Intents, Siri will suggest your
appʼs actions to help people discover your appʼs features and gains the ability to take actions
in and across apps.By adopting the App Intents framework, you allow people to personalize their devices by
instantly using your appʼs functionality with:
Interactions with Siri, including those that use the personal context awareness and action
capabilities of Apple Intelligence.
Spotlight suggestions and search.
Actions and automations in the Shortcuts app.
Hardware interactions that initiate app actions, like the Action button and squeeze gestures
on Apple Pencil.
Focus to allow people to reduce distractions.
Note
Siriʼs personal context understanding, onscreen awareness, and in-app actions are in
development and will be available with a future software update.
For example, App Intents enables you to express your appʼs actions, by offering an App
Shortcut. People can then ask Siri to take those actions on their behalf, whether theyʼre inyour app or elsewhere in the system. Use App Entities to expose content in your app to
Spotlight and semantic indexing with Apple Intelligence. People can then ask Siri to retrieve
information from your app, like asking Siri to pull up flight information from a travel app to
share with a loved one.
You reuse these components with other technologies to offer additional features and
experiences that make your app and its functionality even more discoverable and widely
available. For example, you reuse modular App Intents code together with WidgetKit to offer:
Interactive widgets
Controls
Live Activities
To learn more about features that the App Intents framework enables and how you can best
adopt the framework, see Making actions and content discoverable and widely available.
For design guidance, see Human Interface Guidelines > App Shortcuts, Human Interface
Guidelines > Siri, and Human Interface Guidelines > Action Button.
Topics
Essentials
App Intents updates
Learn about important changes in App Intents.
Making actions and content discoverable and widely available
Adopt App Intents to make your app discoverable with Spotlight, controls, widgets, and
the Action button.
Creating your first app intent
Create your first app intent that makes your app available in system experiences like
Spotlight or the Shortcuts app.Adopting App Intents to support system experiences
Create app intents and entities to incorporate system experiences such as Spotlight,
visual intelligence, and Shortcuts.
Accelerating app interactions with App Intents
Enable people to use your appʼs features quickly through Siri, Spotlight, and Shortcuts.
Siri and Apple Intelligence
Integrating actions with Siri and Apple Intelligence
Create app intents, entities, and enumerations that conform to assistant schemas to tap
into the enhanced action capabilities of Siri and Apple Intelligence.
Making onscreen content available to Siri and Apple Intelligence
Enable Siri and Apple Intelligence to respond to a personʼs questions and action requests
for your appʼs onscreen content.
App intent domains
Make your appʼs actions and content available to Siri and Apple Intelligence with
assistant schemas.
Making your appʼs functionality available to Siri
Add app intent schemas to your app so Siri can complete requests, and integrate your
app with Apple Intelligence, Spotlight, and other system experiences.
Visual intelligence
Integrating your app with visual intelligence
Enable people to find app content that matches their surroundings or objects onscreen
with visual intelligence.
Visual Intelligence
Include your appʼs content in search results that visual intelligence provides.protocol IntentValueQuery
A query that provides entity values to the system; for example, for visual intelligence
search.
Interactive Snippets
Displaying static and interactive snippets
Enable people to view the outcome of an app intent and immediately perform follow-up
actions.
protocol SnippetIntent
An app intent that presents an interactive snippet onscreen.
Other system experiences
Making app entities available in Spotlight
Allow people to find your appʼs content in Spotlight by donating app entities to its
semantic index.
Focus
Adjust your appʼs behavior and filter incoming notifications when the current Focus
changes.
Action button on iPhone and Apple Watch
Enable people to run your App Shortcuts with the Action button on iPhone or to start
your appʼs workout or dive sessions using the Action button on Apple Watch.
Launching your voice-based conversational app from the side button of iPhone
Let people in Japan configure the side button of iPhone to launch your voice-based
conversational app.
Developing a WidgetKit strategy
Explore features, tasks, related frameworks, and constraints as you make a plan to
implement widgets, controls, watch complications, and Live Activities.SiriKit migration
Soup Chef with App Intents: Migrating custom intents
Integrating App Intents to provide your appʼs actions to Siri and Shortcuts.
Actions
App intents
Define the custom actions your app exposes to the system, and incorporate support for
existing SiriKit intents.
Intent discovery
behaviors.
Donate your appʼs intents to the system to help it identify trends and predict future
App Shortcuts
Integrate your appʼs intents and entities with the Shortcuts app, Siri, Spotlight, and the
Action button on supported iPhone and Apple Watch models.
Parameters, custom data types, and queries
Adding parameters to an app intent
Enable people to configure app intents with their custom input values.
Integrating custom data types into your intents
Provide the system with information about the types your app uses to model its data so
that your intents can use those types as parameters.
Parameter resolution
Define the required parameters for your app intents and specify how to resolve those
parameters at runtime.
App entities
Make core types or concepts discoverable to the system by declaring them as appentities.
Entity queries
Help the system find the entities your app defines and use them to resolve parameters.
Resolvers
Resolve the parameters of your app intents, and extend the standard resolution types to
include your appʼs custom types.
Utility types
Common types
Specify common types that your app supports, including currencies, files, and contacts.
Errors
struct AppIntentError
Errors that your intent-handling code can return to indicate problems while interpreting
or executing an app intent.
Protocols
protocol AppIntentSceneDelegate
Implement this protocol on your UIScene delegate to handle AppIntent invocations
targeting a specific scene Example:
protocol AppShortcutsContent
protocol CustomURLRepresentationParameterConvertible
protocol ShowsSnippetIntent
The result of performing an action that present a snippet generated by a Snippet
Intent-conforming type.
protocol TargetContentProvidingIntentprotocol UISceneAppIntent
protocol UndoableIntent
Structures
struct ConfirmationConditions
Conditions for a confirmation request.
struct EntityPropertyModifiers
struct EntityURLRepresentation
The URL representation of an app entity.
struct EnumURLRepresentation
The URL representation of an app enum.
struct FileEntityIdentifier
An identifier for an app entity that refers to a document or other file.
struct IntentChoiceOption
A structure representing an entry in a list of options for a person to choose from before
an app intent resumes its action.
struct IntentModes
A set of options that describe an app intentʼs behavior.
struct IntentURLRepresentation
The URL representation of an app intent.
Macros
macro UnionValue()
Enumerationsenum AppShortcutPhraseToken
Dynamic values you can include in the spoken phrases that run your shortcut.
enum VideoCategory

========================================
FILE: Shared with You Core | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
Framework
Shared with You Core
Integrate custom collaboration with Messages, Mail, and FaceTime.
Overview
The Shared with You Core framework provides classes to collaborate and share documents directly with the Messages,
Mail, and FaceTime apps. Use the classes in this framework to share content, create configurable collaboration settings,
and manage participants.
The framework provides a customizable popover to your app to manage details of the collaboration and connect to
conversations. The UI incorporates technologies you already use, like share sheet and drag and drop. An indicator in the
share sheet header identifies a collaboration.
Use the SWCollaborationCoordinator to manage collaboration activities in your app. The SWCollaboration
Metadata objects contain the collaboration metadata with essential information like, identifiers, titles, and share option
configuration that update the UI. To customize collaboration settings, use the SWCollaborationOption,
SWCollaborationOptionsGroup, and SWCollaborationShareOptions classes. These options appear in
Messages, Mail, and FaceTime, providing people with the opportunity to make choices about permissions, access levels,
and other collaboration parameters.
For more information on integrating with Messages, Mail, and FaceTime, see Adding custom collaboration to your app.
Note
Shared with You Core is a Shared with You framework.
Topics
Coordinate collaborations
class SWCollaborationCoordinator
An object that contains the shared collaboration coordinator.
Handle collaboration actions
class SWAction
An object that represents a collaboration action.
protocol SWCollaborationActionHandler
A delegate to handle incoming collaboration actions from a collaboration coordinator.
class SWStartCollaborationAction
An object that represents the first action sent to an app when the user shares a collaboration.
class SWUpdateCollaborationParticipantsAction
An action that contains the cryptographic identities the system uses to add to or remove from an existing
collaboration.
Register the collaboration metadata
class SWCollaborationMetadata
A model object for conveying data during a collaboration.
Manage options in a collaboration
class SWCollaborationOption
An object that determines how the system shares a document in a collaboration.
class SWCollaborationOptionsGroup
An object that represents a group of collaboration options that the system displays together.
class SWCollaborationOptionsPickerGroup
An object that represents a group of collaboration options that the system displays together with mutually
exclusive options.
class SWCollaborationShareOptions
An object that represents the state of the collaboration options for the document.
struct SWLocalCollaborationIdentifier
A local identifier for a collaboration.
let UTCollaborationOptionsTypeIdentifier: String
A string constant for the options type identifier.
Manage collaboration participants
class SWPerson
An object that tracks participants in a collaboration.
struct SWCollaborationIdentifier
A unique identifier for a collaboration.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Shared with You | Apple Developer Documentation.pdf
========================================
Documentation Language: Swift
Technology
Shared with You
Surface shared content and collaborate in your app.
iOS 16.0+ iPadOS 16.0+ Mac Catalyst 16.0+ macOS 13.0+ tvOS 16.0+ visionOS 1.0+
Overview
Access and view content shared from Messages across the system and continue the
messaging experience without leaving your app. Incorporate Shared with You to make it easier
for people to access content shared through conversations or notifications.Support a Shared with You shelf in your app to visually represent shared items with an
SWAttributionView that the system renders. Securely share universal links that your app
accesses using the SWHighlight class. For information on getting started, see Making your
app content shareable.
Related sessions from WWDC22
Session 10094: Add Shared with You to your appTopics
Frameworks
Shared with You Core
Integrate custom collaboration with Messages, Mail, and FaceTime.
Shared content
Making your app content shareable
Add support for universal links and a Shared with You shelf to support shared content in
your app.
Shared content interactions
Use highlights and attribution views to manage participants and trigger events for shared
content.
Collaboration
Adding shared content collaboration to your app
Manage shared content collaboration in your app using CloudKit and iCloud Drive.
Adding custom collaboration to your app
Integrate your custom collaboration app with Messages.
Collaboration views
Create and customize a collaboration view to manage the shared content actions.
Framework versions
Version number
Version stringMacros
Macros

========================================
FILE: Configuring the View Controller for Your Custom Interface | Apple Developer Documentation.pdf
========================================
Documentation Language: Swift
SiriKit / Configuring the View Controller for Your Custom Interface
Article
Configuring the View Controller for Your
Custom Interface
Configure your view controller to replace or augment the default interface in
Siri or Maps.
Overview
When displaying responses to the user, SiriKit provides a default interface for displaying the
content of your response. Replace some or all of this default interface with custom views,
which you might do to fully customize the userʼs Siri-based interactions with your app.
Another option is to augment the default interface with a single view, hiding portions of the
default UI that your content might duplicate.
Requirements and Limitations
For all customizations, you provide a view controller whose views contain the information that
you want to display. When replacing the default interface, SiriKit may create multiple instances
of your view controller, and you must configure each one appropriately for the type of
displayed content. When augmenting the default interface, SiriKit creates a single instance of
your view controller.
While onscreen, your view controllers remain part of the foreground Siri or Maps interface
until the user dismisses it. You can update your view controllers as needed using timers orother programmatic means. Your view controllers also receive the normal callbacks when
theyʼre loaded, shown, and hidden. However, your view controllers donʼt receive touch events
or any other events while theyʼre onscreen, and you canʼt add gesture recognizers to them.
Therefore, never create an interface with controls or views that require user interactions.
Replace Some or All of the Default Interface
In iOS 11 and later, you can replace some or all of the default Siri or Maps interface. Before
displaying an interface to the user, Siri builds a list of parameters—that is, instances of the
INParameter class—representing the data it wants to display. Each parameter identifies a
property of the intent or response object contained in the INInteraction object that SiriKit
provides.
After building the list of parameters, SiriKit creates one or more instances of your view
controller and calls the configureView(for:of:interactiveBehavior:context:
completion:) method of each one, passing it a specific set of parameters. When the
configureView(for:of:interactiveBehavior:context:completion:) method
is called, you must decide whether you want to provide a custom interface for the specified
parameters. If you do, add subviews to the view controllerʼs root view and update those views
with the parameterʼs content.
Although SiriKit often passes only one parameter at a time to your configureView(for:
of:interactiveBehavior:context:completion:) method, you can configure a view
that displays content for any number of parameters. When calling the completion handler of
your configuration method, provide SiriKit with the set of parameters that your interface
displays. Before creating a new view controller with the next set of parameters, SiriKit checks
to see if you already displayed those parameters. If you did, SiriKit does not ask you to display
them again.
Augment the Default Interface
If you want to keep the default Siri or Maps interface and only augment it with your custom
content, implement the configure(with:context:completion:) method of your view
controller. SiriKit instantiates your view controller and calls that method to configure your view
controllerʼs view. The context parameter tells you where your view controller will be displayed,
giving you an opportunity to display your content differently in Siri and Maps.The figure below shows the high-level life cycle of your view controller when you configure it
to augment the default interface. The system creates your view controller and calls its
configure(with:context:completion:) method, passing it the interaction object you
need to configure your interface. Once configured, your view controller is presented onscreen
with the rest of the Siri or Maps content.Note
While a view controller is onscreen, Maps may call the configure(with:context:
completion:) method again to deliver updated information for you to display. For
example, Maps calls this method when your Intents extension provides a status update
for a booked ride. Use any follow-up calls to update your view controllerʼs interface.
When the user dismisses the Siri or Maps interface, the system releases its reference to your
view controller and your Intents UI extension. Your view controllers should only display
information. Do not try to save data or communicate with your app when your view controller
moves offscreen.
Important
In iOS 11 and later, if your view controller implements both the configureView(for:
of:interactiveBehavior:context:completion:) and configure(with:
context:completion:) methods, SiriKit calls only the configureView(for:of:
interactiveBehavior:context:completion:) method.
Tips for Implementing Your View Controller
Here are some tips for implementing the view controller for your Intents UI extension:
Incorporate your brand into your interface. Using your appʼs color, imagery, and other
design elements is a great way to add familiarity and convey the presence of your app
within the Siri or Maps interfaces.
Configure any animated content to run only when your view controller is visible. Wait
until your view controllerʼs viewDidAppear(_:) method is called to start animations.
Stop animations in your view controllerʼs viewWillDisappear(_:) method.
Configure your view controllerʼs view as quickly as possible so that Siri can display it.
Your view controller may not be onscreen for very long, so use local resources and the
provided INInteraction object for the bulk of your configuration. If you need to fetch
more information from a server, always do so asynchronously and update your interfacelater.
Configure your interface using only the provided interaction object. The provided
INInteraction object contains the original intent and the response provided by your
Intents extension, which runs in a separate process. Using only the provided interaction
object ensures that your view controllerʼs interface accurately reflects the information
provided by your Intents extension. To communicate more information to your Intents UI
app extension, your Intents app extension can include a custom NSUserActivity object
with its response and put the additional information in that objectʼs userInfo dictionary.
Do not include advertising in your interface. You may include branding and information
that is relevant to the user, but advertising is prohibited.
Return a zero size when you want to hide your custom interface. When calling the
handler block of your configuration method, specify CGRectZero for the size when you do
not want the view controller to be shown onscreen. You might hide the view controller when
there is no additional information to display for the specified intent.
Do not include a map view when your view controller is shown in a Maps context. When
the context parameter is set to INUIHostedViewContext.mapsCard, do not include an
MKMapView in your view controllerʼs interface. Maps already displays a map, so having two
maps showing similar information would be confusing to users.
Use child view controllers to switch between different types of content. Your Intents UI
app extension has only one initial view controller. Using child view controllers lets you
encapsulate the behavior for for different intents or different views of an intent in one place.
During configuration of your initial view controller, all you have to do is instantiate the
appropriate child view controller and install its view in your interface.
Hiding Portions of the Default Interface
SiriKit lets you hide some types of content in the default interfaces using properties of the
INUIHostedViewSiriProviding protocol. If you are only augmenting the default
interface with custom content, use these properties to avoid duplicating the content shown by
Siri or Maps. For example, a ride booking app that adds a map to the default interface could
implement the displaysMap property and use it to hide the map in the default interface.
For more information about hiding portions of the default interface, see INUIHostedViewSiriProviding.
See Also
Articles
Adding User Interactivity with Siri Shortcuts and the Shortcuts App
Add custom intents and parameters to help users interact more quickly and effectively
with Siri and the Shortcuts app.
Defining Relevant Shortcuts for the Siri Watch Face
Inform Siri when your appʼs shortcuts may be useful to the user.
Deleting Donated Shortcuts
Remove your donations from Siri.
Dispatching intents to handlers
Provide SiriKit with an intent handler capable of handling a specific intent.
Improving Siri Media Interactions and App Selection
Fine-tune voice controls and improve Siri Suggestions by sharing app capabilities,
customized names, and listening habits with the system.
Improving interactions between Siri and your messaging app
Donate app-specific content, use Siriʼs contact suggestions, and adopt the latest
platform features to create a more consistent messaging experience.
Registering Custom Vocabulary with SiriKit
Register your appʼs custom terminology, and provide sample phrases for how to use your
app with Siri.
Confirming the Details of an Intent
Perform final validation of the intent parameters and verify that your services are readyto fulfill the intent.
Handling an Intent
Fulfill the intent and provide feedback to SiriKit about what you did.
Resolving the Parameters of an Intent
Validate the parameters of an intent and make sure that you have the information you
need to continue.
Generating a List of Ride Options
Generate ride options for Maps to display to the user.
Handling the Ride-Booking Intents
Support the different intent-handling sequences for booking rides with Shortcuts or
Maps.
Donating Reservations
Inform Siri of reservations made from your app.
Specifying Synonyms for Your App Name
Provide alternative names for your app that are more familiar or easier for users to speak.
Intent Phrases
The keys that you include in your global vocabulary file to show how users engage your
app from Siri.

========================================
FILE: appEntityIdentifier | Apple Developer Documentation.pdf
========================================
V
var NSUserActivityErrorMinimum: Int
News Discover Design Develop Distribute Support Account
Foundation / NSUserActivity / appEntityIdentifier
Instance Property
appEntityIdentifier
The identifier of an app entity that you associate with the user activity.
iOS 18.2+ iPadOS 18.2+ Mac Catalyst 18.2+ macOS 15.2+ tvOS 18.2+ visionOS 2.2+ watchOS 11.2+
var appEntityIdentifier: EntityIdentifier? { get set }
V
var NSUserActivityHandoffFailedError…
Documentation Language: Swift
V
var NSUserActivityHandoffUserInfoTo…
All Technologies
V
var NSUserActivityRemoteApplication…
Foundation
Instance Properties
P
var appEntityIdentifier: EntityIdentif…
Instance Methods
M
func widgetConfigurationIntent<Inten…
Default Implementations
AppEntityAnnotatable Implementations
NSUserActivityDelegater P
System Interaction
C
ProcessInfo
C
NSBackgroundActivityScheduler
User Notifications
C
NSUserNotification Deprecated
C
NSUserNotificationAction Deprecated
C
NSUserNotificationCenter Deprecated
NSUserNotificationCenterDelegater P
Combine Integration
T
Published
T
ObservableObject
Resources
Notifications
Discussion
By associating an app entity with a user activity, you make the entity available to Siri and Apple Intelligence.
To clear the association with the app entity, set appEntityIdentifier to nil.
For more information, refer to Making onscreen content available to Siri and Apple Intelligence and App
Intents.
App Extension Support
Filter
Errors and Exceptions
/
Scripting Support
Files and Data Persistence
Platforms
File System
iOS
iPadOS
Archives and Serialization
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Developer Documentation
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Parameter resolution | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Parameter resolution
Intent parameters
C
IntentParameter
C
IntentParameterDependency
S
IntentParameterContext
E
InputConnectionBehavior
Parameter choices
DynamicOptionsProviderr P
AppEnumr P
Shortcuts support
ParameterSummaryr P
S
IntentParameterSummary
S
ParameterSummaryString
S
ParameterSummaryWhenCondition
S
ParameterSummarySwitchCondition
S
ParameterSummaryCaseCondition
S
ParameterSummaryDefaultCaseConditi…
App entities
Entity queries
Filter
App Intents / Parameter resolution
API Collection
Parameter resolution
Define the required parameters for your app intents and specify how to resolve those
parameters at runtime.
/
Overview
Parameters represent input arguments to your app intents and offer additional metadata to the system.
When you define an app intent, add the @Parameter property wrapper to any properties you use as input.
For example, an app intent that sends a message might include a parameter for the recipient and message
string. The system collects and resolves the relevant parameter information before it performs your app
intent.
The following partial example shows how to declare parameters for a custom app intent that enables
someone to order soup from your app. Configure the parameter property wrapper with any additional
details that help the system infer extra information about your parameter.
struct OrderSoupIntent: AppIntent {
@Parameter(title: "Soup")
var soup: Soup
@Parameter(title: "Quantity", inclusiveRange: (1, 10))
var quantity: Int
// Other properties
}
Topics
Intent parameters
class IntentParameter
A property wrapper that indicates the associated property is an input argument of the app intent.
class IntentParameterDependency
A property wrapper that represents an app intent dependency you use to provide dynamic options.
struct IntentParameterContext
A type that provides information about an associated parameter during value resolution.
enum InputConnectionBehavior
Describes the input behaviors for connecting a parameter to the output of the previous App Intent.
Parameter choices
protocol DynamicOptionsProvider
An interface for providing a dynamic list of options for a parameter of your app intent.
protocol AppEnum
An interface to express that a custom type has a predefined, static set of valid values to display.
Shortcuts support
protocol ParameterSummary
An interface for defining the visual representation of an app intentʼs parameters.
struct IntentParameterSummary
A type that describes the user interface configuration of an app intentʼs parameters.
struct ParameterSummaryString
A human-readable string that interpolates parameter key paths to provide user-configurable
placeholders in the Shortcuts app.
struct ParameterSummaryWhenCondition
A type that represents a conditional statement in a parameter summary.
struct ParameterSummarySwitchCondition
A type that represents a switch statement in a parameter summary.
struct ParameterSummaryCaseCondition
A type that represents an individual case of a switch statement in a parameter summary.
struct ParameterSummaryDefaultCaseCondition
A type that represents the default case of a switch statement in a parameter summary.
See Also
Parameters, custom data types, and queries
Adding parameters to an app intent
Enable people to configure app intents with their custom input values.
Integrating custom data types into your intents
Provide the system with information about the types your app uses to model its data so that your
intents can use those types as parameters.
App entities
Make core types or concepts discoverable to the system by declaring them as app entities.
Entity queries
Help the system find the entities your app defines and use them to resolve parameters.
Resolvers
Resolve the parameters of your app intents, and extend the standard resolution types to include your
appʼs custom types.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Adding parameters to an app intent | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Adding parameters to an app intent
Integrating custom data types into your in…
Parameter resolution
App entities
Entity queries
Resolvers
Utility types
Common types
Errors
S
AppIntentError
Protocols
AppIntentSceneDelegater P
AppShortcutsContentr P
r P
CustomURLRepresentationParameterCon…
ShowsSnippetIntentr P
TargetContentProvidingIntentr P
UISceneAppIntentr P
UndoableIntentr P
Structures
App Intents / Adding parameters to an app intent
Article
Adding parameters to an app intent
Enable people to configure app intents with their custom input values.
Filter
/
Overview
Many of your appʼs actions likely require input data to perform their work. To help people provide the input
that an AppIntent needs to perform its functionality, add parameters to the intent to tell the system
about that data and whether itʼs required or optional. When you expose these parameters, people can
configure your intents with values unique to their requirements and enable the App Intents framework to
mediate with system experiences to write those values at runtime.
For example, the Accelerating app interactions with App Intents sample code projectʼs GetTrailInfo
intent lets people choose which hiking trail information to view when they invoke the app intent. It declares
a trail parameter by decorating the trail property with the IntentParameter property wrapper and
provides a title and a description to identify the parameter in the Shortcuts app.
@Parameter(title: "Trail", description: "The trail to get information on.")
var trail: TrailEntity
Note that the example doesnʼt provide localized text for the title and description fields to keep the
example focused and make it easy to understand. Always provide localized strings for app intents, App
Shortcuts, and their parameters.
Make a parameter optional or required
How you define your parameter variables determines whether the system treats that parameter as required
or optional. If you define a variable as a non-optional type, the system knows the parameter is required
and, when necessary, requests a value. Conversely, if you define a variable as an optional type, the system
assumes the parameter is optional and doesnʼt request a value. In this scenario, use the property wrapperʼs
requestValue(_:) method to pause execution and request a value if the intent canʼt proceed
otherwise.
guard let date = date else {
throw $date.requestValue("What date would you like to use?")
}
Review supported parameter types
You can use the @Parameter property wrapper with common Swift and Foundation types:
Primitives such as Bool, Int, Double, String, Duration, Date, Decimal, Measurement, and URL.
Collections such as Array and Set. Make sure the collectionʼs elements are of a type thatʼs compatible
with IntentParameter.
Additionally:
Use framework-specific types such as IntentPerson and IntentFile. For additional types, see
Common types.
Use enumerable types that conform to the AppEnum protocol for parameters that have known static
values at build time.
Use custom types that adopt the AppEntity protocol and that the system can request at runtime.
For example, the Accelerating app interactions with App Intents sample code project makes its trail data
available in an app intent through the TrailEntity type, which is a structure conforming to the App
Entity protocol.
Transform input into your intent parameterʼs types
When a person provides input that your app intents use, the input doesnʼt always match the type that your
parameters require. For example, natural spoken language commands from Siri are strings, but your app
intent might require an integer or floating-point value. To help you with input of various types, use
Resolvers to leverage the systemʼs ability to translate one type to another automatically so your app intent
can use the input.
Restrict parameter values
To make it easy for people to provide your app intents with the right information, restrict parameter values.
The system presents known values as a list and prompts the person to select one when it needs to resolve
a parameter. To restrict parameter values to a list of known values:
At compile time, use an enumeration type for the parameter that conforms to the AppEnum protocol.
At runtime, specify an options provider as part of the property wrapperʼs declaration. An options
provider is a type you implement that conforms to the DynamicOptionsProvider protocol and
provides a set of permitted values at runtime.
For example, the Accelerating app interactions with App Intents sample code project uses a dynamic
options provider to display a sorted list of location parameters in the Shortcuts app.
struct LocationOptionsProvider: DynamicOptionsProvider {
@Dependency
private var trailManager: TrailDataManager
func results() async throws -> [String] {
Logger.intentLogging.debug("Getting locations from LocationOptionsProvider")
// Get a list of locations and return it sorted for display, such as in the Shortcuts app.
return trailManager.uniqueLocations
.sorted(using: KeyPathComparator(\.self, comparator: .localizedStandard))
}
}
You can configure a parameter with additional options such as enforcing an inclusive range for number
types, or specifying the capitalization style and keyboard mode for string types. For more information, see
IntentParameter.
Provide an interactive parameter summary for your intent
A parameter summary is a visual, textual outline of your app intent that the Shortcuts app displays in the
shortcut editor. The summary can include placeholders that people interact with to choose the values for
the intentʼs parameters. Even if your intent doesnʼt expose any parameters, providing a summary is an
opportunity to present more information about your intent in addition to its title.
To add a parameter summary to your intent, implement the protocolʼs parameterSummary requirement
and use the provided ParameterSummaryBuilder result builder to build the summary. Write the content
using localized natural language and, where applicable, substitute words that represent parameters with
the key paths to those parameters.
static var parameterSummary: some ParameterSummary {
Summary("Get information on \(\.$trail)")
}
The shortcut editor substitutes each key path with the corresponding parameterʼs title and enables a
person to set the value by tapping it. The editor uses the parameterʼs type to determine which input
controls to display.
Parameter summaries can include conditional statements such as AppIntent.When and AppIntent
.Switch that let the summary update itself in response to already chosen values.
For example, the Accelerating app interactions with App Intents sample code project uses AppIntent
.Switch in its SuggestedTrails app intent:
static var parameterSummary: some ParameterSummary {
Switch(\.$activity) {
Case(.biking) {
When(\.$location, .hasAnyValue) {
Summary("Ride a bike within \(\.$searchRadius) of \(\.$location)")
} otherwise: {
When(\.$trailCollection, .hasAnyValue) {
Summary("Pick a bike ride from \(\.$trailCollection)")
} otherwise: {
Summary("Suggest bike rides from \(\.$trailCollection) or near \(\.$location
}
}
}
DefaultCase() {
When(\.$location, .hasAnyValue) {
Summary("Suggest \(\.$activity) trails within \(\.$searchRadius) of \(\.
} otherwise: {
When(\.$trailCollection, .hasAnyValue) {
Summary("Suggest \(\.$activity) trails from \(\.$trailCollection)")
} otherwise: {
Summary("Suggest \(\.$activity) trails from \(\.$trailCollection) or near
}
}
}
}
}
For more information, see Parameter resolution.
Review the role of app entities
App entities provide the system with information about your appʼs data, or about concepts related to your
appʼs data. App entities describe your appʼs custom data types you use for parameters, and help the
system resolve parameters for app intents by letting it inspect relevant types. For example, a photo app
that provides app entities for its photos and albums might also provide app entities to represent “the most
recent photo” or “the default album.” These specific app entities help resolve intents more quickly and with
fewer verbal interactions.
Define app entities for core types and concepts that you want to make available to system experiences,
and make sure to include properties for any data values that help people discover the entities using
queries. For example, create an entity that describes a photo album and add a property to the entity for the
name of the photo album.
For more information about expressing your appʼs data as entities, see Integrating custom data types into
your intents.
See Also
Parameters, custom data types, and queries
Integrating custom data types into your intents
Provide the system with information about the types your app uses to model its data so that your
intents can use those types as parameters.
Parameter resolution
Define the required parameters for your app intents and specify how to resolve those parameters at
runtime.
App entities
Make core types or concepts discoverable to the system by declaring them as app entities.
Entity queries
Help the system find the entities your app defines and use them to resolve parameters.
Resolvers
Resolve the parameters of your app intents, and extend the standard resolution types to include your
appʼs custom types.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Adopting App Intents to support system experiences | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Essentials
App Intents updates
Making actions and content discoverable …
Creating your first app intent
Adopting App Intents to support syste…
Accelerating app interactions with App Int…
Siri and Apple Intelligence
Integrating actions with Siri and Apple Int…
Making onscreen content available to Siri …
App intent domains
Making your appʼs functionality available t…
Visual intelligence
Integrating your app with visual intelligence
Visual Intelligence
IntentValueQueryr P
Interactive Snippets
Displaying static and interactive snippets
SnippetIntentr P
Other system experiences
Filter
App Intents / Adopting App Intents to support system experiences
Sample Code
Adopting App Intents to support system
experiences
Create app intents and entities to incorporate system experiences such as Spotlight,
visual intelligence, and Shortcuts.
Download
iOS 26.0+ iPadOS 26.0+ macOS 26.0+ Xcode 26.0+
/
Overview
The app in this sample offers actions in the Shortcuts app that people can use to create custom shortcuts.
It includes an App Shortcut to find the closest landmark and find tickets to visit the landmark, all without
opening the app. Additionally, the app makes its data available to system experiences like Spotlight, Siri and
Apple Intelligence, and visual intelligence.
By adopting the App Intents framework, the app provides functionality across the system, enabling people
to:
In Shortcuts, find and run the appʼs app intents.
In Shortcuts, create custom shortcuts or view the provided “Find Closest” App Shortcut.
In Shortcuts, place custom shortcuts or the App Shortcut on the Home Screen as a bookmark.
In Spotlight, search for a landmark or the “Find Closest” App Shortcut.
With visual intelligence, circle an object in the visual intelligence camera or onscreen and view matching
results from the app.
With the Action button, trigger a custom shortcut or the App Shortcut.
From Siri suggestions, use custom shortcuts or the App Shortcut.
In the app, view information about a landmark, then ask Siri something like “Whatʼs a summary of the
history of this place?” or similar to receive a content summary, and more.
Describe actions as app intents and entities
The app contains many actions and makes them available to the system as app intents, so people can use
them to create custom shortcuts and invoke across system experiences. For example, the app offers key
actions like finding the closest landmark or opening a landmark in the app. This app intent opens a
landmark in the app:
import AppIntents
struct OpenLandmarkIntent: OpenIntent {
static let title: LocalizedStringResource = "Open Landmark"
@Parameter(title: "Landmark", requestValueDialog: "Which landmark?")
var target: LandmarkEntity
func perform() async throws -> some IntentResult {
return .result()
}
}
To use your data as input and output of app intents and make the data available to the system, you use app
entities. App entities often limit the information a model object you persist to storage to what the system
needs. They also add required information to understand the data or to use it in system experiences. For
example, the LandmarkEntity of the sample app provides required typeDisplayRepresentation
and displayRepresentation properties but doesnʼt include every property of the Landmark model
object:
struct LandmarkEntity: IndexedEntity {
static var typeDisplayRepresentation: TypeDisplayRepresentation {
return TypeDisplayRepresentation(
name: LocalizedStringResource("Landmark", table: "AppIntents", comment: "The type name for t
numericFormat: "\(placeholder: .int) landmarks"
)
}
var displayRepresentation: DisplayRepresentation {
DisplayRepresentation(
title: "\(name)"
,
subtitle: "\(continent)"
,
image: .init(data: try! self.thumbnailRepresentationData)
)
}
static let defaultQuery = LandmarkEntityQuery()
var id: Int { landmark.id }
@ComputedProperty(indexingKey: \.displayName)
var name: String { landmark.name }
// Maps the description variable to the Spotlight indexing key `contentDescription`.
@ComputedProperty(indexingKey: \.contentDescription)
var description: String { landmark.description }
@ComputedProperty
var continent: String { landmark.continent }
@DeferredProperty
var crowdStatus: Int {
get async throws { // swiftlint:disable:this implicit_getter
await modelData.getCrowdStatus(self)
}
}
var landmark: Landmark
var modelData: ModelData
init(landmark: Landmark, modelData: ModelData) {
self.modelData = modelData
self.landmark = landmark
}
}
For more information about describing actions as app intents and app entities, refer to Making actions and
content discoverable and widely available and Creating your first app intent.
Offer interactive snippets
The appʼs “Find Closest” App Shortcut performs an app intent that finds the closest nearby landmark
without opening the app, and allows people to find tickets to visit it. Instead of taking them to the app, the
app intent displays interactive snippets that appear as overlays at the top of the screen. To display the
interactive snippet, the appʼs ClosestLandmarkIntent returns a SnippetIntent that presents the
interactive snippet in its perform() method:
import AppIntents
import SwiftUI
struct ClosestLandmarkIntent: AppIntent {
static let title: LocalizedStringResource = "Find Closest Landmark"
@Dependency var modelData: ModelData
func perform() async throws -> some ReturnsValue<LandmarkEntity> & ShowsSnippetIntent &
let landmark = await self.findClosestLandmark()
return .result(
value: landmark,
dialog: IntentDialog(
full: "The closest landmark is \(landmark.name).",
supporting: "\(landmark.name) is located in \(landmark.continent)."
),
snippetIntent: LandmarkSnippetIntent(landmark: landmark)
)
}
}
For more information about displaying interactive snippets, refer to Displaying static and interactive
snippets.
Make your entity available to Siri and Apple Intelligence
To allow Siri to access the landmark information thatʼs visible onscreen in the app, its LandmarkEntity
implements the Transferable protocol and provides plain-text, image, and PDF representations that Siri
can understand and forward to other services, including third-party services:
extension LandmarkEntity: Transferable {
static var transferRepresentation: some TransferRepresentation {
FileRepresentation(exportedContentType: .pdf) { @MainActor landmark in
let url = URL.documentsDirectory.appending(path: "\(landmark.name).pdf")
let renderer = ImageRenderer(content: VStack {
Image(landmark.landmark.backgroundImageName)
.resizable()
.aspectRatio(contentMode: .fit)
Text(landmark.name)
Text("Continent: \(landmark.continent)")
Text(landmark.description)
}.frame(width: 600))
renderer.render { size, renderer in
var box = CGRect(x: 0, y: 0, width: size.width, height: size.height)
guard let pdf = CGContext(url as CFURL, mediaBox: &box, nil) else {
return
}
pdf.beginPDFPage(nil)
renderer(pdf)
pdf.endPDFPage()
pdf.closePDF()
}
return .init(url)
}
DataRepresentation(exportedContentType: .image) {
try $0.imageRepresentationData
}
DataRepresentation(exportedContentType: .plainText) {
"""
Landmark: \($0.name)
Description: \($0.description)
""".data(using: .utf8)!
}
}
}
When the landmark becomes visible onscreen, the app uses the user activity annotation API to give the
system access to the data:
HStack(alignment: .bottom) {
Text(landmark.name)
.font(.title)
.fontWeight(.bold)
.userActivity(
"com.landmarks.ViewingLandmark"
) {
}
$0.title = "Viewing \(landmark.name)"
$0.appEntityIdentifier = EntityIdentifier(for: try! modelData.landmarkEntity(id: landmark.id
}
For more information about making onscreen content available to Siri and Apple Intelligence, refer to
Making onscreen content available to Siri and Apple Intelligence.
Add entities to the Spotlight index
The app describes its data as app entities, so the system can use it when it performs app intents.
Additionally, the app donates the entities into the semantic search index, making it possible to find the app
entities in Spotlight. The following example shows how the appʼs LandmarkEntity conforms to Indexed
Entity and uses Swift macros to add the indexing keys that Spotlight needs.
struct LandmarkEntity: IndexedEntity {
// ...
// Maps the description to the Spotlight indexing key `contentDescription`.
@ComputedProperty(indexingKey: \.contentDescription)
var description: String { landmark.description }
@ComputedProperty
var continent: String { landmark.continent }
// ...
}
In a utility function, the app donates the landmark entities to the Spotlight index:
static func donateLandmarks(modelData: ModelData) async throws {
let landmarkEntities = await modelData.landmarkEntities
try await CSSearchableIndex.default().indexAppEntities(landmarkEntities)
}
For more information, refer to Making app entities available in Spotlight.
Integrate search results with visual intelligence
With visual intelligence, people circle items onscreen or in visual intelligence camera to search for matching
results across apps that support visual intelligence. To support visual intelligence search, the sample app
implements an IntentValueQuery to find matching landmarks:
@UnionValue
enum VisualSearchResult {
case landmark(LandmarkEntity)
case collection(CollectionEntity)
}
struct LandmarkIntentValueQuery: IntentValueQuery {
@Dependency var modelData: ModelData
func values(for input: SemanticContentDescriptor) async throws -> [VisualSearchResult] {
guard let pixelBuffer: CVReadOnlyPixelBuffer = input.pixelBuffer else {
return []
}
let landmarks = try await modelData.search(matching: pixelBuffer)
return landmarks
}
}
extension ModelData {
/**
This method contains the search functionality that takes the pixel buffer that visual intelligence
and uses it to find matching app entities. To keep this example app easy to understand, this functi
returns the same landmark entity.
*/
func search(matching pixels: CVReadOnlyPixelBuffer) throws -> [VisualSearchResult] {
let landmarks = landmarkEntities.filter {
$0.id != 1005
}.map {
VisualSearchResult.landmark($0)
}.shuffled()
let collections = userCollections
.filter {
$0.landmarks.contains(where: { $0.id == 1005 })
}
.map {
CollectionEntity(collection: $0, modelData: self)
}
.map {
VisualSearchResult.collection($0)
}
return [try! .landmark(landmarkEntity(id: 1005))]
+ collections
+ landmarks
}
}
For more information about integrating your app with visual intelligence, refer to Visual Intelligence.
See Also
Essentials
App Intents updates
Learn about important changes in App Intents.
Making actions and content discoverable and widely available
Adopt App Intents to make your app discoverable with Spotlight, controls, widgets, and the Action
button.
Creating your first app intent
Create your first app intent that makes your app available in system experiences like Spotlight or the
Shortcuts app.
Accelerating app interactions with App Intents
Enable people to use your appʼs features quickly through Siri, Spotlight, and Shortcuts.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Accelerating app interactions with App Intents | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Essentials
App Intents updates
Making actions and content discoverable …
Creating your first app intent
Adopting App Intents to support system e…
Accelerating app interactions with App I…
Siri and Apple Intelligence
Integrating actions with Siri and Apple Int…
Making onscreen content available to Siri …
App intent domains
Making your appʼs functionality available t…
Visual intelligence
Integrating your app with visual intelligence
Visual Intelligence
IntentValueQueryr P
Interactive Snippets
Displaying static and interactive snippets
SnippetIntentr P
Other system experiences
Filter
App Intents / Accelerating app interactions with App Intents
Sample Code
Accelerating app interactions with App
Intents
Enable people to use your appʼs features quickly through Siri, Spotlight, and Shortcuts.
Download
iOS 18.1+ iPadOS 18.1+ macOS 15.1+ visionOS 2.1+ watchOS 11.0+ Xcode 26.0+
/
Overview
The app in this sample code project provides information on trails, allowing people to check on conditions,
search for trails that allow activities like skiing, and record which trails they visit. Expressing these features
as intents allows people to use them through Siri, Spotlight search, and Shortcuts. Additionally, the project
integrates workout tracking on Apple Watch, and shows how to implement Action button support on Apple
Watch Ultra. The intents also appear as actions in the Shortcuts app. People can combine these actions to
build entirely new features in Shortcuts because the intents provide custom data types that match each
otherʼs inputs.
Identify common actions
The sample app includes two key features that people are likely to use frequently: looking up information
on a trail, and recording activity on a trail. To make it easy for people to use these features without even
opening the app, the sample code creates intents for them to use with Siri, Spotlight search, and Shortcuts.
For example, if someone saves their favorite trails in the app and wants to get the current conditions for
those trails, the app implements the OpenFavorites structure, which conforms to AppIntent. When
someone runs this intent, the app opens and navigates to the Favorites view.
/// Each intent needs to include metadata, such as a localized title. The title of the intent displays t
static let title: LocalizedStringResource = "Open Favorite Trails"
/// An intent can optionally provide a localized description that the Shortcuts app displays.
static let description = IntentDescription("Opens the app and goes to your favorite trails."
/// Tell the system to bring the app to the foreground when the intent runs.
static let openAppWhenRun: Bool = true
/**
When the system runs the intent, it calls `perform()`.
Intents run on an arbitrary queue. Intents that manipulate UI need to annotate `perform()` with `@MainA
so that the UI operations run on the main actor.
*/
@MainActor
func perform() async throws -> some IntentResult {
navigationModel.selectedCollection = trailManager.favoritesCollection
/// Return an empty result, indicating that the intent is complete.
return .result()
}
Create App Shortcuts
People may ask Siri to show their favorite trails, or they may find this suggested action through a Spotlight
search. To support both of these options, the app implements an AppShortcut using OpenFavorites.
An App Shortcut combines an intent with phrases people may use with Siri to perform the action, and
additional metadata, such as an icon, and then uses this information in a Spotlight search. People can
invoke the App Shortcut with a suggested phrase, or other similiar words, because the system uses a
semantic similarity index to help identify peopleʼs requests — automatically matching phrases that are
similar, but not identical.
AppShortcut(intent: OpenFavorites(), phrases: [
"Open Favorites in \(.applicationName)"
,
"Show my favorite \(.applicationName)"
],
shortTitle: "Open Favorites",
systemImageName: "star.circle")
To register the App Shortcut with the system, the app calls updateAppShortcutParameters on its App
ShortcutsProvider during the init of the App structure.
To aid the systemʼs presentation of the App Shortcut, the sample app includes a short title and an SF
Symbols name that represent the App Shortcut. Further, the sample appʼs Info.plist file declares
NSAppIconActionTintColorName with the appʼs primary color and two contrasting colors in an array
for the NSAppIconComplementingColorNames key. The system uses these colors when displaying the
App Shortcuts, such as in Spotlight or the Shortcuts app. The specified values of the color names for these
keys come from the appʼs asset catalog.
After registering an App Shortcut with the system, people can begin using the intent through Siri without
any further configuration. To teach people a phrase to use the intent, the app provides a SiriTipView in
the associated view.
SiriTipView(intent: OpenFavorites(), isVisible: $displaySiriTip)
The SiriTipView takes a binding to a visibility Boolean so that the app hides the view if an individual
chooses to dismiss it.
Aside from intents for people to quickly view their favorite trails and track their workouts, the sample app
provides extensive search capabilities through intents. The app doesnʼt provide App Shortcuts for intents
that people use less commonly. Best practice is to provide App Shortcuts for only the most common
actions in an app — usually between two and five intents, and not more than ten.
Design custom responses
Even though the app doesnʼt provide GetTrailInfo as an App Shortcut, people may still interact with it
through Siri, such as including the intent in a shortcut they create in the Shortcuts app. For a good user
experience, this intent provides its result with a visual response using a custom UI snippet, and as a dialog
for Siri to communicate the same information. It does so by conforming the return type of the intentʼs
perform function to both ProvidesDialog and ShowsSnippetView.
func perform() async throws -> some IntentResult & ReturnsValue<TrailEntity> & ProvidesDialog
The app provides both visual experiences and voice-only experiences because people may be in a context
where they canʼt see information in a custom UI (such as when the intent runs on HomePod), or when
displaying the custom UI may be inappropriate (such as when the intent runs through CarPlay). This
implementation provides a custom UI with a shorter supporting dialog to use when the custom UI is visible,
and a different dialog containing additional information if the system canʼt show the snippet. The sample
uses a transparent background for the custom UI because the system displays it over a translucent
background material. Avoiding opaque backgrounds provides the best results.
let snippet = TrailInfoView(trail: trailData, includeConditions: true)
/**
This intent displays a custom view that includes the trail conditions as part of the view. The dialog i
the system can only read the response, but not display it. When the system can display the response, th
conditions.
*/
let dialog = IntentDialog(full: "The latest reported conditions for \(trail.name) indicate:
supporting: "Here's the latest information on trail conditions.")
return .result(value: trail, dialog: dialog, view: snippet)
This sample app provides custom dialog throughout its intents. SuggestTrails validates the parameters
that people provide and uses the custom dialog to prompt them for additional information. For example, if
the provided location parameter isnʼt specific enough, the intent prompts the individual to choose from a
list of locations related to their input. The app does this by throwing needsDisambiguationError with
a value for the dialog parameter.
let dialog = IntentDialog("Multiple locations match \(location). Did you mean one of these locations?"
let disambiguationList = suggestedMatches.sorted(using: KeyPathComparator(\.self, comparator: .localized
throw $location.needsDisambiguationError(among: disambiguationList, dialog: dialog)
Add parameters to an intent
An app intent can optionally require certain parameters to complete its action. For example, the GetTrail
Info intent declares a trail parameter by decorating the property with the IntentParameter
property wrapper.
@Parameter(title: "Trail", description: "The trail to get information for.")
var trail: TrailEntity
The system supports parameters using common Foundation types, such as String, and those for custom
data types in an app. The app makes its trail data available in an app intent through the TrailEntity
type, which is a structure conforming to the AppEntity protocol.
To allow the system to query the app for TrailEntity data, the entity implements the Identifiable
protocol with values that are stable and persistent. TrailEntity declares defaultQuery, which the
system uses to perform queries to receive TrailEntity structures.
static let defaultQuery = TrailEntityQuery()
An AppEntity makes its properties available to the system by decorating it with the EntityProperty
property wrapper.
/**
The trail's name. The `EntityProperty` property wrapper makes this property's data available to the sys
such as when an intent returns a trail in a shortcut.
The system automatically generates the title for this property from the variable name when it displays
Generated titles are available for both `EntityProperty` and `IntentIntentParameter` property wrappers.
*/
@Property var name: String
/**
A description of the trail's location, such as a nearby city name, or the national park encompassing it
If you want the displayed title for the property to be different from the variable name, use a `title`
`EntityProperty` property wrapper.
*/
@Property(title: "Region")
var regionDescription: String
Provide the appʼs data through queries
The system queries the app for its trail data through TrailEntityQuery, a type conforming to Entity
Query. For example, if someone saves a specific value as the trail parameter for GetTrailInfo, the
system locates the TrailEntity by using the defaultQuery and requesting the entity by its ID from
the Identifable protocol. All types conforming to EntityQuery need to implement this method.
func entities(for identifiers: [TrailEntity.ID]) async throws -> [TrailEntity] {
Logger.entityQueryLogging.debug("[TrailEntityQuery] Query for IDs \(identifiers)")
return trailManager.trails(with: identifiers)
.map { TrailEntity(trail: $0) }
}
The app also provides a list of common trail suggestions by implementing the optional suggested
Entities function.
func suggestedEntities() async throws -> [TrailEntity] {
Logger.entityQueryLogging.debug("[TrailEntityQuery] Request for suggested entities")
return trailManager.trails(with: trailManager.favoritesCollection.members)
.map { TrailEntity(trail: $0) }
}
There are several subprotocols to EntityQuery, each of which enables different types of functionality.
The sample app implements all of them for demonstration purposes, but a real app can use only the ones
that meet its needs.
The app implements EntityStringQuery to help people configure GetTrailInfo. When people
configure this intent in the Shortcuts app, they first see the list of trails from suggestedEntities. The
Shortcuts app provides a search field, enabling people to search for results that appear in the list of
suggested trails. The app provides results for the search term by implementing entities(matching:).
func entities(matching string: String) async throws -> [TrailEntity] {
Logger.entityQueryLogging.debug("[TrailEntityQuery] String query for term \(string)")
return trailManager.trails { trail in
trail.name.localizedCaseInsensitiveContains(string)
}.map { TrailEntity(trail: $0) }
}
Enable Find intents
Apps implementing either the EnumerableEntityQuery or the EntityPropertyQuery protocol
automatically add a Find intent in the Shortcuts app. These intents enable people to build powerful new
features for themselves in Shortcuts, powered by the appʼs data — without requiring the app to implement
that feature itself. For example, the sample app focuses its UI on providing trail information, but people can
also use its data to plan activities for a vacation. The app doesnʼt need to build vacation-planning features
because it implements these entity query protocols to provide an interface to the data through a Shortcut.
The sample app groups trails into collections based on geographic region, and implements the collections
as a type called TrailCollection that conforms to AppEntity. The list of geographic regions is small,
and a TrailCollection is a simple structure with the collection name and a list of trail IDs that require
little memory. To make this information available through a Find intent, the app implements Featured
CollectionEntityQuery with conformance to EnumerableEntityQuery. The app uses
EnumerableEntityQuery here because the data for the featured trail collections is a small and fixed set
of values, and doesnʼt require a large amount of memory. The app implements allEntities to return all
of the values, which people can filter by name in the Shortcuts app.
func allEntities() async throws -> [TrailCollection] {
Logger.entityQueryLogging.debug("[FeaturedCollectionEntityQuery] Request for all entities"
return trailManager.featuredTrailCollections
}
The app also implements EntityPropertyQuery for TrailEntity. This query type is ideal for large
data sets that may have large numbers of entities, or entities that have higher memory consumption.
Implementing this query adds a Find intent to the Shortcuts app, enabling people to run predicate searches
on entity properties. For example, someone planning a vacation around seeing waterfalls that are easily
accessible can configure the Find intent with criteria for trails containing fall in the trail name, and a trail
distance of less than 1 kilometer. An implementation of EntityPropertyQuery includes several required
functions and properties. TrailEntityQuery+PropertyQuery.swift contains the complete
implementation.
Designing great intents for integration with the system means that the intents work as standalone intents
with their parameters, and also work with other intents the app provides, or with other apps that may be
installed. People can create shortcuts that use the output of one intent the app provides and use it as input
to another intent the app provides, like the following examples:
SuggestTrails can use the output of the Find intent for trail collections as input.
The Find intent for trails can use the output of SuggestTrails to further refine the results.
The Find intent for trails can also work alone, searching for matching trail properties from all of the trail
data the app provides.
Contribute entities to Spotlight
The sample app provides its trail data to Spotlight when the app first runs. The app declares a Trail
structure for this data, containing the appʼs internal representation of that data. The app maps its data from
the structure to searchable attributes in a CSSearchableItemAttributeSet.
var searchableAttributes: CSSearchableItemAttributeSet {
let attributes = CSSearchableItemAttributeSet()
attributes.title = name
attributes.namedLocation = regionDescription
attributes.keywords = activities.localizedElements
attributes.latitude = NSNumber(value: coordinate.latitude)
attributes.longitude = NSNumber(value: coordinate.longitude)
attributes.supportsNavigation = true
return attributes
}
The app also declares a TrailEntity structure to make the trail data available to the rest of the system
as part of its App Intents integration. To integrate TrailEntity with Spotlight, TrailEntity conforms
to IndexedEntity. The app associates the searchable attributes from the Trail structure with the
TrailEntity by calling associateAppEntity(_:priority:) before contributing the data to the
Spotlight index.
// Create an array of the searchable information for each `Trail`.
let searchableItems = trails.map { trail in
let item = CSSearchableItem(uniqueIdentifier: String(trail.id),
domainIdentifier: nil,
attributeSet: trail.searchableAttributes)
let isFavorite = favoritesCollection.members.contains(trail.id)
let weight = isFavorite ? 10 : 1
let intent = TrailEntity(trail: trail)
/**
Associate `TrailEntity` with the data that the `Trail` structure provides so the system recognizes
both types represent the same data. You need to create this association before adding the `CSSearch
to a `CSSearchableIndex`.
*/
item.associateAppEntity(intent, priority: weight)
return item
}
do {
// Add the trails to the search index so people can find them through Spotlight.
// You need to do this as part of the app's initial setup on launch.
let index = CSSearchableIndex.default()
try await index.indexSearchableItems(searchableItems)
Logger.spotlightLogging.info("[Spotlight] Trails indexed by Spotlight")
} catch let error {
Logger.spotlightLogging.error("[Spotlight] Trails were not indexed by Spotlight. Reason:
}
Integrate universal links
The sample app offers an OpenTrail intent so that people can open the app to a specific trailʼs
information from a shortcut. Rather than adding code to configure the appʼs UI for displaying a trailʼs
information just for this intent, the app uses the same URL scheme it uses to implement universal links. The
app declares the URL for a trailʼs details through conformance to URLRepresentableEntity.
extension TrailEntity: URLRepresentableEntity {
static var urlRepresentation: URLRepresentation {
// Use string interpolation to fill values from your entity necessary for constructing the unive
// This example URL uses the unique and persistant identifier for the `TrailEntity` in the URL.
"https://example.com/trail/\(.id)/details"
}
}
To leverage the appʼs existing code for handling a universal link, the app conforms the OpenTrail intent
to both OpenIntent and URLRepresentableIntent. These conformances allow the app to skip
implementing a perform() method on OpenTrail. When the intent runs, the system automatically
passes the URL to the app using the standard mechanisms required for handling universal links.
See Also
Essentials
App Intents updates
Learn about important changes in App Intents.
Making actions and content discoverable and widely available
Adopt App Intents to make your app discoverable with Spotlight, controls, widgets, and the Action
button.
Creating your first app intent
Create your first app intent that makes your app available in system experiences like Spotlight or the
Shortcuts app.
Adopting App Intents to support system experiences
Create app intents and entities to incorporate system experiences such as Spotlight, visual
intelligence, and Shortcuts.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Adding shared content collaboration to your app | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
Shared with You / Adding shared content collaboration to your app
Article
Adding shared content collaboration to your app
Manage shared content collaboration in your app using CloudKit and iCloud Drive.
Overview
Your app can create collaborations and share content in a Messages conversation by leveraging CloudKit and iCloud
Drive to create and store content on the server. Collaborators add a document to conversations by sharing content
using Messages. The system displays collaboration activity in Messages conversations and in active FaceTime calls.
This collaboration process builds on existing technologies, like drag and drop and the system share sheet. If your app
doesnʼt use iCloud for shared content, the Shared with You framework provides an SWCollaborationMetadata
object wrapped in NSItemProvider to implement a custom collaboration infrastructure.
Create a collaboration object
If your app is sharing a file URL using iCloud Drive, that URL is your collaboration object. To manage a CloudKit
collaboration, your app uses NSItemProvider to register a CKShare container and create a collaboration object. The
system transports your appʼs data to other processes using the CKShare container.
Your app gives an existing CKShare to the collaboration object or provides a preparation handler to create a CKShare
when collaboration starts. In the example below, your app starts a new collaboration and creates the CKShare
container.
// Create a new collaboration object.
let itemProvider = NSItemProvider()
itemProvider.registerCKShare(container: container, allowedSharingOptions: CKAllowedSharingOptions.standard, preparationHandler: {
// Create your share and save to the server or throw an error.
return savedShare
})
For an existing collaboration, your app retrieves the existing collaboration object from the server.
// Retrieve an existing collaboration object.
let itemProvider = NSItemProvider()
itemProvider.registerCKShare(share, container: container, allowedSharingOptions: CKAllowedSharingOptions
Present collaboration controls
A collaborator can modify the share options from the share sheet. To add the collaboration controls to the header of a
share sheet, your app provides the collaboration object that it created or retrieved from the server.
// Present a share sheet in iOS.
let activityViewController = UIActivityViewController(activityItems: [collaborationObject], applicationActivities:
presentingViewController.present(activityViewController, animated: true)
In macOS, a share popover offers similar options to the iOS share sheet.
// Present a share popover in macOS.
let sharingServicePicker = NSSharingServicePicker(items: [collaborationObject])
sharingServicePicker.show(relativeTo: view.bounds, of: view, preferredEdge: .minY)
Provide a title and image for the collaboration header
If your app provides a file as shared data, the system automatically populates a title and image for the collaboration
header in the share sheet. Otherwise, if your app uses CloudKit data as shared content, or if youʼd like to override the
default title and image, you can provide a title and image for the collaboration header.
In iOS, create a UIActivityItemsConfiguration with a title and image that your app passes to a UIActivity
ViewController.
// Provide CloudKit metadata in iOS.
let configuration = UIActivityItemsConfiguration(itemProviders: [collaborationItemProvider])
configuration.perItemMetadataProvider = { (
_, key) in
switch key {
case .linkPresentationMetadata:
// Create LPLinkMetadata with the title and imageProvider.
return metadata
default:
return nil
}
}
let activityViewController = UIActivityViewController(activityItemsConfiguration: configuration)
In macOS, create an NSPreviewRepresentingActivityItem with a title, image, and icon that your app passes to
an NSSharingServicePicker. The image represents the shared content, and the icon represents the source of the
shared content.
// Provide CloudKit metadata in macOS.
let title = “Shared Item”
let image = NSImage(contentsOfFile: “Shared_Item_Preview_Image.png”)
let icon = NSImage(contentsOfFile: “App_Icon.png”)
let previewRepresentingItem = NSPreviewRepresentingActivityItem(item: collaborationItemProvider, title: title, image: image, icon: icon)
let picker = NSSharingServicePicker(items: [previewRepresentingItem])
Create a SwiftUI transferable object for collaboration through ShareLink
In SwiftUI, use ShareLink to support collaboration mode in the share sheet. The object your app shares must adopt
Transferable, a protocol for sharing and data transfer.
In the example below, a structure provides a CKShareTransferRepresentation by either returning an existing
CKShare or creating a new one.
// Create a SwiftUI Transferable object.
struct Note: Transferable {
var share: CKShare?
func saveCKShareToServer() async throws -> CKShare { … }
static var transferRepresentation: some TransferRepresentation {
CKShareTransferRepresentation { note in
if let share = note.share {
return .existing(share, container: container, options: options)
} else {
return .prepareShare(container: container, options: options) {
return try await note.saveCKShareToServer()
}
}
}
}
}
If your app is sharing a file URL using iCloud Drive, that URL is the Transferable object shared through ShareLink.
Once your app creates a Transferable object, pass it to ShareLink. When your app shares a URL or string, the
system automatically creates a preview. Optionally, your app can include a SharePreview object, which the system
uses to display the title and image for the preview.
// Adopt a SwiftUI ShareLink.
struct ContentView: View {
// SharedPhoto() returns an object that conforms to the Transferable protocol.
@State let photo = SharedPhoto()
var body: some View {
ShareLink(item: photo, preview: SharePreview(photo.title, image: photo.image))
}
}
Initialize the collaboration view
A collaborator accesses the SWCollaborationView using an icon in the navigation bar. This icon shows the app that
manages the shared content and the number of collaborators associated with the collaboration.
The system handles the layout and formatting of the collaboration view. Your app is responsible for providing the item
Provider(_:) and the activeParticipantCount. The NSItemProvider contains the CKShare for CloudKit-
based apps, the file URL for iCloud Drive-based apps, or the /SharedWithYouCore/SWCollaboration
Metadata/Representation for custom collaboration infrastructures.
// Initialize the collaboration view.
let collaborationView = SWCollaborationView(itemProvider: itemProvider)
collaborationView.activeParticipantCount = myModel.activePeople.count
To add a completely customized view on the collaboration view, your app creates a view and assigns it to the content
View.
collaborationView.contentView = MyView(model: myModel)
For CloudKit and iCloud Drive adopters, the collaboration view includes a manage button. The button brings up the
manage user interface, where collaborators can add and remove participants or change the share settings. Your app can
also assign a custom title to the manageButtonTitle. The title defaults to “Manage Share” if your app doesnʼt
customize it.
collaborationView.manageButtonTitle = "Custom Manage Button"
If your app uses a custom collaboration infrastructure, you must provide your own manage button.
Observe when a server saves a share
Since your app needs to manage active content sharing, itʼs critical to know when a share starts or stops. If your app
uses CloudKit or iCloud Drive, Shared with You provides a CKSystemSharingUIObserver protocol that your app
uses to observe and handle updates to collaborations.
First, your app passes a CKContainer to CKSystemSharingUIObserver to create an observer.
let observer = CKSystemSharingUIObserver(container: container)
Then use the systemSharingUIDidSaveShareBlock in that observer to capture and react to the result of the
server-side save of the share.
observer.systemSharingUIDidSaveShareBlock = {
_, result in
switch result {
case .success(let share):
// Handle the successful save of a share.
case .failure(let error):
// Handle the error for an unsuccessful save.
}
}
Use the systemSharingUIDidStopSharingBlock in that same observer to handle when a share stops.
observer.systemSharingUIDidStopSharingBlock = {
switch result {
case .success(let share):
// Handle the successful share deletion.
case .failure(let error):
// Handle the error when a deletion fails.
_, result in
}
}
Post notices for shared content collaboration
Your app can post notices to summarize updates to a collaboration. These notices appear at the top of the related
Messages thread. These updates include changes to the shared content, new mentions, server-side changes, and
updates to the collaborators.
To post a notice, retrieve the SWCollaborationHighlight and use it to create an SWHighlightEvent that
matches the type of update.
Use SWHighlightChangeEvent to post a notice about content updates or comments. Use SWHighlightCenter to
retrieve a collaboration highlight with the URL of the CKShare your app used to initiate the collaboration.
// Retrieve the collaboration highlight from the highlight center.
let highlightCenter: SWHighlightCenter = self.highlightCenter
let highlight = try highlightCenter.collaborationHighlight(forURL: ckShareURL, error: &error)
Next, create an SWHighlightChangeEvent instance. The initializer takes an SWHighlight object and an
SWHighlightChangeEventTrigger value. In this case, the app sets the trigger type to SWHighlightChange
EventTrigger.edit. Lastly, post the notice for that event to the highlight center.
// Post a change event notice.
let editEvent = SWHighlightChangeEvent(highlight: highlight, trigger: .edit)
highlightCenter.postNotice(for: editEvent)
Post a persistence event notice
Use the SWHighlightPersistenceEvent to post a notice when your app moves, renames, or deletes content on the
server. In the example below, the SWHighlightPersistenceEventTrigger.renamed trigger type signifies the
document name has changed.
// Post a persistence event notice that shows your app renamed a document.
let renamedEvent = SWHighlightPersistenceEvent(highlight: highlight, trigger: .renamed)
highlightCenter.postNotice(for: renamedEvent)
Post a membership event notice
When your app alters the membership for a collaboration and triggers a membership event, the system posts an update
to the collaborators.
After your app retrieves the highlight, create the membership event by passing in the retrieved highlight. Use either
SWHighlightMembershipEventTrigger.addedCollaborator or SWHighlightMembershipEventTrigger
.removedCollaborator as the trigger for the SWHighlightMembershipEvent.
// Post a membership event notice that shows your app added a collaborator.
let membershipEvent = SWHighlightMembershipEvent(highlight: highlight, trigger: .addedCollaborator)
highlightCenter.postNotice(for: membershipEvent)
If the membership of a Messages group changes, Shared with You keeps collaborators on your shared documents in
sync. For CloudKit and iCloud Drive, your app doesnʼt have to do anything.
When a person adds someone new to a Messages conversation for a collaboration, the system prompts the document
owner in Messages to add them to the share. When a person removes someone from a Messages conversation, the
system prompts the document owner in Messages to remove them from the share.
See Also
Collaboration
Adding custom collaboration to your app
Integrate your custom collaboration app with Messages.
Collaboration views
Create and customize a collaboration view to manage the shared content actions.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Action button on iPhone and Apple Watch | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Action button on iPhone and Apple Watch
Responding to the Action button
Responding to the Action button on Ap…
StartWorkoutIntentr P
PauseWorkoutIntentr P
ResumeWorkoutIntentr P
StartDiveIntentr P
S
ConfirmationActionName
Launching your voice-based conversation…
Developing a WidgetKit strategy
SiriKit migration
Soup Chef with App Intents: Migrating cu…
Actions
App intents
Intent discovery
App Shortcuts
Parameters, custom data types, and queries
Adding parameters to an app intent
Integrating custom data types into your in…
Filter
App Intents / Action button on iPhone and Apple Watch
API Collection
Action button on iPhone and Apple Watch
Enable people to run your App Shortcuts with the Action button on iPhone or to start your
appʼs workout or dive sessions using the Action button on Apple Watch.
Overview
On supported iPhone models, people can choose a single App Shortcut to perform an appʼs action when
they press the Action button by selecting an App Shortcut in Settings > Action button. To give users quick
access to your appʼs functionality, create App Shortcuts for your high-value app intents using the
init(intent:phrases:shortTitle:systemImageName:) or init(intent:phrases:short
Title:systemImageName:parameterPresentation:) initializer. For additional information, see
App Shortcuts.
On supported Apple Watch models, people can choose to start workout or dive session using the Action
button in Settings > Action Button. To add your app to the list of available workout or dive apps, implement
an App Intent that adopts the StartWorkoutIntent or StartDiveIntent protocol. For more
information, see Responding to the Action button on Apple Watch Ultra.
For design guidance, see Human Interface Guidelines > App Shortcuts and Human Interface Guidelines >
Action button.
/
Topics
Responding to the Action button
Responding to the Action button on Apple Watch Ultra
Use App Intents to register actions for your app.
protocol StartWorkoutIntent
An App Intent for starting a workout.
protocol PauseWorkoutIntent
An App Intent that lets someone pause your appʼs current workout session.
protocol ResumeWorkoutIntent
An App Intent that lets someone resume your appʼs paused workout session.
protocol StartDiveIntent
An App Intent that lets people start a dive session when they press the Action button on Apple Watch
Ultra.
struct ConfirmationActionName
See Also
Other system experiences
Making app entities available in Spotlight
Allow people to find your appʼs content in Spotlight by donating app entities to its semantic index.
Focus
Adjust your appʼs behavior and filter incoming notifications when the current Focus changes.
Launching your voice-based conversational app from the side button of iPhone
Let people in Japan configure the side button of iPhone to launch your voice-based conversational
app.
Developing a WidgetKit strategy
Explore features, tasks, related frameworks, and constraints as you make a plan to implement
widgets, controls, watch complications, and Live Activities.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Soup Chef with App Intents: Migrating custom intents | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
SiriKit
Frameworks
Intents
IntentsUI
Sample code
Adding Shortcuts for Wind Down
Booking Rides with SiriKit
Handling Payment Requests with SiriKit
Handling Workout Requests with SiriKit
Integrating Your App with Siri Event Sugg…
Managing Audio with SiriKit
Providing Hands-Free App Control with In…
Soup Chef: Accelerating App Interactions …
Soup Chef with App Intents: Migrating c…
Articles
Adding User Interactivity with Siri Shortcu…
Defining Relevant Shortcuts for… Deprecated
Deleting Donated Shortcuts
Dispatching intents to handlers
Improving Siri Media Interactions and App…
Filter
SiriKit / Soup Chef with App Intents: Migrating custom intents
Sample Code
Soup Chef with App Intents: Migrating custom
intents
Integrating App Intents to provide your appʼs actions to Siri and Shortcuts.
Download
iOS 14.3+ iPadOS 14.3+ Mac Catalyst 14.3+ Xcode 17.0+
/
Overview
This version of Soup Chef highlights the changes required to migrate from a custom intent to App Intents. It
modifies the existing Soup Chef sample to add support for AppIntents, AppEntities, and App Shortcuts as
described in Migrate Custom Intents to App Intents.
Configure the sample code project
Before you can run Soup Chef, you need to:
C. Set the app group name for the SoupChef, SoupChefIntents, SoupChefWatchExtension, and
SoupChefIntentsWatch targets to a valid name. For more information on App Groups, see Configure App
Groups.
G. Change the value of AppGroup in UserDefaults+DataSource.swift to match your app group name.
Share code between the app and app extension
The Soup Chef project contains targets for an app and an Intents app extension, which the system uses to
handle shortcuts that run in the background. To avoid duplicating code that is common across the two
targets, the project includes a shared framework called SoupKit. This framework provides a central location
for shared code responsible for tasks such as data management and donating shortcuts. For more
information about structuring code, see Structuring Your Code to Support App Extensions.
Convert the intent definition
The intent definitions, which define the custom intents, are recreated as their respective AppIntent
representation using the “Convert to AppIntents” button in the intent definition file. The new intent files,
located in the App Intent Group of the project, each have an autogenerated structure and implement the
CustomIntentMigratedAppIntent protocol. Each parameter of the custom intent represents an AppEntity
structure.
struct OrderSoup: AppIntent, CustomIntentMigratedAppIntent {
Implement queries
Each of the four parameters for the OrderSoupIntent have their respective AppEntity representation.
The SoupAppEntity and ToppingAppEntity use the existing data manager to resolve the entity
values. Additionally, apps can also resolve entities by string or UUID. The full list of entities the person sees
when they tap the parameter in the Shortcuts app can also show by returning a collection of entities in the
suggestedEntities() implementation. OrderType has a representation as AppEnum, and Order
Details is represented as a TransientAppEntity because it doesnʼt have unique identifier.
func suggestedEntities() async throws -> IntentItemCollection<SoupAppEntity> {
let soupMenuManager = SoupMenuManager()
// Only adopt `EntityStringQuery` for searching large catalogs, not for small static collect
// The Shortcuts app supports filtering of small collections by default.
let availableRegularItems = soupMenuManager.findItems(exactlyMatching: [.available, .regular
let availableDailySpecialItems = soupMenuManager.findItems(exactlyMatching: [.available, .da
return ItemCollection {
ItemSection<SoupAppEntity>(
items:
availableRegularItems .map {
IntentItem<SoupAppEntity>(
SoupAppEntity($0),
title: SoupAppEntity($0).localizedStringResource,
image: SoupAppEntity($0).displayRepresentation.image)
}
)
ItemSection<SoupAppEntity>(
title: "Specials",
items: availableDailySpecialItems .map {
IntentItem<SoupAppEntity>(
SoupAppEntity($0),
title: SoupAppEntity($0).localizedStringResource,
image: SoupAppEntity($0).displayRepresentation.image)
}
)
}
}
Replace custom intents with App Intents
The Perform method in AppIntents subsumes the resolve, confirm, and handle functionality that was
required with custom Intents. Entities declared in an App Intent can be optional or required. The entity type
and query implementation help to resolve their values automatically in App Intents. Handling cases where
user input requires confirmation or needs new value are handled explicitly within the Perform function.
For example, confirming the order before placing it, or requesting a delivery location arenʼt provided. The
Perform method handles the final execution and returns an intent result which can be the dialog that
needs to be spoken as well as the snippet that is shown onscreen to the person.
The following is an example of how to resolve Topping using an Entity Query:
func entities(matching string: String) async throws -> [ToppingAppEntity] {
let menuItemTopping = Order.MenuItemTopping.allCases.filter { $0.rawValue == string }
let result = menuItemTopping.map { (topping) -> ToppingAppEntity in
return ToppingAppEntity(
id: topping.rawValue, displayString: topping.localizedName(useDeferredIntentLocaliza
}
return result
}
The following is an example of how to validate quantity values and returning results in perform method:
func perform() async throws -> some ProvidesDialog & ShowsSnippetView {
if quantity > menuItem[0].itemsInStock {
let errorPrompt = OrderSoupError.notEnoughInStock(quantity ).localizedStringResource
return .result(value: OrderDetailsAppEntity(), dialog: IntentDialog
}
Provide dynamic options
The storeLocations parameter has a backing by a DynamicOptionsProvider that returns all store
locations directly in results method.
@available(iOS 16.0, macOS 13.0, watchOS 9.0, tvOS 16.0, *)
struct SoupChefAppShortcutsProvider: AppShortcutsProvider {
static var appShortcuts: [AppShortcut] {
AppShortcut(
intent: OrderSoup(),
phrases: [
"Order \(.applicationName)"
,
"Order \(\.$soup) from \(.applicationName)"
],
shortTitle: "Order Soup"
)
}
static var shortcutTileColor: ShortcutTileColor = .orange
}
App Shortcut provider and localization
To make the Intent easier to discover, this version of Soup Chef implement AppShortcuts that allow the
Intent to automatically appear in the Shortcut app. To aid with localization of AppShortcuts, use App
Shortcuts.strings to add support for other locales.
"TOMATO_SOUP" = "Tomato Soup";
"NE_CLAM_CHOWDER" = "New England Clam Chowder";
"CHICKEN_NOODLE_SOUP" = "Chicken Noodle Soup";
See Also
Sample code
Adding Shortcuts for Wind Down
Reveal your appʼs shortcuts inside the Health app.
Booking Rides with SiriKit
Add Intents extensions to your app to handle requests to book rides using Siri and Maps.
Handling Payment Requests with SiriKit
Add an Intent Extension to your app to handle money transfer requests with Siri.
Handling Workout Requests with SiriKit
Add an Intent Extension to your app that handles requests to control workouts with Siri.
Integrating Your App with Siri Event Suggestions
Donate reservations and provide quick access to event details throughout the system.
Managing Audio with SiriKit
Control audio playback and handle requests to add media using SiriKit Media Intents.
Providing Hands-Free App Control with Intents
Resolve, confirm, and handle intents without an extension.
Soup Chef: Accelerating App Interactions with Shortcuts
Make it easy for people to use Siri with your app by providing shortcuts to your appʼs actions.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Making app entities available in Spotlight | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Making app entities available in Spotlight
Focus
Action button on iPhone and Apple Watch
Launching your voice-based conversation…
Developing a WidgetKit strategy
SiriKit migration
Soup Chef with App Intents: Migrating cu…
Actions
App intents
Intent discovery
App Shortcuts
Parameters, custom data types, and queries
Adding parameters to an app intent
Integrating custom data types into your in…
Parameter resolution
App entities
Entity queries
Resolvers
Utility types
Filter
App Intents / Making app entities available in Spotlight
Article
Making app entities available in Spotlight
Allow people to find your appʼs content in Spotlight by donating app entities to its
semantic index.
/
Overview
With Spotlight, people access information from within apps and the web, and use it to launch apps and
perform actions. When you adopt the App Intents framework and create App Shortcuts, people can
perform your appʼs actions from Spotlight. Additionally, you can donate your AppEntity objects to
Spotlight, allowing people to find your content and launch your app to view more information. For example,
people might search nearby landmarks in Spotlight, find a travel appʼs content, and tap it to launch the app
for detailed information.
Create an intent that displays your entity in your app
When an app entity appears in Spotlight, people can tap it to open your app to the scene that shows
detailed information matching the entity. For example, the Adopting App Intents to support system
experiences sample app makes landmarks available to Spotlight. When someone taps a landmark in
Spotlight, the app opens to display detailed information about that landmark.
For each entity type that you want to make available to Spotlight, create an app intent that conforms to
OpenIntent and takes the entity as a parameter, as in the following example:
import AppIntents
struct OpenLandmarkIntent: OpenIntent {
static let title: LocalizedStringResource = "Open Landmark"
@Parameter(title: "Landmark", requestValueDialog: "Which landmark?")
var target: LandmarkEntity
}
Make your app entity indexable
To donate your app entities to the semantic index of Spotlight, they need to conform to the Indexed
Entity protocol. For example, the sample app for Adopting App Intents to support system experiences
extends its LandmarkEntity to add the protocol conformance.
struct LandmarkEntity: IndexedEntity {
// ...
}
By stating that your entity conforms to IndexedEntity, you can then donate it to Spotlight. By default,
the title, subtitle, and image of the entityʼs DisplayRepresentation become indexed attributes in
Spotlight, and Spotlight shows your entity if a search matches one of those attributes.
However, your entity likely contains additional information that you want to be searchable and findable in
Spotlight. To declare additional attributes that are searchable in Spotlight, implement a custom attribute set
for your entity:
Use the @Property or @ComputedProperty Swift property wrappers to add your entityʼs variables to
the Spotlight index.
In iOS 18, provide an attributeSet for your indexed entities that contains attributes for Spotlight
indexing.
If you already use Core Spotlight, associate your app entities with a matching CSSearchableItem.
For more information about each option, refer to the applicable section below.
Mark your entityʼs variables as indexable properties
The system can automatically extract the keys for Spotlight indexing at compile time and store them in the
App Intents metadata that Xcode generates as part of your appʼs bundle. As a result, Spotlight indexing is
faster and can find your app entities without launching your app, and without you having to explicitly
donate the entities to Spotlight. You also donʼt need to manually update or remove entities from the
Spotlight index when your appʼs data changes.
To add your indexed entityʼs variables to the Spotlight index, use the @Property or @Computed
Property Swift macro as follows:
Map the indexed entityʼs variable to an indexing key that CSSearchableItemAttributeSet defines,
and use @ComputedProperty(indexingKey: or @Property(indexingKey:).
If an indexed entityʼs variable doesnʼt fit any of the indexing keys that CSSearchableItemAttribute
Set defines, use @ComputedProperty(customIndexingKey:) or @Property(customIndexing
Key:) to match the variable to a custom Spotlight indexing key.
Note
If your app entities conform to a schema and domain in App intent domains, donate them to the
system without defining an indexing key mapping. Entities that conform to a schema use a fixed shape
that maps to Spotlight indexing keys. You canʼt provide your own mapping for its variables.
The following example shows how the LandmarkEntity of the Adopting App Intents to support system
experiences sample app uses the different @ComputedProperty Swift macros to the entityʼs variables as
searchable attributes to the Spotlight index:
struct LandmarkEntity: IndexedEntity {
// ...
// Maps the description variable to the Spotlight indexing key `contentDescription`.
@ComputedProperty(indexingKey: \.contentDescription)
var description: String { landmark.description }
// Maps the continent variable to a custom Spotlight indexing key.
@ComputedProperty(
customIndexingKey: CSCustomAttributeKey(
keyName: "com_AppIntentsTravelTracking_LandmarkEntity_continent"
)!
)
var continent: String { landmark.continent }
// ...
}
On app launch, donate your app entities to the Spotlight index using CSSearchableIndex and its index
AppEntities(_:priority:).
The following example shows the implementation of the donation in the AppIntentsTravelTracking
app:
import AppIntents
import CoreSpotlight
enum EntityDonator {
static func donateLandmarks(modelData: ModelData) async throws {
let landmarkEntities = await modelData.landmarkEntities
try await CSSearchableIndex.default().indexAppEntities(landmarkEntities)
}
}
If your appʼs data changes, delete app entities that no longer exist from the Spotlight index using delete
AppEntities(identifiedBy:ofType:) or deleteAppEntities(ofType:).
Implement the optional searchable attribute set for your indexed
entity
In iOS 18, you canʼt donate your app entities and their attributes to the Spotlight index using the
@ComputedProperty or @Property Swift macros. Instead, your app entity needs to provide the
attributeSet property. You need to manually donate each entity to the index, and then update the index
when your data changes.
The following example shows how the sample app for Accelerating app interactions with App Intents
creates the CSSearchableItemAttributeSet:
var searchableAttributes: CSSearchableItemAttributeSet {
let attributes = CSSearchableItemAttributeSet()
attributes.title = name
attributes.namedLocation = regionDescription
attributes.keywords = activities.localizedElements
attributes.latitude = NSNumber(value: coordinate.latitude)
attributes.longitude = NSNumber(value: coordinate.longitude)
attributes.supportsNavigation = true
return attributes
}
On launch of your app, add your entities to the Spotlight index using CSSearchableIndex and its index
AppEntities(_:priority:). If your appʼs data changes, delete app entities that no longer exist from
the Spotlight index using deleteAppEntities(identifiedBy:ofType:) or deleteApp
Entities(ofType:).
Associate existing Core Spotlight indexable items with app
entities
If your app already supports Spotlight or uses Core Spotlight for its search functionality, follow these steps
to create app entities and associate them with the CSSearchableItem that represents the entity in the
Spotlight index:
O. Create the CSSearchabileItem that represents the entity in the Spotlight index.
P. Set the searchable attributes for CSSearchableItem.
Q. Associate the searchable item with the app entity it represents with associateAppEntity(_:
priority:). Alternatively, initialize CSSearchabileItem using one of its initializers that takes an
IndexedEntity as a parameter. Make sure to associate the app entity with the searchable item before
adding the item to the Spotlight index.
S. Add all items to the index using indexSearchableItems(_:completionHandler:).
The following code example from Accelerating app interactions with App Intents shows how the sample
appʼs TrailDataManager creates searchable items, associates each item with the matching app entity,
and then donates them to the Spotlight index:
func updateSpotlightIndex() async {
guard CSSearchableIndex.isIndexingAvailable() else {
Logger.spotlightLogging.info("[Spotlight] Indexing is unavailable")
return
}
// Create an array of the searchable information for each `Trail`.
let searchableItems = trails.map { trail in
let item = CSSearchableItem(uniqueIdentifier: String(trail.id),
domainIdentifier: nil,
attributeSet: trail.searchableAttributes)
let isFavorite = favoritesCollection.members.contains(trail.id)
let weight = isFavorite ? 10 : 1
let intent = TrailEntity(trail: trail)
/**
Associate `TrailEntity` with the data that the `Trail` structure provides so the system recogni
both types represent the same data. You need to create this association before adding `CSSearch
to `CSSearchableIndex`.
*/
item.associateAppEntity(intent, priority: weight)
return item
}
do {
// Add the trails to the search index so people can find them through Spotlight.
// You need to do this as part of the app's initial setup on launch.
let index = CSSearchableIndex.default()
try await index.indexSearchableItems(searchableItems)
Logger.spotlightLogging.info("[Spotlight] Trails indexed by Spotlight")
} catch let error {
Logger.spotlightLogging.error("[Spotlight] Trails were not indexed by Spotlight. Reason:
}
}
See Also
Other system experiences
Focus
Adjust your appʼs behavior and filter incoming notifications when the current Focus changes.
Action button on iPhone and Apple Watch
Enable people to run your App Shortcuts with the Action button on iPhone or to start your appʼs
workout or dive sessions using the Action button on Apple Watch.
Launching your voice-based conversational app from the side button of iPhone
Let people in Japan configure the side button of iPhone to launch your voice-based conversational
app.
Developing a WidgetKit strategy
Explore features, tasks, related frameworks, and constraints as you make a plan to implement
widgets, controls, watch complications, and Live Activities.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Entity queries | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Entity queries
Identifier-based queries
EntityQueryr P
EnumerableEntityQueryr P
String-based queries
EntityStringQueryr P
Property-matched queries
EntityPropertyQueryr P
S
EntityQueryProperties
C
EntityQueryProperty
Property comparators
S
EntityQuerySortingOptions
S
EntityQuerySortableByProperty
S
EntityQuerySort
Unique entity queries
UniqueAppEntityQueryr P
S
UniqueAppEntityProvider
Resolvers
Utility types
Filter
App Intents / Entity queries
API Collection
Entity queries
Help the system find the entities your app defines and use them to resolve parameters.
Overview
When the system needs to retrieve one or more specific instances of an app entity, it asks you to provide a
relevant query type. The system uses queries during parameter resolution when the parameter of an intent
contains an entity. The system also uses them to resolve information in a different format into one of your
appʼs entities. For example, it uses them to resolve natural spoken language into one of your appʼs entities.
The system can sometimes determine which entities it needs and provide you with a list of corresponding
identifiers. Provide an EntityQuery type to supply the entities for those identifiers. Provide additional
query types to perform more advanced searches, such as a search that matches specific properties of the
entity.
/
Topics
Identifier-based queries
protocol EntityQuery
An interface for locating entities using their identifiers.
protocol EnumerableEntityQuery
An interface you use to provide a short list of entities that are relatively small in size.
String-based queries
protocol EntityStringQuery
An interface that locates entities using arbitrary string input.
Property-matched queries
protocol EntityPropertyQuery
An interface for locating entities by matching values against one or more of their properties.
struct EntityQueryProperties
A type that provides the properties to include in a property-matched query.
class EntityQueryProperty
An object that provides the supported comparators you use to describe the different ways users can
query against a property of an app entity.
Property comparators
Specify the type of comparison to perform during a property-matched query.
struct EntityQuerySortingOptions
The potential properties you can use to sort the results of a query.
struct EntityQuerySortableByProperty
Details about a specific property you use to sort the query results.
struct EntityQuerySort
The properties to use to sort the results when the query runs.
Unique entity queries
protocol UniqueAppEntityQuery
A query designed for only returning a single possible value, provided by uniqueEntity. Protocol
extensions will provide the other required query methods based on that.
struct UniqueAppEntityProvider
A simplified query type conforming to UniqueAppEntityQuery. Use this as the value of the
defaultQuery of an entity conforming to UniqueAppEntity.
See Also
Parameters, custom data types, and queries
Adding parameters to an app intent
Enable people to configure app intents with their custom input values.
Integrating custom data types into your intents
Provide the system with information about the types your app uses to model its data so that your
intents can use those types as parameters.
Parameter resolution
Define the required parameters for your app intents and specify how to resolve those parameters at
runtime.
App entities
Make core types or concepts discoverable to the system by declaring them as app entities.
Resolvers
Resolve the parameters of your app intents, and extend the standard resolution types to include your
appʼs custom types.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Responding to the Action button on Apple Watch Ultra | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Responding to the Action button on A…
StartWorkoutIntentr P
PauseWorkoutIntentr P
ResumeWorkoutIntentr P
StartDiveIntentr P
S
ConfirmationActionName
Launching your voice-based conversation…
Developing a WidgetKit strategy
SiriKit migration
Soup Chef with App Intents: Migrating cu…
Actions
App intents
Intent discovery
App Shortcuts
Parameters, custom data types, and queries
Adding parameters to an app intent
Integrating custom data types into your in…
Parameter resolution
App entities
Filter
App Intents / Action button on iPhone and Apple Watch / Responding to the Action button on Apple Watch Ultra
Article
Responding to the Action button on Apple
Watch Ultra
Use App Intents to register actions for your app.
Overview
On Apple Watch Ultra, people can specify the action that the system performs when they press the Action
button. By default, the watch provides actions for starting workouts, starting dives, starting a backtrack
navigation session, setting a waypoint, turning on the flashlight, and running a shortcut from the Shortcuts
app. To add your dive or workout app to the list of apps that appear when someone chooses Settings >
Action Button, use App Intents to register actions for your app.
For workout apps, you can implement the following protocols:
StartWorkoutIntent
Starts a workout session when someone first presses the Action button.
AppIntent
Runs a custom action when someone presses the Action button during your appʼs active workout
session. Donating an intent sets the Action buttonʼs next action. Your app can have only one next
action at a time; however, donating a new intent changes the next action.
PauseWorkoutIntent
/
Pauses the current workout session when someone simultaneously presses the Action button and the
side button during a workout session.
ResumeWorkoutIntent
Resumes the current workout session when someone simultaneously presses the Action button and
the side button while a workout session is in a paused state.
For dive apps, you can implement the following protocols:
StartDiveIntent
Starts a dive session when someone first presses the Action button.
AppIntent
Runs a custom action when someone presses the Action button during your appʼs active dive session.
The system also performs the next action if someone simultaneously presses the Action button and
the side button. Donating an intent sets the Action buttonʼs next action. Your app can have only one
next action at a time; however, donating a new intent changes the next action.
Important
When creating intents for the Action button, donʼt implement them in an AppIntentsExtension.
Always implement the intents directly in your watchOS app.
Start a new workout session
Start by creating either an AppEnum or an AppEntity that defines the types of workouts that your app
supports. If your app supports only a single workout, you can create an enumeration with a single case.
Also define the display representation for each type of workout that your app supports. Apple Watch Ultra
shows the case descriptionʼs title and subtitle below the First Press settings when someone sets your app
as the workout app in Settings > Action Button.
enum WorkoutEnum: String, AppEnum {
// List the types of workout your app supports.
case running
static var typeDisplayRepresentation: TypeDisplayRepresentation = "Workout"
// Define the display representation for each of the workouts your app supports.
static var caseDisplayRepresentations: [WorkoutEnum: DisplayRepresentation] =
[.running: DisplayRepresentation(title: "Running", subtitle: "outside run")]
}
Next, create a structure that adopts the StartWorkoutIntent protocol. Your implementation needs to
define the intentʼs title, a list of suggestedWorkouts, and a parameter that contains the workout
Style.
struct MyStartWorkoutIntent: StartWorkoutIntent {
// Define the intent's title.
static var title: LocalizedStringResource = "Start Workout"
// Define a list of start workout intents that appear below the First Press settings when someone se
static var suggestedWorkouts: [MyStartWorkoutIntent] = [MyStartWorkoutIntent()]
// Define a parameter that specifies the type of workout that this intent starts.
@Parameter(title: "Type of Workout")
var workoutStyle: WorkoutEnum
// Define an init method that sets the default workout type.
init() {
workoutStyle = .running
}
// Add the display representation, and the perform method here.
}
Important
Define your implementationʼs workoutStyle property using the AppIntent.Parameter property
wrapper.
You can dynamically change the list of suggested workouts by changing the value of the suggested
Workouts property and then calling invalidateSuggestedWorkouts(), which tells the system to
reread the suggested workouts.
Next, set the display strings for the intent by defining the displayRepresentation just after the
intentʼs initializer.
var displayRepresentation: DisplayRepresentation {
WorkoutEnum.caseDisplayRepresentations[workoutStyle] ??
DisplayRepresentation(title: "Unknown")
}
Then, implement your intentʼs perform() method. The system calls this method when anything starts the
intent. In your implementation, you have 30 seconds to start a workout session and return a successful
value. If you donʼt start a workout session in that time, the system displays an error message, but the app
remains in the foreground. People can start a workout session directly from the app, but without a session,
the app goes to the background the next time they drop their wrist.
// Define the method that the system calls when it performs the intent.
func perform() async throws -> some IntentResult {
logger.debug("*** Performing a Start Intent. ***")
// Start a workout session inside the perform method.
let workoutManager = MyWorkoutManager.shared
try await workoutManager.startWorkout(type: workoutStyle)
// Schedule a task to request authorization and then set up the data source and start collecting dat
Task {
await workoutManager.requestAuthorization()
do {
try await workoutManager.startCollectingData()
} catch {
fatalError("*** An error occurred while setting up the data source: \(error.localizedDescrip
}
}
// Return a successful result.
return .result()
}
The start workout intent becomes available as soon as someone downloads your app. This means they can
set up the Action button and run your start workout intent without ever launching your app.
Similarly, if you update your app and change the data types that the workout session uses, someone can
launch the updated workout from the Action button without launching your app.
To ensure that your app requests authorization for the current set of HealthKit data types it intends to use
during its workout sessions, you need to schedule an authorization request from within your intentʼs
perform() method. Because someone using your app doesnʼt have access to its user interface until after
the perform() method returns, you need to schedule the request authorization using a Task.
Note
If your app has never requested authorization for any HealthKit data types, the system just launches
your app when someone presses the Action button. It doesnʼt call your intentʼs perform() method.
Before authorizing the HealthKit data, create and start your workout session.
func startWorkout(type: WorkoutEnum) throws {
logger.debug("*** Start a workout of type \(type.rawValue) ***")
logger.debug("==> Creating the workout configuration.")
let configuration = HKWorkoutConfiguration()
configuration.activityType = .running
configuration.locationType = .outdoor
self.configuration = configuration
logger.debug("==> Creating the workout session.")
let session = try HKWorkoutSession(healthStore: store, configuration: configuration)
session.delegate = self
self.session = session
workoutType = type
logger.debug("==> Starting the session.")
session.startActivity(with: Date())
}
The code example above creates a workout configuration for an outdoor run. It then uses the configuration
to create the workout session, assigns a workout session delegate to receive state change and errors from
the workout, and starts the session.
Because the app hasnʼt created a data source for the workout session, the session doesnʼt generate any
data.
Next, request authorization for all the HealthKit data types that your workout sessions use.
func requestAuthorization() async {
logger.debug("*** Requesting Authorization ***")
// The quantity type to write to the health store.
let typesToShare: Set = [
HKQuantityType.workoutType()
]
// The quantity types to read from the health store.
let typesToRead: Set = [
HKQuantityType(.heartRate),
HKQuantityType(.activeEnergyBurned),
HKQuantityType(.distanceWalkingRunning)
]
guard HKHealthStore.isHealthDataAvailable() else {
logger.debug("*** HealthKit is not supported on this device. ***")
return
}
do {
try await store.requestAuthorization(toShare: typesToShare, read: typesToRead)
} catch {
fatalError("*** An error occurred while requesting authorization to read and save data:
}
enabled = true
}
This authorization request can take an arbitrarily long amount of time. Any time you request authorization
for new data, the system displays an authorization sheet, and waits until someone either authorizes the
data or dismisses the sheet. However, if someone has already authorized the requested data types, the
system returns immediately.
After the authorization request finishes, set up the data source, assign a delegate to receive data from the
workout builder, and begin collecting data from the workout.
func startCollectingData() async throws {
precondition(enabled == true)
guard let configuration else { fatalError("*** You need to create a workout configuration before cal
guard let session else { fatalError("*** You need to create a session before calling this method. **
logger.debug("==> Setting the session's data source.")
let builder = session.associatedWorkoutBuilder()
builder.dataSource = HKLiveWorkoutDataSource(healthStore: store,
workoutConfiguration: configuration)
builder.delegate = self
logger.debug("==> Begin collecting data.")
try await builder.beginCollection(at: Date())
self.builder = builder
logger.debug("==> Donate the mark lap intent as the Action button's next action.")
try await MyStartWorkoutIntent().donate(result: .result(actionButtonIntent: MyMarkLapIntent
}
In the code example above, the last line donates the MyMarkLapIntent() as the next action for the
Action button. Donating the next action is described in more detail below.
After implementing your StartWorkoutIntent, build and run your app to load it onto the test device or
Simulator. Then, on the test device, choose Settings > Action Button. Tap Action and choose Workout, then
tap App and choose your app.
The device starts a new workout session when you press the Action button.
Important
The system always launches your app before running the perform() method for your Start
WorkoutIntent or StartDiveIntent structures. By default, these intents set their openAppWhen
Run property to true. To ensure these intents run as expected, donʼt change the propertyʼs value.
Support multiple workout types
Your app can provide a list of suggested workout types, letting people associate a particular workout type
with the Action button.
To suggest multiple workout types, start by defining the different types of workouts that your app supports
in your AppEnum implementation.
enum WorkoutEnum: String, AppEnum {
// List the types of workout your app supports.
case walking
case running
case swimming
case cycling
static var typeDisplayRepresentation: TypeDisplayRepresentation = "Workout"
// Set the display representation here.
}
Then set a display representation for each case.
static var caseDisplayRepresentations: [WorkoutEnum: DisplayRepresentation] =
[.walking: DisplayRepresentation(title: "Walking", subtitle: "outside walk"),
.running: DisplayRepresentation(title: "Running", subtitle: "outside run"),
.swimming: DisplayRepresentation(title: "Swimming", subtitle: "lap swim"),
.cycling: DisplayRepresentation(title: "Cycling", subtitle: "outside cycling")
]
Next, in your StartWorkoutIntent implementation, define the set of suggested workouts.
static var suggestedWorkouts: [MyStartWorkoutIntent] =
[MyStartWorkoutIntent(style: .walking),
MyStartWorkoutIntent(style: .running),
MyStartWorkoutIntent(style: .swimming),
MyStartWorkoutIntent(style: .cycling)]
Then, in the perform() method, check the intentʼs workoutStyle and create the corresponding
workout session.
func perform() async throws -> some IntentResult {
let workoutManager = MyWorkoutManager.shared
await workoutManager.requestAuthorization()
await workoutManager.startWorkout(type: workoutStyle)
return .result()
}
Create a configuration for the specified type of workout.
func startWorkout(type: WorkoutEnum) throws {
logger.debug("*** Should be starting a workout of type \(type.rawValue) ***")
logger.debug("==> Creating the workout configuration.")
let configuration = HKWorkoutConfiguration()
switch type {
case .walking:
configuration.activityType = .walking
case .running:
configuration.activityType = .running
case .swimming:
configuration.activityType = .swimming
case .cycling:
configuration.activityType = .cycling
}
configuration.activityType = type.activityType()
if type == .swimming {
configuration.locationType = .indoor
configuration.swimmingLocationType = .pool
configuration.lapLength = HKQuantity(unit: HKUnit.yard(), doubleValue: 25.0)
} else {
configuration.locationType = .outdoor
}
self.configuration = configuration
logger.debug("==> Creating the workout session.")
let session = try HKWorkoutSession(healthStore: store, configuration: configuration)
session.delegate = self
self.session = session
workoutType = type
logger.debug("==> Starting the session.")
session.startActivity(with: Date())
}
And, finally, request authorization for all the data types that your workout sessions use.
// The quantity types to read from the health store.
let typesToRead: Set = [
HKQuantityType(.heartRate),
HKQuantityType(.activeEnergyBurned),
HKQuantityType(.distanceCycling),
HKQuantityType(.distanceSwimming),
HKQuantityType(.distanceWalkingRunning)
]
Build and run your app again. When you open the Action button settings, you can specify a particular
workout for the First Press > Workout setting.
And pressing the Action button launches the selected type of workout.
Donate the next action
Apple Watch Ultra runs the next action when someone presses the Action button while a workout or dive
session is already running. This means the first time someone presses the Action button, the system starts
your session. If they press the Action button any other time during the session, it performs the next action.
To set the next action, implement a structure that adopts the AppIntent protocol.
struct MarkLapIntent: AppIntent {
static var title: LocalizedStringResource = "Mark Lap"
func perform() async throws -> some IntentResult {
logger.debug("*** Perform a mark lap intent. ***")
await MyWorkoutManager.shared.markLap(at: Date())
return .result()
}
}
This intent needs a title property that provides a localized description of the action, and a perform()
method, which the system calls when it performs the intent.
Next, donate the app intent as the current sessionʼs next action. For example, in your start workout intentʼs
perform() method, you can donate the next action for the new session by returning result(action
ButtonIntent:).
However, in most cases you want to donate a next action regardless of whether the user presses the Action
button or launches the session from within your app. To ensure that your app donates the correct intent,
simply return .result() from your start intent, and then donate the next intent as soon as the session
starts.
Previous code examples show how to donate the MyMarkLapIntent in its startCollectingData()
method. The app then calls this method when starting a workout from the Action button or from the appʼs
user interface.
logger.debug("==> Donate the mark lap intent as the Action button's next action.")
try await MyStartWorkoutIntent().donate(result: .result(actionButtonIntent: MyMarkLapIntent()))
You can donate as many action intents as you need; however, your app can use only the most recently
donated intent as the next action. Donating a new intent changes the next action.
Pause and resume a workout
Apple Watch Ultra supports pausing and resuming a current workout session by simultaneously pressing
both the Action button and the side button.
To implement the pause action, create a structure that adopts the PauseWorkoutIntent protocol.
struct MyPauseWorkoutIntent: PauseWorkoutIntent {
static var title: LocalizedStringResource = "Pause Workout"
func perform() async throws -> some IntentResult {
logger.debug("*** Performing a pause intent. ***")
await MyWorkoutManager.shared.pauseWorkout()
return .result()
}
}
This intent needs a title property that provides a localized description of the action, and a perform()
method, which the system calls when it performs the intent.
Similarly, to implement the resume action, create a structure that adopts the ResumeWorkoutIntent
protocol.
struct MyResumeWorkoutIntent: ResumeWorkoutIntent {
static var title: LocalizedStringResource = "Resume Workout"
func perform() async throws -> some IntentResult {
logger.debug("*** Performing a resume intent. ***")
await MyWorkoutManager.shared.resumeWorkout()
return .result()
}
}
If your app doesnʼt implement structures that adopt these protocols, the system ignores simultaneous
presses.
Start a new dive session
Dive sessions work similarly to workout sessions. To start a dive session, implement a structure that adopts
the StartDiveIntent protocol. Typically, people start the dive session just before entering the water.
Your app can then donate App Intents that help them use your app while in the water. For example, while in
the water they canʼt use the touch screen, but the Action button and Digital Crown function normally.
struct MyStartDiveSessionIntent: StartDiveIntent {
static var title: LocalizedStringResource = "Starting a dive session."
func perform() async throws -> some IntentResult {
logger.debug("*** Starting a dive session. ***")
await DiveManager.shared.start()
return .result(actionButtonIntent: MyCollectSubmergedDataIntent())
}
}
This intent needs a title property that provides a localized description of the action, and a perform()
method, which the system calls when it performs the intent.
To read live depth, water pressure, and water temperature data, see Accessing submersion data.
Important
Before you can access live dive data, your app needs to include an entitlement to access submersion
data. For more information, see Express interest in the Submerged Depth and Pressure API.
Unlike workout sessions, the start dive intent supports only a single type of session. You can donate next
actions for your dive session; however, you canʼt create intents to pause or resume the session.
Passing data to the intents
The previous examples use singleton objects to share data between the different parts of your app;
however, App Intents support dependency injection, letting you define the data in your main app, and
access it in your intents.
In your intents, create a property that uses the AppDependency property wrapper.
struct MyStartWorkoutIntent: StartWorkoutIntent {
@Dependency var workoutManager: MyWorkoutManager
// Add remaining code here.
}
Then, as early as possible when your app launches, use the AppDependencyManager to define the
dependency.
AppDependencyManager.shared.add { MyWorkoutManager() }
You can set the dependency in your appʼs applicationDidFinishLaunching() method. Or, if your
app uses SwiftUI life cycles, add an init() method to your App structure, and set it there.
One of the main advantages of dependency injection is that you can easily replace your main data object
with a mock object during testing.
Note
You can only use dependency injection to pass data objects from your main app to its intents. If you
need to pass the data to other parts of your app, you need to use a different approach.
Debug intents
To see console output and respond to breakpoints in Xcode, use the following steps to debug your intents:
W. Build and run your app in Xcode.
X. On the test device or Simulator, send your app to the background. For example, press Shift-Command-H
in Simulator to send your app to the background.
Z. Make sure you set the actions you want to test by choosing Settings > Action Button.
\. Press the Action button to test the primary and next actions. On a test device, you can also test the
pause and resume actions for workout sessions by pressing the Action button and the side button
simultaneously.
Any logging from your intents appears in Xcodeʼs console. The system also pauses execution for any
breakpoints you set in Xcode.
See Also
Responding to the Action button
protocol StartWorkoutIntent
An App Intent for starting a workout.
protocol PauseWorkoutIntent
An App Intent that lets someone pause your appʼs current workout session.
protocol ResumeWorkoutIntent
An App Intent that lets someone resume your appʼs paused workout session.
protocol StartDiveIntent
An App Intent that lets people start a dive session when they press the Action button on Apple Watch
Ultra.
struct ConfirmationActionName
Developer Documentation
Platforms
iOS
Topics & Technologies
Accessibility
Resources
Documentation
Programs
Apple Developer ProgramiPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
To submit feedback on documentation, visit Feedback Assistant.
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto

========================================
FILE: Shared content interactions | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
Shared with You / Shared content interactions
API Collection
Shared content interactions
Use highlights and attribution views to manage participants and trigger events for shared content.
Topics
Attributions
class SWAttributionView
A view that displays the sender who shares a highlight and provides related actions.
Highlights
class SWHighlight
An object that represents a universal link to share by any number of contacts in one or more conversations.
class SWHighlightCenter
An object that contains a priority-ordered list of universal links to share with the current user.
Highlight events
protocol SWHighlightEvent
A protocol that defines an activity that the system posts in response to a user action for a highlight.
class SWHighlightChangeEvent
An object that represents change activity for a highlight.
class SWHighlightMembershipEvent
An object that represents membership activity for a highlight.
class SWHighlightMentionEvent
An object that represents mention activity for a highlight.
class SWHighlightPersistenceEvent
An object that represents persistence activity for a highlight.
Participants
class SWPerson
An object that tracks participants in a collaboration.
class SWRemoveParticipantAlert
An alert that prompts the user to remove a participant from a Messages group.
See Also
Shared content
Making your app content shareable
Add support for universal links and a Shared with You shelf to support shared content in your app.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Intent discovery | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Intent discovery
Donation management
S
IntentDonationManager
S
IntentDonationIdentifier
S
IntentDonationMatchingPredicate
Intent predictions
PredictableIntentr P
S
IntentPrediction
Intent relevancy
S
RelevantIntent
C
RelevantIntentManager
S
RelevantContext
App Shortcuts
Parameters, custom data types, and queries
Adding parameters to an app intent
Integrating custom data types into your in…
Parameter resolution
App entities
Entity queries
Filter
App Intents / Intent discovery
API Collection
Intent discovery
Donate your appʼs intents to the system to help it identify trends and predict future
behaviors.
Overview
Make your intents more discoverable to people by donating them to the system. When someone performs
an action in your app, donate an intent that corresponds to that action. The system uses the information
you provide to predict actions someone might take in the future. For example, if someone requests the
weather from your app each morning, the system might proactively offer the corresponding app intent at
the same time each day.
Donate intents only when someone uses your appʼs interface directly. You donʼt need to donate intents
associated with Siri or interactions with the Shortcuts app because the system donates them automatically.
You can also delete donations when someone cancels or reverses a previously executed action, or when
the action is no longer relevant.
/
Topics
Donation management
struct IntentDonationManager
A type you use to donate intents to the system, or delete intents when they become irrelevant.
struct IntentDonationIdentifier
An opaque type that identifies a specific donation to the system.
struct IntentDonationMatchingPredicate
The match conditions that identify a set of previously donated app intents.
Intent predictions
protocol PredictableIntent
An interface that allows the system to suggest the app intent to someone in the future using
predictions you provide.
struct IntentPrediction
A prediction for a specific app intent that the system might display to someone when itʼs relevant.
Intent relevancy
struct RelevantIntent
A type that specifies an intent and its relevance to the user.
class RelevantIntentManager
A type that saves relevant intents.
struct RelevantContext
Contextual clues the system uses to show relevant widgets in the Smart Stack on watchOS.
See Also
Actions
App intents
intents.
Define the custom actions your app exposes to the system, and incorporate support for existing SiriKit
App Shortcuts
Integrate your appʼs intents and entities with the Shortcuts app, Siri, Spotlight, and the Action button
on supported iPhone and Apple Watch models.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Integrating actions with Siri and Apple Intelligence | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Essentials
App Intents updates
Making actions and content discoverable …
Creating your first app intent
Adopting App Intents to support system e…
Accelerating app interactions with App Int…
Siri and Apple Intelligence
Integrating actions with Siri and Apple I…
Making onscreen content available to Siri …
App intent domains
Making your appʼs functionality available t…
Visual intelligence
Integrating your app with visual intelligence
Visual Intelligence
IntentValueQueryr P
Interactive Snippets
Displaying static and interactive snippets
SnippetIntentr P
Other system experiences
Filter
App Intents / Integrating actions with Siri and Apple Intelligence
Article
Integrating actions with Siri and Apple
Intelligence
Create app intents, entities, and enumerations that conform to assistant schemas to tap
into the enhanced action capabilities of Siri and Apple Intelligence.
iOS 18.0+ iPadOS 18.0+ macOS 15.0+ tvOS 18.0+ visionOS 2.0+ watchOS 11.0+ Xcode 16.0+
/
Overview
Apple Intelligence is a new personal intelligence system that deeply integrates powerful generative models
into the core of iPhone, iPad and Mac. Siri will draw on the capabilities of Apple Intelligence to deliver
assistance thatʼs more natural, contextually relevant and personal to users.
Note
Siriʼs personal context understanding, onscreen awareness, and in-app actions are in development and
will be available with a future software update.
A big part of peopleʼs personal context are the apps they use every day. The App Intents framework gives
you a means to express your appʼs capabilities and content to the system and integrate them with Siri and
Apple Intelligence. This will unlock new ways for your users to interact with your app from anywhere on
their device.
Note
If youʼre new to the App Intents framework, make sure to read Making actions and content
discoverable and widely available and Creating your first app intent.
Understand assistant schemas
To integrate your app with Siri and Apple Intelligence, provide AppIntent, AppEntity, and AppEnum
implementations that work well with the pre-trained models Apple Intelligence uses. To provide the
implementation that Apple Intelligence needs, create the necessary code using Swift macros to generate
additional properties, and add the relevant protocol conformance for your app intent, app entity, and app
enum implementation. Xcode offers templates for the macros and verifies the conformance of your code at
compile time.
To create implementations that work well with Siri and Apple Intelligence:
For your App Intents implementation, use the AppIntent(schema:) macro.
For your AppEntity implementation, use the AppEntity(schema:) macro.
For your AppEnum implementation, use the AppEnum(schema:) macro.
Each macro requires you to provide a schema value to generate app intent, app entity, or app enum code
that Apple Intelligence can understand. The value you provide to the macros, the assistant schema, has
two parts:
The App intent domain that describes a collection of APIs for specific functionality; for example, the
.photos domain if an app has photos or video functionality.
The schema, an action or a content type within the domain, the specific API for the app intent, app
entity, or app enum you create.
For example, an app intent that opens a photo from a photo library uses @AppIntent(schema:
.photos.openAsset) to make sure the intent provides necessary metadata that allows Apple
Intelligence to understand it well.
Important
Only use the provided app intents domains and schemas for app actions and content that match the
specific domain and schema.
For a list of available assistant schemas, see App intent domains.
Review schema requirements
Conforming to an assistant schema comes with requirements that vary depending on the domain and
schema. However, all assistant schemas share the following constraints:
App intents canʼt require parameters in addition to the parameters a schema expects. If your app intent
uses additional parameters, make them optional.
Optional parameters that extend the schema are only available to the app intent when it appears in the
Shortcuts app.
App entities canʼt use required properties in addition to the properties the schema expects. However,
you can use optional properties.
App enums donʼt come with requirements for their enumeration cases and offer full flexibility, but you
canʼt use more than a total of 10 app enums that conform to assistant schemas.
Create an app intent that implements a schema
To create an app intent that integrates your app functionality with Apple Intelligence:
N. Identify an action or existing app intent implementation in your app that matches a domain listed in App
intent domains.
O. Create a new Swift file for your app intent code.
P. Use Xcode code completion to generate code that conforms to an assistant schema: Type the name of
the domain, followed by an underscore (<domain>_) and choose the schema that fits your action. For
example, type photos_ to see a list of available schemas for the .photos domain and choose the
action to open an asset (photos_openAsset ). To ensure assistant schema conformance for an
existing app intent, add the macro — for example, @AppIntent(schema: .photos.openAsset) —
to your existing app intent implementation.
U. Build your app to check for errors that indicate that your app intent implementation doesnʼt match the
chosen assistant schema.
W. Make changes to meet the schema requirements and rebuild your app.
Tip
Xcode code completion can create AppIntent, AppEntity, and AppEnum code that conforms to
assistant schemas.
The following code snippet shows how the Making your appʼs functionality available to Siri sample declares
an app intent that opens a video from a deviceʼs media library:
@AppIntent(schema: .photos.openAsset)
struct OpenAssetIntent: OpenIntent {
var target: AssetEntity
@Dependency
var library: MediaLibrary
@Dependency
var navigation: NavigationManager
@MainActor
func perform() async throws -> some IntentResult {
let assets = library.assets(for: [target.id])
guard let asset = assets.first else {
throw IntentError.noEntity
}
navigation.openAsset(asset)
return .result()
}
}
Note
When an app intent conforms to an assistant schema that is known at compile time, the system no
longer needs metadata you previously provided, like a title or description. Remove them to
simplify your code. However, you can always supply additional metadata as needed.
Ensure app entities and app enums conform to the schema
Many actions you describe as an AppIntent require parameters or return results, often with custom types
you describe as an AppEntity or AppEnum. If you use an app entity or app enum in an intent that
conforms to an assistant schema, the entity or enum also needs to conform to the assistant schema.
Ensuring conformance works similar to conformance for your app intent:
N. Annotate your app entity or app enum with the AppEntity(schema:) or AppEnum(schema:) macro
or create a new entity or enum using Xcode code completion to automatically generate code that
conforms to a schema. For more information, see the previous section.
O. Pass the corresponding domain and entity or enum parts to the macro.
P. Update your code to meet the requirements of the schema.
For example, the AssetEntity implementation from the Making your appʼs functionality available to Siri
sample looks like this:
@AppEntity(schema: .photos.asset)
struct AssetEntity: IndexedEntity {
static let defaultQuery = AssetQuery()
let id: String
let asset: Asset
@Property(title: "Title")
var title: String?
var creationDate: Date?
var location: CLPlacemark?
var assetType: AssetType?
var isFavorite: Bool
var isHidden: Bool
var hasSuggestedEdits: Bool
var displayRepresentation: DisplayRepresentation {
DisplayRepresentation(
title: title.map { "\($0)" } ?? "Unknown",
subtitle: assetType?.localizedStringResource ?? "Photo"
)
}
}
Consider the impact of updating existing app intents
Your existing app intents might overlap with functionality that assistant schemas provide. If you can make
an existing app intent conform to a schema without making changes to parameters that the intent uses,
proceed with adding schema conformance. However, changing existing app intent implementations or
removing app intents can directly impact people because their custom shortcuts may no longer work.
To not break peopleʼs existing workflows, create a new app intent in addition to an existing app intent. As a
result, both intents appear in the Shortcuts app as actions. To avoid them appearing as duplicates, mark
your new app intent as available to Apple Intelligence only by setting isAssistantOnly to true. For
example, an app intent implementation could look like this:
@AppIntent(schema: .photos.createAssets)
struct CreateAssetsIntent: AppIntent {
// ...
static let isAssistantOnly: Bool = true
// ...
@MainActor
// ...
func perform() async throws -> some ReturnsValue<[AssetEntity]> {
}
}
Similarly, you can set isAssistantOnly to true for any applicable app entities and app enums that
conform to an assistant schema.
After some time, you can remove the isAssistantOnly code and remove your old app intent. For more
information about giving people time to update their custom shortcuts with new app intents, see
Understand the impact of removing app intents and shortcuts.
See Also
Siri and Apple Intelligence
Making onscreen content available to Siri and Apple Intelligence
Enable Siri and Apple Intelligence to respond to a personʼs questions and action requests for your
appʼs onscreen content.
App intent domains
Make your appʼs actions and content available to Siri and Apple Intelligence with assistant schemas.
Making your appʼs functionality available to Siri
Add app intent schemas to your app so Siri can complete requests, and integrate your app with Apple
Intelligence, Spotlight, and other system experiences.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Supporting universal links in your app | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation
Xcode / Projects and workspaces / Allowing apps and websites to link to your con… / Supporting universal links in your app
Article
Supporting universal links in your app
Prepare your app to respond to an incoming universal link.
}
{
Overview
When a user activates a universal link, the system launches your app and sends it an NSUserActivity object. Query
this object to find out how your app launched and to decide what action to take.
To support universal links in your app:
?. Create a two-way association between your app and your website and specify the URLs that your app handles. See
Supporting associated domains.
G. Update your app delegate to respond when it receives an NSUserActivity object with the activityType set to
NSUserActivityTypeBrowsingWeb.
Warning
Universal links offer a potential attack vector into your app, so make sure to validate all URL parameters and discard
any malformed URLs. In addition, limit the available actions to those that donʼt risk the userʼs data. For example,
donʼt allow universal links to directly delete content or access sensitive information about the user. When testing
your URL-handling code, make sure your test cases include improperly formatted URLs.
Update your app delegate to respond to a universal link
When the system opens your app as the result of a universal link, your app receives an NSUserActivity object with
an activityType value of NSUserActivityTypeBrowsingWeb. The activity objectʼs webpageURL property
contains the HTTP or HTTPS URL that the user accesses. Use NSURLComponents APIs to extract the components of
the URL. See the examples that follow.
This example code shows how to handle a universal link in macOS:
func application(
_ application: NSApplication,
continue userActivity: NSUserActivity,
restorationHandler: @escaping ([NSUserActivityRestoring]) -> Void) -> Bool
{
// Get URL components from the incoming user activity.
guard userActivity.activityType == NSUserActivityTypeBrowsingWeb,
let incomingURL = userActivity.webpageURL,
let components = NSURLComponents(url: incomingURL, resolvingAgainstBaseURL: true) else {
return false
}
// Check for specific URL components that you need.
guard let path = components.path,
let params = components.queryItems else {
return false
}
print("path = \(path)")
if let albumName = params.first(where: { $0.name == "albumname" } )?.value,
let photoIndex = params.first(where: { $0.name == "index" })?.value {
print("album = \(albumName)")
print("photoIndex = \(photoIndex)")
return true
} else {
print("Either album name or photo index missing")
return false
}
This example code shows how to handle a universal link in iOS and tvOS:
func application(
_ application: UIApplication,
continue userActivity: NSUserActivity,
restorationHandler: @escaping ([UIUserActivityRestoring]?) -> Void) -> Bool
// Get URL components from the incoming user activity.
guard userActivity.activityType == NSUserActivityTypeBrowsingWeb,
let incomingURL = userActivity.webpageURL,
let components = NSURLComponents(url: incomingURL, resolvingAgainstBaseURL: true) else {
return false
}
// Check for specific URL components that you need.
guard let path = components.path,
let params = components.queryItems else {
return false
}
print("path = \(path)")
if let albumName = params.first(where: { $0.name == "albumname" } )?.value,
let photoIndex = params.first(where: { $0.name == "index" })?.value {
print("album = \(albumName)")
print("photoIndex = \(photoIndex)")
return true
} else {
print("Either album name or photo index missing")
return false
}
If your app has opted into Scenes, and your app is not running, the system delivers the universal link to the scene(_:
willConnectTo:options:) delegate method after launch, and to scene(_:continue:) when the universal link is
tapped while your app is running or suspended in memory.
func scene(
_
scene: UIScene, willConnectTo
session: UISceneSession,
options connectionOptions: UIScene.ConnectionOptions) {
// Get URL components from the incoming user activity.
guard let userActivity = connectionOptions.userActivities.first,
userActivity.activityType == NSUserActivityTypeBrowsingWeb,
let incomingURL = userActivity.webpageURL,
let components = NSURLComponents(url: incomingURL, resolvingAgainstBaseURL: true) else {
return
}
// Check for specific URL components that you need.
guard let path = components.path,
let params = components.queryItems else {
return
}
print("path = \(path)")
if let albumName = params.first(where: { $0.name == "albumname" })?.value,
let photoIndex = params.first(where: { $0.name == "index" })?.value {
print("album = \(albumName)")
print("photoIndex = \(photoIndex)")
} else {
print("Either album name or photo index missing")
}
}
This example code shows how to handle a universal link in watchOS:
func handle(
_ userActivity: NSUserActivity)
{
// Get URL components from the incoming user activity.
guard userActivity.activityType == NSUserActivityTypeBrowsingWeb,
let incomingURL = userActivity.webpageURL,
let components = NSURLComponents(url: incomingURL, resolvingAgainstBaseURL: true) else { return
// Check for specific URL components that you need.
guard let path = components.path,
let params = components.queryItems else { return }
print("path = \(path)")
if let albumName = params.first(where: { $0.name == "albumname" } )?.value,
let photoIndex = params.first(where: { $0.name == "index" })?.value {
print("album = \(albumName)")
print("photoIndex = \(photoIndex)")
} else {
print("Either album name or photo index missing")
}
Note
In watchOS, a Safari-like interface is available for apps such as Messages and Mail. For other apps, when the user
clicks a universal link that points to content in a companion app that the user doesnʼt have installed, the system
notifies the user to view the URL on their iPhone.
}
}
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: App Intents updates | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
Updates
WWDC
WWDC25
WWDC24
WWDC23
WWDC22
WWDC21
Technology updates
Accelerate updates
Accessibility updates
ActivityKit updates
AdAttributionKit Updates
App Clips updates
App Intents updates
AppKit updates
Apple Intelligence updates
AppleMapsServerAPI Updates
Apple Pencil updates
ARKit updates
Audio Toolbox updates
Filter
Updates / App Intents updates
Article
App Intents updates
Learn about important changes in App Intents.
/
Overview
Browse notable changes in App Intents.
June 2025
Create app intents that conform to SnippetIntent to display an interactive snippet.
Make app entities available in Spotlight that conform to IndexedEntity and use the @Computed
Property(indexingKey:) or @Property(indexingKey:) Swift macros for attributes you want to
add to the Spotlight index.
Integrate your app with visual intelligence by providing app entities to the system using an Intent
ValueQuery.
Create an AppEntity that conforms to the Transferable protocol and associate the app entity with
a NSUserActivity using the activityʼs appEntityIdentifier property to make onscreen content
available to Siri without adopting an assistant schema.
November 2024
Siri and Apple Intelligence
Make onscreen content available to Siri and Apple Intelligence by describing it as an AppEntity and
adopting an assistant schema. Additionally, adopt the Transferable protocol, and associate the app
entity with a NSUserActivity using the activityʼs appEntityIdentifier property.
June 2024
System integration
Integrate your app with Siri and Apple Intelligence using App intent domains.
Use ControlConfigurationIntent and WidgetKit to allow users to put controls on the Lock Screen
or in Control Center.
Create a locked camera capture extension for your app and implement a CameraCaptureIntent to
allow people to capture photos and videos from controls or the Action button.
Create app intents that capture audio by implementing AudioRecordingIntent.
Allow people to find app entities in Spotlight by adopting the IndexedEntity protocol.
Content sharing
Make it possible to share and transfer data you describe as App entities by conforming to
Transferable.
Receive content other apps make available with app intents by using IntentFile for your app intent
parameters.
Describe the file that stores your app intent data using FileEntity.
General
Provide additional information about errors with AppIntentError.PermissionRequired, App
IntentError.Unrecoverable, and AppIntentError.UserActionRequired.
Pass a condition to requestConfirmation(conditions:actionName:dialog:) to only require
user confirmation if a personʼs context meets the provided condition.
Use URLRepresentableIntent, URLRepresentableEntity, and URLRepresentableEnum to
represent your app intents, app entities, and app enums as universal links that you use to provide deep
links to your appʼs content.
Define a set of types for an intent parameter using the UnionValue() macro to create flexible app
intents because a parameter can be of one of several pre-defined union types.
Create entities that have just one singular instance with UniqueAppEntity and the corresponding
UniqueAppEntityQuery. For example, to provide an app intent for app settings that appear in your
app or in System Settings, create a singleton entity that encapsulates all settings as properties. Use it in
the app intent that offers actions to change your appʼs settings.
See Also
Technology updates
Accelerate updates
Learn about important changes to Accelerate.
Accessibility updates
Learn about important changes to Accessibility.
ActivityKit updates
Learn about important changes in ActivityKit.
AdAttributionKit Updates
Learn about important changes to AdAttributionKit.
App Clips updates
Learn about important changes in App Clips.
AppKit updates
Learn about important changes to AppKit.
Apple Intelligence updates
Learn about important changes to Apple Intelligence.
AppleMapsServerAPI Updates
Learn about important changes to AppleMapsServerAPI.
Apple Pencil updates
Learn about important changes to Apple Pencil.
ARKit updates
Learn about important changes to ARKit.
Audio Toolbox updates
Learn about important changes to Audio Toolbox.
AuthenticationServices updates
Learn about important changes to AuthenticationServices.
AVFAudio updates
Learn about important changes to AVFAudio.
AVFoundation updates
Learn about important changes to AVFoundation.
Background Tasks updates
Learn about important changes in Background Tasks.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Collaboration views | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
Shared with You / Collaboration views
API Collection
Collaboration views
Create and customize a collaboration view to manage the shared content actions.
Topics
Collaboration views
class SWCollaborationView
A view that contains the collaboration content and options.
Collaboration attributes
class SWCollaborationHighlight
A highlight object that represents an active collaboration.
class SWCollaborationMetadata
A model object for conveying data during a collaboration.
struct SWCollaborationIdentifier
A unique identifier for a collaboration.
struct SWLocalCollaborationIdentifier
A local identifier for a collaboration.
let SWCollaborationMetadataTypeIdentifier: String
A string constant for the metadata type identifier.
Collaboration management
protocol SWCollaborationViewDelegate
A delegate object that the system notifies about changes to the collaboration popover state.
class SWCollaborationCoordinator
An object that contains the shared collaboration coordinator.
class SWCollaborationOption
An object that determines how the system shares a document in a collaboration.
class SWCollaborationOptionsGroup
An object that represents a group of collaboration options that the system displays together.
class SWCollaborationOptionsPickerGroup
An object that represents a group of collaboration options that the system displays together with mutually
exclusive options.
class SWCollaborationShareOptions
An object that represents the state of the collaboration options for the document.
let UTCollaborationOptionsTypeIdentifier: String
A string constant for the options type identifier.
Actions
class SWAction
An object that represents a collaboration action.
class SWStartCollaborationAction
An object that represents the first action sent to an app when the user shares a collaboration.
protocol SWCollaborationActionHandler
A delegate to handle incoming collaboration actions from a collaboration coordinator.
class SWUpdateCollaborationParticipantsAction
An action that contains the cryptographic identities the system uses to add to or remove from an existing
collaboration.
See Also
Collaboration
Adding shared content collaboration to your app
Manage shared content collaboration in your app using CloudKit and iCloud Drive.
Adding custom collaboration to your app
Integrate your custom collaboration app with Messages.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Shortcut-Related UI | Apple Developer Documentation.pdf
========================================
Documentation Language: Swift
SiriKit / IntentsUI / Shortcut-Related UI
API Collection
Shortcut-Related UI
Incorporate standard buttons and interfaces into your user interface to offer
easy shortcut creation.Topics
Shortcut Button
class INUIAddVoiceShortcutButton
A button that allows the user to add or edit a shortcut.
Shortcut Editors
class INUIAddVoiceShortcutViewController
A view controller that guides the user through the steps for adding a shortcut to Siri.
class INUIEditVoiceShortcutViewController
A view controller that lets the user edit or remove an existing shortcut.
See Also
Custom UI for Shortcuts
Configuring the View Controller for Your Custom Interface
Configure your view controller to replace or augment the default interface in Siri or Maps.

========================================
FILE: Adding custom collaboration to your app | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
Shared with You / Adding custom collaboration to your app
Article
Adding custom collaboration to your app
Integrate your custom collaboration app with Messages.
Overview
If your app uses iCloud to store shared content, you can use the steps in Adding shared content collaboration to your
app to add collaboration. To share content without using iCloud, the Shared with You framework provides an
SWCollaborationMetadata object wrapped in NSItemProvider to implement a custom collaboration
infrastructure.
Before you can use this collaboration infrastructure, your app needs to support universal links to share content with
other apps. For more details about implementing universal links, see Making your app content shareable.
Related sessions from WWDC22
Session 10093: Integrate your custom collaboration app with Messages
Create the metadata object
When a user decides to share a collaboration from your app through the Messages app, you first create metadata to
represent the content. The metadata includes share options the user can configure prior to sending the message, and
many other properties you can customize. Next, you provide that metadata to the share sheet, or to drag and drop using
the steps below in the “Present a collaboration view” section.
The string you pass to SWLocalCollaborationIdentifier doesnʼt need to be unique across devices, itʼs only for
your app to use locally. Similarly, the system displays the initiatorʼs account handle and name that your app retrieves
from personNameComponents(from:) locally so the collaborator can confirm their account.
// Configure the SWCollaborationMetadata.
let localIdentifier = SWLocalCollaborationIdentifier(rawValue: "identifier")
let metadata = SWCollaborationMetadata(localIdentifier: localIdentifier)
metadata.title = "Content Title"
metadata.initiatorHandle = "user@example.com"
let formatter = PersonNameComponentsFormatter()
if let components = formatter.personNameComponents(from: "Devin") {
metadata.initiatorNameComponents = components
}
After your app sets the identifier and initiator for the metadata, configure SWCollaborationShareOptions. Share
options are the settings a person configures on the collaboration in Messages or the share sheet. Options represent
individual switches, or mutually exclusive values for a setting. Options have a title and an identifier, and are either in a
selected or an unselected state.
There are two classes to represent a group of options: SWCollaborationOptionsGroup and SWCollaboration
OptionsPickerGroup. Use SWCollaborationOptionsGroup to represent a collection of switches, and use
SWCollaborationOptionsPickerGroup to represent mutually exclusive values for a setting.
In the example below, a person can choose either the “Can make changes” or the “Read only” option. The collaborator
can choose “Allow mentions” and the “Allow comments” options independent of each other. The app then passes both
the option groups to SWCollaborationShareOptions to initialize the defaultShareOptions.
// Configure the SWCollaborationShareOptions.
let permission = SWCollaborationOptionsPickerGroup(identifier: UUID().uuidString,
options: [
SWCollaborationOption(title: "Can make changes", identifier: UUID().uuidString),
SWCollaborationOption(title: "Read only", identifier: UUID().uuidString)
])
permission.options[0].isSelected = true
permission.title = "Permission"
let additionalOptions = SWCollaborationOptionsGroup(identifier: UUID().uuidString,
options: [
SWCollaborationOption(title: "Allow mentions", identifier: UUID().uuidString),
SWCollaborationOption(title: "Allow comments", identifier: UUID().uuidString)
])
additionalOptions.title = "Additional Settings"
let optionsGroups = [permission, additionalOptions]
metadata.defaultShareOptions = SWCollaborationShareOptions(optionsGroups: optionsGroups)
Present a collaboration view
If your app uses SwiftUI, SWCollaborationMetadata is compatible with the Transferable protocol and the
ShareLink view. In the example below, the app defines a Transferable model object and creates a Proxy
Representation to return a collaboration metadata instance. Then, the app passes that model object to a Share
Link instance in the view.
// Configure the SwiftUI TransferRepresentation object.
struct CustomCollaboration: Transferable {
var name: String
static var transferRepresentation: some TransferRepresentation {
ProxyRepresentation { customCollaboration in
SWCollaborationMetadata(
localIdentifier: .init(rawValue: "com.example.customcollaboration"),
title: customCollaboration.name,
defaultShareOptions: nil,
initiatorHandle: "johnappleseed@apple.com",
initiatorNameComponents: nil
)
}
}
}
// Initialize ShareLink with the custom collaboration model object.
struct ContentView: View {
var body: some View {
ShareLink(item: CustomCollaboration(name: "Example"), preview: .init("Example"))
}
}
Itʼs good practice to register multiple representations of the content to support sharing through as many channels as
possible. For example, Messages automatically offers an option to send the content as a copy if you provide a file
representation.
For UIKit and AppKit apps, use NSItemProvider to support content sharing. SWCollaborationMetadata
conforms to the NSItemProviderReading and NSItemProviderWriting protocols, so you can register a
metadata instance with an item provider to support collaboration. Use NSItemProvider with UIActivityView
Controller and UIDragItem in iOS and iPadOS, and NSSharingServicePicker in macOS.
In the example code below, the app registers the collaboration metadata in an NSItemProvider instance. Then the
app creates a UIActivityItemsConfiguration object with the item provider object and passes that to the
UIActivityViewController. Finally, the app presents the share sheet.
// Present the iOS share sheet.
func presentActivityViewController(metadata: SWCollaborationMetadata) {
let itemProvider = NSItemProvider()
itemProvider.registerObject(metadata, visibility: .all)
let activityConfig = UIActivityItemsConfiguration(itemProviders: [itemProvider])
let shareSheet = UIActivityViewController(activityItemsConfiguration: activityConfig)
present(shareSheet, animated: true)
}
To support drag and drop in iOS, initialize NSItemProvider and register the metadata the same way as in the previous
code example, then create a UIDragItem with the item provider.
// Support iOS drag and drop.
func createDragItem(metadata: SWCollaborationMetadata) -> UIDragItem {
let itemProvider = NSItemProvider()
itemProvider.registerObject(metadata, visibility: .all)
return UIDragItem(itemProvider: itemProvider)
}
The API is similar in macOS for the sharing popover. Use the item provider to initialize an NSSharingServicePicker
object and show the picker relative to a target view.
// Show the macOS sharing popover.
func showSharingServicePicker(view: NSView, metadata: SWCollaborationMetadata) {
let itemProvider = NSItemProvider()
itemProvider.registerObject(metadata, visibility: .all)
let picker = NSSharingServicePicker(items: [itemProvider])
picker.show(relativeTo: view.bounds, of: view, preferredEdge: .minY)
}
To support drag and drop in macOS, use NSPasteboardItem instead of NSItemProvider. Assign the collaboration
metadata to collaborationMetadata on a new NSPasteboardItem instance.
// Support macOS drag and drop.
func createPasteboardItem(metadata: SWCollaborationMetadata) -> NSPasteboardItem {
let pasteboardItem = NSPasteboardItem()
pasteboardItem.collaborationMetadata = metadata
return pasteboardItem
}
The system stages a draft of your collaborative content in Messages. After a person taps the Send button, the system
coordinates with your app to create the share.
Prepare the collaboration coordinator
SWCollaborationCoordinator is a singleton, meaning thereʼs a global shared instance that your app uses to
respond to action requests. Your app defines an action handler that conforms to the SWCollaborationAction
Handler protocol. Because the collaboration coordinator runs in the background and can send requests for actions to
your app at any time, define your action handler early in the launch process. The app in the example below registers the
handler in the application(_:didFinishLaunchingWithOptions:) method:
// Assign your action handler to the SWCollaborationCoordinator.
private let collaborationCoordinator = SWCollaborationCoordinator.shared
func application(
_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication
// Conform to the SWCollaborationActionHandler protocol.
collaborationCoordinator.actionHandler = self
}
Your action handler is responsible for responding to SWAction requests from the system. An SWAction represents
work your app needs to handle during a collaboration. Your app calls fulfill() after it completes a request. If your
app canʼt complete an action, it responds with fail(). Itʼs important to respond to SWAction requests quickly to
avoid a system timeout.
The example code below retrieves the localIdentifier and userSelectedShareOptions from the
SWCollaborationMetadata in the action. The APIRequest object in this example is the API for processing
collaboration requests on a web server.
// Handle a system request for an SWStartCollaborationAction.
func collaborationCoordinator(
_
coordinator: SWCollaborationCoordinator,
handle action: SWStartCollaborationAction) {
let localID = action.collaborationMetadata.localIdentifier.rawValue
let selectedOptions = action.collaborationMetadata.userSelectedShareOptions
let prepareRequest = APIRequest.PrepareCollaboration(localID: localID, selectedOptions)
Task {
do {
let response = try await apiController.send(request: prepareRequest)
let identifier = response.deviceIndependentIdentifier
action.fulfill(using: response.url, collaborationIdentifier: identifier)
} catch {
Log.error("Caught an error while preparing the collaboration: \(error)")
action.fail() // Cancels the message.
}
}
}
If the SWStartCollaborationAction is successful, the system sends your app a second action to update the
collaboration participants. Before you can add or remove participants, your app needs to have a way to verify
participants.
Verify participant access
The SWUpdateCollaborationParticipantsAction contains the cryptographic identities for the participants. The
system derives the identities from the collaboration identifier that SWStartCollaborationAction provides. Your
shared content server is responsible for identity storage and verification of recipient devices.
To verify a participant, use the SWPerson.Identity rootHash property. A root hash is a secure value your app
sends to your server to uniquely identify a participant on their devices. To perform a verification, your server needs to
compute a root hash.
When the system sends a collaboration message for a participant, it actually sends individual messages to each device
for that participant. The Messages app identifies each device using a cryptographic public key. Because the goal is to
allow access only on this participantʼs set of devices, the system derives the root hash from the set of public keys
registered to each recipient.
The root hash is the root node of a data structure called a Merkle tree. A Merkle tree is a binary tree that the system
builds by performing a sequence of hashing operations. To derive an identity for the participant based on their public
keys, the system uses the keys as the leaves of this tree. The hashing algorithm that the system uses in the Merkle tree
ensures that the system can only compute the root node from that set of keys.
In the example below, the user has three devices and three public keys. The keys are unique for each collaboration
identifier that your app provides, using a process called key diversification. To prevent tracking the number of devices
registered to a user, the system pads the set with random keys up to a fixed size. Your server hashes the padded set of
diversified keys to create the leaf nodes of the tree with a SHA-256 algorithm.
Your server then concatenates and hashes each pair of leaf nodes to derive their predecessor nodes. Repeat this
process with the predecessor nodes until a single root node remains. This is the root hash that the system uses to
uniquely represent this recipientʼs identity across their devices.
The figure below shows that itʼs possible to generate a root hash using a subset of the nodes from a complete Merkle
tree. Your server can use the hashes H4, H7, and H11, along with the diversified public key P3, to reproduce the root
hash in this tree. First, hash the public key to get the missing leaf node H3. Then use H3 and H4 to generate H8. Next,
use the given H7 node with H8 to generate H10. Finally, use H10 and H11 to produce the root hash.
Itʼs important to note that you can prove the system uses the public key P3 to generate a given root hash, without
needing to reconstruct the entire tree. The subset of nodes necessary to do this is a proof of inclusion. Verification
begins when your app opens a universal link. To do this, you first need to check that the link is collaborative.
Verify a collaboration link
SWCollaborationHighlight represents a collaborative link that your app retrieves from SWHighlightCenter.
Use that collaboration highlight to generate the proof of inclusion. To represent a proof of inclusion, use SWPerson
.IdentityProof. To perform verification, first generate this object along with a cryptographic signature to send to
your server. Retrieve the proof using the getSignedIdentityProof(for:using:completionHandler:)
method on SWHighlightCenter.
Use the signature to ensure that a bad actor canʼt send the request to gain access to your collaboration. The data can
be a challenge you request from your server, or a nonce that the device generates. The example below uses the
challenge approach.
The system passes the URL, which is the universal link associated with a collaboration, to application(_:did
FinishLaunchingWithOptions:). Use this URL to fetch the associated SWCollaborationHighlight from the
SWHighlightCenter.
Request the challenge from the server, and pass the returned data to the getSignedIdentityProof method on
SWHighlightCenter, along with the highlight. This method returns a signed identity proof that the app sends to the
server for verification.
The app sends the proof to the server, along with the public key and the signed data. Your app signs the data using the
Elliptic Curve Digital Signature Algorithm over the P-256 elliptic curve. Verify the signature on the data using the public
key in the identity proof. You can do this with most common encryption libraries.
// Retrieve a signed identity proof for a highlight.
func application(
_ app: UIApplication, open url: URL,
options: [UIApplication.OpenURLOptionsKey : Any] = [:]) -> Bool {
let highlightCenter: SWHighlightCenter = self.highlightCenter
let challengeRequest = APIRequest.GetChallengeData()
Task {
do {
let highlight = try highlightCenter.collaborationHighlight(for: url)
let challenge = try await apiController.send(request: challengeRequest)
let proof = try await highlightCenter.getSignedIdentityProof(for: highlight,
using: challenge.data)
let proofOfInclusionRequest = APIRequest.SubmitProofOfInclusion(for: proof)
let result = try await apiController.send(request: proofOfInclusionRequest)
documentController.update(currentDocument, with: result)
} catch {
Log.error("Caught an error while generating the proof of inclusion: \(error)")
}
}
}
After you verify the signature, you can trust that the identity proof the system sends is from the device associated with
that public key. Next, use the identity proof to recompute the root hash. A recursive algorithm works well with tree data
structures, as in the code example below:
// Recursive code for root hash generation.
func generateRootHashFromArray(localHash: SHA256Digest, inclusionHashes: [SHA256Digest],
publicKeyIndex: Int) -> SHA256Digest {
guard let firstHash = inclusionHashes.first else { return localHash }
// Check whether the node is the left or the right successor.
let isLeft = publicKeyIndex.isMultiple(of: 2)
// Calculate the combined hash.
var rootHash: SHA256Digest
if isLeft {
rootHash = hash(concatenate([localHash, firstHash]), using: .sha256)
} else {
rootHash = hash(concatenate([firstHash, localHash]), using: .sha256)
}
// Recursively pass in elements and move up the Merkle tree.
let newInclusionHashes = inclusionHashes.dropFirst()
rootHash = generateRootHashFromArray(
localHash: rootHash,
inclusionHashes: Array(newInclusionHashes),
publicKeyIndex: (publicKeyIndex / 2)
)
return rootHash
}
On the initial invocation, pass in the hash of the public key, the set of inclusion hashes, and the public key index. Next,
remove the first inclusion hash. Check the public key index to see whether the key is on the left or the right of its sibling.
Concatenate and hash the selected hashes in the correct order. Next, remove the consumed node in the inclusion
Hashes array, and pass the rest to a recursive call to this same function. The public key index then updates so that itʼs
ready for the next node in the tree.
With this simple function, you can quickly compute a root hash given an identity proof. The server can check that this
generated root hash is in the list of root hashes the owner of the document uploads during sending. The hash is present
in the list of known hashes, so the server can grant access to the document.
Next, sign some data and retrieve the proof of inclusion. Send the signed data and proof to your server. Verify the
signature on the data. Using the proof of inclusion, generate the root hash. Finally, compare the root hash to the list of
known identities associated with that content.
Add a participant
The example below shows how to handle the update participants action. First, retrieve the collaboration identifier from
the actionʼs metadata — this is the identifier you supply to the fulfill() method while handling SWStart
CollaborationAction.
Next, use the actionʼs addedIdentities property to retrieve the participant data to store on your content server. Each
identity has a rootHash property, which is the data you store on your server to validate participants during the
collaboration process.
After you retrieve this data, create another server request to add the participants to the collaboration with the target
identifier. Then, send the request to your server, and fulfill or fail the action. This time, the fulfill method doesnʼt take any
parameters. After you set up the collaboration, your app has everything it needs to grant immediate access to the
recipients of the message.
// Add a participant.
func collaborationCoordinator(
_
coordinator: SWCollaborationCoordinator,
handle action: SWUpdateCollaborationParticipantsAction) {
let identifier = action.collaborationMetadata.collaborationIdentifier
let participants: [Data] = action.addedIdentities.compactMap { $0.rootHash }
let addParticipants = APIRequest.AddParticipants(identifier: identifier, participants)
Task {
do {
try await apiController.send(request: addParticipants)
action.fulfill() // Sends the URL that the start action provides.
} catch {
Log.error("Caught an error while adding participants to the collaboration: \(error)")
action.fail() // Cancels the message.
}
}
}
Remove a participant
To remove a participant, look up any account associated with a removed identity and revoke their access. If your app
doesnʼt have any associated accounts for this collaboration, delete the root hash from your database. The example code
below uses the removedIdentities property on the action and passes it to a similar removal API request:
// Remove a participant.
func collaborationCoordinator(
_
coordinator: SWCollaborationCoordinator,
handle action: SWUpdateCollaborationParticipantsAction) {
// This is an example of removing participants only. Handle the added identities here too.
let identifier = action.collaborationMetadata.collaborationIdentifier
let removed: [Data] = action.removedIdentities.compactMap { $0.rootHash }
let removeParticipants = APIRequest.RemoveParticipants(identifier: identifier, removed)
Task {
do {
try await apiController.send(request: removeParticipants)
action.fulfill()
} catch {
log.error("Caught an error while adding participants to the collaboration: \(error)")
action.fail()
}
}
}
Post a change event notice
When a participant makes changes to a collaboration, your app posts notices about those changes. The system displays
those notices in Messages as a banner in the shared conversation. The banner includes a description of the changes, as
well as the name of the person who makes each change.
Your app posts a change event for content updates or comments, and it posts a membership event when a participant
joins or leaves. When a person mentions another person in a collaboration, post a mention event. Post a persistence
event when a collaborator moves or deletes content. The example code below shows how to post a change event for an
edit to a collaboration:
// Post a change event notice.
func postContentEditEvent(identifier: SWCollaborationIdentifier) throws {
let highlightCenter: SWHighlightCenter = self.highlightCenter
let highlight = try highlightCenter.collaborationHighlight(forIdentifier: identifier)
let editEvent = SWHighlightChangeEvent(highlight: highlight, trigger: .edit)
highlightCenter.postNotice(for: editEvent)
}
Post a membership event notice
For participant changes, your app posts a membership event and passes either the SWHighlightMembershipEvent
Trigger.addedCollaborator or SWHighlightMembershipEventTrigger.removedCollaborator trigger
type.
// Post a membership event notice.
func postMembershipEvent(identifier: SWCollaborationIdentifier) throws {
let highlightCenter: SWHighlightCenter = self.highlightCenter
let highlight = try highlightCenter.collaborationHighlight(forIdentifier: identifier)
let membershipEvent = SWHighlightMembershipEvent(highlight: highlight, trigger: .addCollaborator)
highlightCenter.postNotice(for: membershipEvent)
}
Post a mention event notice
If your app supports user mentions, you can post a mention event. Initialize a person identity with the root hash of the
mentioned user. Next, pass the mentioned identity to SWHighlightMentionEvent and post the mention event.
The system shows this notice only to the mentioned user in the Messages app.
// Post a mention event notice.
func postMentionEvent(identifier: SWCollaborationIdentifier, mentionedRootHash: Data) throws {
let mentionedIdentity = SWPerson.Identity(rootHash: mentionedRootHash)
let highlightCenter: SWHighlightCenter = self.highlightCenter
let highlight = try highlightCenter.collaborationHighlight(forIdentifier: identifier)
let mentionEvent = SWHighlightMentionEvent(highlight: highlight,
mentionedPersonIdentity: mentionedIdentity)
highlightCenter.postNotice(for: mentionEvent)
}
Post a persistence event notice
Your app posts the persistence event type when a participant moves, renames, or deletes content. In the example
below, the app uses SWHighlightPersistenceEventTrigger.renamed to indicate that the participant changed
the name of the content:
// Post a persistent event notice.
func postContentRenamedEvent(identifier: SWCollaborationIdentifier) throws {
let highlightCenter: SWHighlightCenter = self.highlightCenter
let highlight = try highlightCenter.collaborationHighlight(forIdentifier: identifier)
let renamedEvent = SWHighlightPersistenceEvent(highlight: highlight, trigger: .renamed)
highlightCenter.postNotice(for: renamedEvent)
}
See Also
Collaboration
Adding shared content collaboration to your app
Manage shared content collaboration in your app using CloudKit and iCloud Drive.
Collaboration views
Create and customize a collaboration view to manage the shared content actions.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Adding Sticker packs and iMessage apps to the system Stickers app, Messages camera, and FaceTime | Apple Developer Documentation.pdf
========================================
Documentation Language: Swift
Messag… / Adding Sticker packs and iMessage apps to the system Stickers app, Messages camera, and
FaceTime
Article
Adding Sticker packs and iMessage
apps to the system Stickers app,
Messages camera, and FaceTime
Enable your Sticker pack or iMessage app in the media context.
Overview
In iOS 12 and later, Sticker packs and iMessage apps can appear in multiple contexts.
MSMessagesAppPresentationContext.messages context
The Sticker pack or iMessage app appears in the list of iMessage apps that appears when
you press the plus button.
MSMessagesAppPresentationContext.media context
The sticker pack or iMessage app appears in the Stickers app throughout iOS, and in
effect in FaceTime and the Messages camera.
People can access stickers throughout iOS through the emoji keyboard. To access effects in
the Messages camera or FaceTime, a person taps the effects button. The system then
displays all the iMessage apps and Sticker packs that support the media context. A person
can launch an app, and use it to add images or stickers to the camera.
iMessage apps only appear in the messages context. To enable support for the mediacontext, set the MSSupportedPresentationContexts key in your extensionʼs Info
.plist file. If you indicate support for both messages and media, your Stickers only
present in the media context including in Messages.
A Sticker pack or iMessage appʼs context limits its available features. For example, In the
MSMessagesAppPresentationContext.messages context, a person can peel off
stickers and attach them to any bubbles in the current conversation. Your app can also
programatically send stickers, images, text, or interactive messages.
In the MSMessagesAppPresentationContext.media context, your app appears in
effects in Messages and FaceTime. Therefore, the system limits your app to features that
make sense over a photo or video. For instance, a person canʼt play an interactive game while
taking a photo; however, they can add stickers or images to the picture.
Specify the supported contexts
To specify the supported contexts:
M. Open the Info.plist file for your Sticker pack or iMessage app extension.
N. Add the MSSupportedPresentationContexts key, using an Array type.
O. Add String values for the supported contexts. For the MSMessagesAppPresentation
Context.messages context, add the MSMessagesAppPresentationContext
Messages value. For MSMessagesAppPresentationContext.media, add
MSMessagesAppPresentationContextMedia.
You must specify one of the contexts, but if you specify both contexts, they only present in
the MSMessagesAppPresentationContext.media context.
For more information on setting Info.plist keys, see Edit property lists.
Work with the media context
The MSMessagesAppPresentationContext.media context supports only a subset of
the features provided by the Messages framework. People can peel stickers from a sticker
browser view, and place them in the Messages camera or FaceTime. They can reposition,
resize, rotate, or remove stickers from the viewfinder.iMessage apps can also insert stickers or images into the viewfinder using the insert(_:
completionHandler:) or insertAttachment(_:withAlternateFilename:
completionHandler:) methods. However, if the attachment isnʼt an image supported by
MSSticker, then the insertAttachment(_:withAlternateFilename:completion
Handler:) method fails with an MSMessageErrorCode.apiUnavailableIn
PresentationContext error.
Additionally, you canʼt insert interactive messages or text into the media context. You also
canʼt send items automatically. Therefore, the following methods from the MSConversation
class arenʼt available:
insert(_:completionHandler:)
insertText(_:completionHandler:)
sendAttachment(_:withAlternateFilename:completionHandler:)
send(_:completionHandler:)
send(_:completionHandler:)
sendText(_:completionHandler:)
If you call these methods, they fail with an MSMessageErrorCode.apiUnavailableIn
PresentationContext error.
Additionally, because you canʼt send or receive interactive messages, the system never calls
the following methods in the MSMessagesAppPresentationContext.media context:
willSelect(_:conversation:)
didSelect(_:conversation:)
didReceive(_:conversation:)
didStartSending(_:conversation:)
didCancelSending(_:conversation:)
Finally, the MSMessagesAppPresentationContext.media context is already inside the
Messages camera or FaceTime; therefore, you canʼt display another camera inside the current
viewfinder.
Detect the current contextDetect the current context
Use the MSMessagesAppViewController objectʼs presentationContext property to
determine your iMessage appʼs current context. Enable only the features that make sense in
that context.
if presentationContext == .messages {
// The system is presenting your iMessage app inside the Messages app.
// You have full access to the Messages framework.
// You can insert or send stickers, text, attachments, or interactive messages
} else if presentationContext == .media {
// The system is presenting your iMessage app in effects.
// You can only insert stickers and images.
}
See Also
Custom sticker packs
Adding your sticker packs to Messages
Drag and drop your sticker pack into the Stickers asset catalog to let people access your
stickers from Messages.
class MSStickerBrowserViewController
A view controller that provides dynamic content to the standard sticker browser.
class MSStickerBrowserView
A browser view that displays a dynamically generated list of stickers.
class MSStickerView
A view for displaying a sticker.enum MSStickerSize
The size of the stickers in the browser view.

========================================
FILE: AppEntity | Apple Developer Documentation.pdf
========================================
Integrating custom data types into your in…
News Discover Design Develop Distribute Support Account
App Intents / AppEntity
Protocol
AppEntity
An interface for exposing a custom type or app-specific concept to system experiences
like Siri and the Shortcuts app.
iOS 16.0+ iPadOS 16.0+ Mac Catalyst macOS 13.0+ tvOS 16.0+ visionOS watchOS 9.0+
protocol AppEntity : AppValue, DisplayRepresentable, Identifiable where Self == Self.ValueType, Self.I
Parameter resolution
App entities
All Technologies
Entities
Documentation Language: Swift
App Intents
Integrating custom data types into your …
AppEntityr P
Specifying properties
T
AppEntity.Property
Making the entity queryable
P
static var defaultQuery: Self.DefaultQ…
DefaultQuery
P
static var defaultResolverSpecificatio…
P
static var defaultResolverSpecificatio…
Default Implementations
Identifiable Implementations
FileEntityr P
IndexedEntityr P
TransientAppEntityr P
UniqueAppEntityr P
URLRepresentableEntityr P
Entity identity
PersistentlyIdentifiabler P
S
EntityIdentifier
EntityIdentifierConvertibler P
Entity content
Filter
C
EntityProperty
AppValuer P
AnyIntentValuer P
AppEnumr P
URLRepresentableEnumr P
/
Mentioned in
Integrating actions with Siri and Apple Intelligence
Integrating custom data types into your intents
Adding parameters to an app intent
Responding to the Action button on Apple Watch Ultra
Making app entities available in Spotlight
Overview
To use a data model object to app intents, update it to conform to the AppEntity protocol. Declare
properties using the @Property property wrapper to make them visible to the system. The following
example from the Accelerating app interactions with App Intents sample app shows a data model for a trail:
struct TrailEntity: AppEntity {
// Provide the system with the interface required to query `TrailEntity` structures.
static let defaultQuery = TrailEntityQuery()
// The system requires the `AppEntity` identifier to be unique and persistant because the system may
var id: Trail.ID
@Property var name: String
@Property(title: "Region")
var regionDescription: String
@Property var trailLength: Measurement<UnitLength>
var imageName: String
var currentConditions: String
/**
*/
Information on how to display the entity to people — for example, a string like the trail name. Incl
and image for a visually rich display.
var displayRepresentation: DisplayRepresentation {
DisplayRepresentation(title: "\(name)"
,
subtitle: "\(regionDescription)"
,
image: DisplayRepresentation.Image(named: imageName))
}
init(trail: Trail) {
self.id = trail.id
self.imageName = trail.featuredImage
self.currentConditions = trail.currentConditions
self.name = trail.name
self.regionDescription = trail.regionDescription
self.trailLength = trail.trailLength
}
}
extension TrailEntity: URLRepresentableEntity {
static var urlRepresentation: URLRepresentation {
// Use string interpolation to fill values from your entity necessary for constructing the unive
// This example URL uses the unique and persistant identifier for the `TrailEntity` in the URL.
"https://example.com/trail/\(.id)/details"
}
}
For additional property types, see EntityProperty.
It is up to you whether you want to conform to the AppEntity protocol directly on the data models of your
app, or if you create data models specific to your app intents implementation. In many cases, itʼs a good
idea to create models specific to app intents that shadow your app data models to keep entities separate
from the rest of your appʼs logic.
Topics
Specifying properties
typealias Property
Making the entity queryable
static var defaultQuery: Self.DefaultQuery
The default query to use to retrieve entity property instances.
Required Default implementations provided.
associatedtype DefaultQuery : EntityQuery
Required
static var defaultResolverSpecification: EmptyResolverSpecification<Self>
static var defaultResolverSpecification: some ResolverSpecification
Default Implementations
Identifiable Implementations
Relationships
Inherits From
AppValue
CustomLocalizedStringResourceConvertible
DisplayRepresentable
Identifiable
InstanceDisplayRepresentable
PersistentlyIdentifiable
Sendable
SendableMetatype
TypeDisplayRepresentable
Inherited By
AssistantEntity
AssistantSchemaEntity
FileEntity
IndexedEntity
TransientAppEntity
URLRepresentableEntity
UniqueAppEntity
See Also
Entities
Integrating custom data types into your intents
Provide the system with information about the types your app uses to model its data so that your
intents can use those types as parameters.
protocol FileEntity
An entity that refers to a document or other file.
protocol IndexedEntity
IndexedEntity represents an App Entity decorated with an attribute set. A set of attributes that
enable the system to perform structured indexing and queries of entities.
protocol TransientAppEntity
A type that represents a transient model object which exposes its interface to App Intents via
properties. Note that TransientAppEntity types are not meant to be queried.
protocol UniqueAppEntity
An entity that will only ever have one value, such as global settings.
protocol URLRepresentableEntity
An app entity with a URL representation.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: App intents 2 | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
App Intents / App intents
API Collection
App intents
Define the custom actions your app exposes to the system, and incorporate support for
existing SiriKit intents.
Overview
Use app intents to express your appʼs capabilities to the system. An app intent includes the code you need
to perform an action, and expresses the data you require from the system. The system exposes your
actions directly from the Shortcuts app and in system experiences like Siri.
To define an action, create a type that adopts the AppIntent protocol, or a related protocol that provides
the specific behavior you need. Annotate any key properties with the @Parameter property wrapper to let
the system know you need the associated information to perform the action.
For more information about features App Intents enables, see Making actions and content discoverable and
widely available.
Topics
Actions
protocol AppIntent
An interface for providing an app-specific capability that people invoke from system experiences like
Siri and the Shortcuts app.
protocol AudioPlaybackIntent
An App Intent that plays, pauses, or otherwise modifies audio playback state when it executes.
protocol AudioRecordingIntent
An app intent that starts, stops or otherwise modifies audio recording state.
protocol AudioStartingIntent
An App Intent that plays, pauses, or otherwise modifies audio playback state when it executes.
Deprecated
protocol CameraCaptureIntent
Designates intent that will launch an activity that uses deviceʼs camera to capture photos or videos.
Marking your intent with this protocol makes it available as a possible action for Camera quick action.
protocol DeleteIntent
Delete the associated entity(s).
protocol DeprecatedAppIntent
An app intent that marks an action as deprecated and informs people which action to use instead.
protocol ForegroundContinuableIntent
A protocol you use for app intents which begin their work with the app in the background but may
request to continue in the foreground.
Deprecated
protocol OpenIntent
Open the associated item.
struct OpenURLIntent
An intent that opens a universal link.
protocol PlayVideoIntent
An intent that looks for videos based on a search term, then plays the content.
protocol ProgressReportingIntent
An intent that reports progress to the system during its execution
protocol PushToTalkTransmissionIntent
An intent that begins or ends an audio transmission with the Push to Talk framework.
protocol URLRepresentableIntent
An app intent with a URL representation.
protocol SetValueIntent
An intent that contains a value which can be set.
protocol ShowInAppSearchResultsIntent
An app intent that takes a person to search results for a specified search term.
protocol SystemIntent
Designates intent types provided by App Intents.
Controls, widgets, and Live Activities
protocol ControlConfigurationIntent
An interface for configuring a Control Center module.
protocol LiveActivityStartingIntent
An intent that starts, pauses, or otherwise modifies a Live Activity.
Deprecated
protocol LiveActivityIntent
An intent that starts, pauses, or otherwise modifies a Live Activity when it runs.
protocol WidgetConfigurationIntent
An interface for configuring a WidgetKit widget.
Siri and Apple Intelligence
Integrating actions with Siri and Apple Intelligence
Create app intents, entities, and enumerations that conform to assistant schemas to tap into the
enhanced action capabilities of Siri and Apple Intelligence.
App intent domains
Make your appʼs actions and content available to Siri and Apple Intelligence with assistant schemas.
SiriKit intent migration
protocol CustomIntentMigratedAppIntent
An interface for replacing a custom SiriKit intent that allows existing shortcuts and donations to
continue working.
Dependency management
class AppDependencyManager
An object that manages the registration and initialization of an app intentʼs dependencies.
class AppDependency
A property wrapper that resolves a registered dependency at runtime.
Supplementary content
protocol AppIntentsPackage
A type that describes app intent definitions that arenʼt part of an app bundle and their dependencies.
struct IntentDescription
The human-readable description and metadata for an app intent.
struct IntentDialog
The text you want the system to display, or speak, when requesting a value, asking for
disambiguation, or confirming an action.
struct IntentDeprecation
class IntentProjection
Projections for an app intent that returns non-optional values for parameters.
struct IntentSystemContext
Information that the system makes available to an app intent while it performs its action.
Results
protocol IntentResult
A type that contains the result of performing an action, and includes optional information to deliver
back to the initiator.
struct IntentResultContainer
An object that represents the output of a completed intent.
protocol OpensIntent
The result of performing an action that delivers an app intent back to the initiator of the action.
protocol ProvidesDialog
The result of performing an action that delivers a dialog back to the initiator of the action.
protocol ReturnsValue
The result of performing an action that delivers a value back to the initiator.
protocol ShowsSnippetView
The result of performing an action that delivers a view back to the initiator of the action.
protocol ResultsCollection
A protocol representing a collection of returned items with support for sectioning.
Extensions
protocol AppIntentsExtension
An interface for managing an extensionʼs configuration.
See Also
Actions
Intent discovery
Donate your appʼs intents to the system to help it identify trends and predict future behaviors.
App Shortcuts
Integrate your appʼs intents and entities with the Shortcuts app, Siri, Spotlight, and the Action button
on supported iPhone and Apple Watch models.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Supporting associated domains | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation
Xcode / Projects and workspaces / Allowing apps and websites to link to your con… / Supporting associated domains
Supporting associated domains
Connect your app and a website to provide both a native app and a browser experience.
Overview
Associated domains establish a secure association between domains and your app so you can share credentials or
provide features in your app from your website. For example, an online retailer may offer an app to accompany their
website and enhance the user experience.
Shared web credentials, universal links, Handoff, and App Clips all use associated domains. Associated domains provide
the underpinning to universal links, a feature that allows an app to present content in place of all or part of its website.
Users who donʼt download the app get the same information in a web browser instead of the native app.
To associate a website with your app, you need to have the associated domain file on your website and the appropriate
entitlement in your app. The apps in the apple-app-site-association file on your website must have a matching
Associated Domains Entitlement.
Add the associated domain file to your website
When a user installs your app, the system attempts to download the associated domain file and verify the domains in
your entitlement.
Note
If your site uses multiple subdomains (such as example.com, www.example.com, and support.example
.com), each requires its own entry in the Associated Domains Entitlement, and each must serve its own
apple-app-site-association file.
To add the associated domain file to your website, create a file named apple-app-site-association (without an
extension). Update the JSON code in the file for the services you support on the domain. For universal links, be sure to
list the app identifiers for your domain in the applinks service. Similarly, if you create an App Clip, be sure to list your
App Clipʼs app identifier using the appclips service.
The following JSON code represents the contents of a simple association file:
{
"applinks": {
"details": [
{
"appIDs": [ "ABCDE12345.com.example.app", "ABCDE12345.com.example.app2" ],
"components": [
{
"#": "no_universal_links",
"exclude": true,
"comment": "Matches any URL with a fragment that equals no_universal_links and instructs the system not to open it as a universal link."
},
{
"/": "/buy/*",
"comment": "Matches any URL with a path that starts with /buy/."
},
{
"/": "/help/website/*",
"exclude": true,
"comment": "Matches any URL with a path that starts with /help/website/ and instructs the system not to open it as a universal link."
},
{
"/": "/help/*",
"?": { "articleNumber": "????" },
"comment": "Matches any URL with a path that starts with /help/ and that has a query item with name 'articleNumber' and a value of exactly four characters."
}
]
}
]
},
"webcredentials": {
"apps": [ "ABCDE12345.com.example.app" ]
},
"appclips": {
"apps": ["ABCDE12345.com.example.MyApp.Clip"]
}
}
The appIDs and apps keys specify the application identifiers for the apps that are available for use on this website
along with their service types. Use the following format for the values in these keys:
<Application Identifier Prefix>.<Bundle Identifier>
The details dictionary only applies to the applinks service type; other service types donʼt use it. The components
key is an array of dictionaries that provides pattern matching for components of the URL.
After you construct the association file, place it in your siteʼs .well-known directory. The fileʼs URL should match the
following format:
https://<fully qualified domain>/.well-known/apple-app-site-association
You must host the file using https:// with a valid certificate and with no redirects.
Add the associated domains entitlement to your app
To set up the entitlement in your app, open the targetʼs Signing & Capabilities tab in Xcode and add the Associated
Domains capability. If theyʼre not already present, this step adds the Associated Domains Entitlement to your
app and the associated domains feature to your app ID.
Important
For a single-target watchOS apps, add the Associated Domains capability to the watchOS app target. For watchOS
apps with separate WatchKit extensions, you must add the Associated Domains capability to the WatchKit
Extension target.
To add your domain to the entitlement, click Add (+) at the bottom of the Domains table to add a placeholder domain.
Replace the placeholder with the appropriate prefix for the service your app supports and your siteʼs domain. Make sure
to only include the desired subdomain and the top-level domain. Donʼt include path and query components or a trailing
slash (/).
Add the domains that share credentials with your app. For services other than appclips, you can prefix a domain with
*. to match all of its subdomains.
Each domain you specify uses the following format:
<service>:<fully qualified domain>
Starting with macOS 11 and iOS 14, apps no longer send requests for apple-app-site-association files directly to
your web server. Instead, they send these requests to an Apple-managed content delivery network (CDN) dedicated to
associated domains.
While youʼre developing your app, if your web server is unreachable from the public internet, you can use the alternate
mode feature to bypass the CDN and connect directly to your private domain.
You enable an alternate mode by adding a query string to your associated domainʼs entitlement as follows:
<service>:<fully qualified domain>?mode=<alternate mode>
For more information about alternate modes, see Associated Domains Entitlement. For information about
universal links, see Allowing apps and websites to link to your content. For information about Handoff, see Implementing
Handoff in Your App. For information about App Clips, see Configuring App Clip experiences.
Important
Appleʼs content delivery network requests the apple-app-site-association file for your domain within 24
hours. Devices check for updates approximately once per week after app installation.
Topics
Entitlements
Associated Domains Entitlement
The associated domains for specific services, such as shared web credentials, universal links, and App Clips.
Services
object applinks
The root object for a universal links service definition.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: App intent domains | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Essentials
App Intents updates
Making actions and content discoverable …
Creating your first app intent
Adopting App Intents to support system e…
Accelerating app interactions with App Int…
Siri and Apple Intelligence
Integrating actions with Siri and Apple Int…
Making onscreen content available to Siri …
App intent domains
Macros
#
macro AppIntent<T>(schema: T)
#
macro AppEntity<T>(schema: T)
#
macro AppEnum<T>(schema: T)
Books
Making ebook actions available to Siri a…
AssistantSchemas.BooksIntentr P
AssistantSchemas.BooksEntityr P
AssistantSchemas.BooksEnumr P
App Intents / App intent domains
API Collection
App intent domains
Make your appʼs actions and content available to Siri and Apple Intelligence with
assistant schemas.
Overview
To enable enhanced understanding and more conversational interactions with Siri for your app, choose a
domain and a schema that match your appʼs functionality. By conforming your app intent, app entity, or
your app enumeration to a schema, you ensure that Apple Intelligence understands your appʼs actions and
content. When youʼve identified the schema to use, leverage the AppIntent(schema:), App
Entity(schema:), and AppEnum(schema:) macros to write schema-conforming code.
Note
Siriʼs personal context understanding, onscreen awareness, and in-app actions are in development and
will be available with a future software update.
To learn more, refer to Integrating actions with Siri and Apple Intelligence and Making onscreen content
available to Siri and Apple Intelligence.
Filter
/
Topics
Macros
macro AppIntent<T>(schema: T)
A Swift macro you use to make sure your app intent conforms to an schema.
macro AppEntity<T>(schema: T)
macro AppEnum<T>(schema: T)
A Swift macro you use to make sure your app enum conforms to a schema.
Books
Making ebook actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs ebook and audiobook functionality with Siri and
Apple Intelligence.
protocol BooksIntent
Assistant schema conformance for app intents that offer ebook and audiobook functionality.
protocol BooksEntity
Assistant schema conformance for app entities that describe ebooks or audiobooks.
protocol BooksEnum
Assistant schema conformance for types you use to describe ebooks or audiobooks.
Browser
Making browser actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs web browsing functionality with Siri and Apple
Intelligence.
protocol BrowserIntent
Assistant schema conformance for app intents that offer web browsing functionality.
protocol BrowserEntity
Assistant schema conformance for app entities that describe data for web browsing functionality.
protocol BrowserEnum
Assistant schema conformance for types you use for web browsing functionality.
Camera
Making camera actions available to Siri and Apple Intelligence
Create app intents and enumerations to integrate your appʼs camera functionality with Siri and Apple
Intelligence.
protocol CameraIntent
Assistant schema conformance for app intents that offer camera functionality.
protocol CameraEnum
Assistant schema conformance for types you use for camera functionality.
Document reader
Making document reader actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs document viewing and editing functionality with
Siri and Apple Intelligence.
protocol ReaderIntent
Assistant schema conformance for app intents that offer document viewing and editing functionality.
protocol ReaderEntity
Assistant schema conformance for app entities that describe documents.
protocol ReaderEnum
Assistant schema conformance for types you use to describe documents.
File management
Making file management actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs file management functionality with Siri and
Apple Intelligence.
protocol FilesIntent
Assistant schema conformance for app intents that offer file management functionality.
protocol FilesEntity
Assistant schema conformance for app entities that describe files.
iPhone side button access (only in Japan)
Launching your voice-based conversational app from the side button of iPhone
Let people in Japan configure the side button of iPhone to launch your voice-based conversational
app.
protocol AssistantIntent
Assistant schema conformance for app intents that offer support for the side button on iPhone in
Japan.
Journaling
Making journaling actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs journaling functionality with Siri and Apple
Intelligence.
protocol JournalIntent
Assistant schema conformance for app intents that offer journaling functionality.
protocol JournalEntity
Assistant schema conformance for app entities that describe journaling data.
Email
Making email actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs email functionality with Siri and Apple
Intelligence.
protocol MailIntent
Assistant schema conformance for app intents that offer email functionality.
protocol MailEntity
Assistant schema conformance for app entities that describe email.
Photos and videos
Making photo and video actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs photo and video functionality with Siri and
Apple Intelligence.
protocol PhotosIntent
Assistant schema conformance for app intents that offer photo and video functionality.
protocol PhotosEntity
Assistant schema conformance for app entities that describe media assets.
protocol PhotosEnum
Assistant schema conformance for types you use to describe photos and videos.
Presentations
Making presentation actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs presentation functionality with Siri and Apple
Intelligence.
protocol PresentationIntent
Assistant schema conformance for app intents that offer presentation functionality.
protocol PresentationEntity
Assistant schema conformance for app entities that describe presentation data.
Spreadsheets
Making spreadsheet actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs spreadsheet functionality with Siri and Apple
Intelligence.
protocol SpreadsheetIntent
Assistant schema conformance for app intents that offer spreadsheet functionality.
protocol SpreadsheetEntity
Assistant schema conformance for app entities that describe spreadsheet data.
System and in-app search
Making in-app search actions available to Siri and Apple Intelligence
Create app intents and entities to integrate your appʼs search functionality with Siri and Apple
Intelligence.
protocol SystemIntent
Assistant schema conformance for app intents that match system-provided intents.
Whiteboard
Making whiteboard actions available to Siri and Apple Intelligence
Create app intents and entities that make your appʼs whiteboard functionality available to Siri and
Apple Intelligence.
protocol WhiteboardIntent
Assistant schema conformance for app intents that offer whiteboard functionality.
protocol WhiteboardEntity
Assistant schema conformance for app entities that describe data for whiteboard functionality.
protocol WhiteboardEnum
Assistant schema conformance for whiteboard types.
Word processor and text editing
Making word processor actions available to Siri and Apple Intelligence
Create app intents and entities that make your appʼs word processor functionality available to Siri and
Apple Intelligence.
protocol WordProcessorIntent
Assistant schema conformance for app intents that offer word processing functionality.
protocol WordProcessorEntity
Assistant schema conformance for app entities that describe text documents.
Base protocols
Assistant schema base protocols
Protocols that provide the underlying functionality for assistant schemas.
Deprecated symbols
macro AssistantIntent<T>(schema: T)
A Swift macro you use to make sure your app intent conforms to an assistant schema.
Deprecated
macro AssistantEntity<T>(schema: T)
A Swift macro you use to make sure your app entity conforms to an assistant schema.
Deprecated
macro AssistantEnum<T>(schema: T)
A Swift macro you use to make sure your app enum conforms to an assistant schema.
Deprecated
See Also
Siri and Apple Intelligence
Integrating actions with Siri and Apple Intelligence
Create app intents, entities, and enumerations that conform to assistant schemas to tap into the
enhanced action capabilities of Siri and Apple Intelligence.
Making onscreen content available to Siri and Apple Intelligence
Enable Siri and Apple Intelligence to respond to a personʼs questions and action requests for your
appʼs onscreen content.
Making your appʼs functionality available to Siri
Add app intent schemas to your app so Siri can complete requests, and integrate your app with Apple
Intelligence, Spotlight, and other system experiences.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Making your app content shareable | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
Shared with You / Making your app content shareable
Article
Making your app content shareable
Add support for universal links and a Shared with You shelf to support shared content in your app.
Overview
System apps like Safari, News, Music, Photos, and Podcasts use Shared with You to make it easier to share content with
friends and family. By adopting universal links and adding a Shared with You shelf to your app, you can also share your
content using Messages. When you add views to showcase shared content activity, your app allows people to view
Messages conversations that contain your shared content and still stay focused on your app.
Your app can also manage who can view or share your content using the SWAttributionView. This adds a new level
of collaboration to your app. You can customize your contentʼs contextual menu to add even more functionality to
shared content.
Adopt universal links
Your app uses universal links to share content with other apps. When a user activates a universal link, the system
launches your app and sends it an NSUserActivity object. Query this object to take actions for your shared content.
To support universal links in your app:
I. Create a two-way association between your app and your website and specify the URLs that your app handles. See
Supporting associated domains.
O. Update your app delegate to respond when it receives an NSUserActivity object with the activityType set to
NSUserActivityTypeBrowsingWeb.
For more information, see Supporting universal links in your app.
Add Shared with You capability
To add the Shared with You capability in Xcode, follow these steps:
I. Select your project target.
O. Select the Signing & Capabilities pane.
S. Click + Capability to bring up the Capabilities library.
U. Choose the Shared with You capability.
For more information, see Adding capabilities to your app.
Add Shared with You shelf
Instead of relying on Messages to display shared content activity, you can add a Shared with You shelf to your app. This
is a custom view your app creates and manages to display SWHighlightCenter activity. People can see new content
shares and interact with existing ones from your app.
// Enumerate Shared with You shelf.
class SharedWithYouViewController: UIViewController, SWHighlightCenterDelegate {
let highlightCenter = SWHighlightCenter()
override func viewDidLoad() {
super.viewDidLoad()
highlightCenter.delegate = self
}
func highlightCenterHighlightsDidChange(
_ highlightCenter: SWHighlightCenter) {
for highlight in highlightCenter.highlights {
let highlightURL = highlight.url
// Generate a rich preview for this highlight.
}
}
Add an SWAttributionView to your content
The SWAttributionView is the user interface your app customizes to give people a way to interact with
SWHighlight events, like the addition of a new participant or a title change to the shared content. You can adjust the
alignment of the content, the width, and the SWAttributionView.DisplayContext format.
// Set the horizontal alignment for an attribution view.
let attributionView = SWAttributionView()
attributionView.highlight = self.highlightCenter.highlights[index]
attributionView.preferredMaxLayoutWidth = maximumWidthForView
attributionView.horizontalAlignment = .leading
You can show the displayContext as an SWAttributionView.DisplayContext.summary or an
SWAttributionView.DisplayContext.detail view. The detail view is ideal if you have more vertical space in
your app to provide a larger image of the shared content and more related information.
// Set the display context for an attribution view.
let attributionView = SWAttributionView()
attributionView.highlight = self.highlightCenter.highlights[index]
attributionView.preferredMaxLayoutWidth = maximumWidthForView
attributionView.horizontalAlignment = .center
attributionView.displayContext = .summary
You can also customize the highlight menu text and add additional menu items.
// Add Shared with You content menu to your app’s content.
let attributionView = SWAttributionView()
attributionView.highlight = self.highlightCenter.highlights[index]
attributionView.menuTitleForHideAction = "Remove Item"
let contextMenuConfig = UIContextMenuConfiguration(identifier: nil,previewProvider: nil) { [weak self]
let additionalMenu = attributionView.supplementalMenu
// Append additional menu items to your content menu.
}
}
See Also
Shared content
Shared content interactions
Use highlights and attribution views to manage participants and trigger events for shared content.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Making onscreen content available to Siri and Apple Intelligence | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Essentials
App Intents updates
Making actions and content discoverable …
Creating your first app intent
Adopting App Intents to support system e…
Accelerating app interactions with App Int…
Siri and Apple Intelligence
Integrating actions with Siri and Apple Int…
Making onscreen content available to Si…
System protocols
AppEntityAnnotatabler P
App intent domains
Making your appʼs functionality available t…
Visual intelligence
Integrating your app with visual intelligence
Visual Intelligence
IntentValueQueryr P
Interactive Snippets
Displaying static and interactive snippets
Filter
App Intents / Making onscreen content available to Siri and Apple Intelligence
API Collection
Making onscreen content available to Siri and
Apple Intelligence
Enable Siri and Apple Intelligence to respond to a personʼs questions and action requests
for your appʼs onscreen content.
iOS 18.2+ iPadOS 18.2+ Mac Catalyst 18.2+ macOS 15.2+ tvOS 18.2+ visionOS 2.2+ watchOS 11.2+
Xcode 16.2+
/
Overview
When a person asks a question about onscreen content or wants to perform an action on it, Siri and Apple
Intelligence will be able to retrieve the content to respond to the question and perform the action. If the
user explicitly requests it, Siri and Apple Intelligence will be able to send content to supported third-party
services. For example, someone could view a website and use Siri to provide a summary by saying or
typing a phrase like “Hey Siri, whatʼs this document about?”
Note
Siriʼs personal context understanding, onscreen awareness, and in-app actions are in development and
will be available with a future software update.
Create an app entity and associate it with the user activity
object
To integrate your appʼs onscreen content with current and upcoming personal intelligence features of Siri
and Apple Intelligence, explicitly provide the onscreen content using the App Intents framework. Describe
the content with an AppEntity — you might be able to reuse existing app entity code. Then, tell the
system about the content when it becomes visible:
K. Create an app entity identifier using EntityIdentifier .
M. Associate the identifier with the current NSUserActivity by setting the activityʼs appEntity
Identifier property.
To remove the association between the user activity and your app entity, set the user activityʼs appEntity
Identifier property to nil.
The following code snippet from the Making your appʼs functionality available to Siri sample code project
shows how a photo-viewing app might provide a photo to Siri and Apple Intelligence by creating an app
entity identifier for the asset app entity that represents a photo, and associating it with the user activity:
MediaView(
image: image,
duration: asset.duration,
isFavorite: asset.isFavorite,
proxy: proxy
)
.userActivity(
"com.example.apple-samplecode.AssistantSchemasExample.ViewingPhoto",
element: asset.entity
) { asset, activity in
activity.title = "Viewing a photo"
activity.appEntityIdentifier = EntityIdentifier(for: asset)
}
Make the app entity transferable
Associating an AppEntity with the NSUserActivity provides Siri and Apple Intelligence with your
appʼs onscreen content to offer personalized intelligence assistance. To go one step further and enable Siri
and Apple Intelligence to further process the provided onscreen content and respond to a personʼs explicit
request to send the content as an attachment to other services, including third parties:
K. Update your app entity to conform to the Transferable protocol.
M. In your Transferable implementation, provide image, PDF, rich text, or plain text representations. To
increase compatibility with third-party services, provide several representations that best fit your
content. For example, an email client might represent an email as rich text, plain text, and a PDF. For
more on adopting Transferable, refer to CoreTransferable.
Provide additional context to the system with an assistant
schema
To enable Siri and Apple Intelligence to further process the provided onscreen content and provide a better
response in iOS 18, make sure that the app entity that you associate with an NSUserActivity conforms
to one of the assistant schemas in the list below.
Note
The listed requests below are examples and not exhaustive. Actual functionality depends on factors
such as the features provided by Siri and Apple Intelligence, the functionality offered by third-party
services, or the phrase a person uses.
Domain Schema Swift macro Example request
Browser tab @AppEntity(schema:
.browser.tab)
A person might ask Siri questions about
the web page.
reader Document
document @AppEntity(schema:
.reader.document)
A person might ask Siri to explain the
conclusion of a document.
File
management
file @AppEntity(schema:
.files.file)
A person might ask Siri to summarize
file content.
Mail message
@AppEntity(schema:
.mail.message)
A person might ask Siri to provide a
summary.
Photos asset @AppEntity(schema:
.photos.asset)
A person might ask Siri about things to
do with an object in a photo.
Presentations document @AppEntity(schema:
.presentation.document)
A person might ask Siri to suggest a
creative title for a presentation.
Spreadsheets document @AppEntity(schema:
.spreadsheet.document)
A person might ask Siri to give an
overview of the spreadsheetʼs data.
Word
processor
document
@AppEntity(schema:
.wordProcessor
.document)
A person might ask Siri to suggest
additional content for a text document.
Topics
System protocols
protocol AppEntityAnnotatable
A protocol that framework types adopt to enable you to provide content to system experiences.
See Also
Siri and Apple Intelligence
Integrating actions with Siri and Apple Intelligence
Create app intents, entities, and enumerations that conform to assistant schemas to tap into the
enhanced action capabilities of Siri and Apple Intelligence.
App intent domains
Make your appʼs actions and content available to Siri and Apple Intelligence with assistant schemas.
Making your appʼs functionality available to Siri
Add app intent schemas to your app so Siri can complete requests, and integrate your app with Apple
Intelligence, Spotlight, and other system experiences.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Integrating custom data types into your intents | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
App Intents
Integrating custom data types into your…
Parameter resolution
App entities
Entity queries
Resolvers
Utility types
Common types
Errors
S
AppIntentError
Protocols
AppIntentSceneDelegater P
AppShortcutsContentr P
r P
CustomURLRepresentationParameterCon…
ShowsSnippetIntentr P
TargetContentProvidingIntentr P
UISceneAppIntentr P
UndoableIntentr P
Structures
S
ConfirmationConditions
App Intents / Integrating custom data types into your intents
Article
Integrating custom data types into your
intents
Provide the system with information about the types your app uses to model its data so
that your intents can use those types as parameters.
Filter
/
Overview
Your app likely defines a number of custom types that model the data the app creates or consumes. For
example, an app that enables people to view information about hiking trails might define types that
describe trail information. Because those types are unique to your app, the framework canʼt interpret them
until you expose them to system experiences like the Shortcuts app. Entities are lightweight types that
provide information to the system about your appʼs data or concepts relating to that data. An entity
identifies and queries the data it represents and describes how the system displays that data onscreen.
Create an entity for each of the core types or concepts you want to use as an input parameter for your
intents.
For more information on creating app intents and specifying their input parameters, see Creating your first
app intent and Adding parameters to an app intent.
Define an entity that represents your data
To let an intent use one of your appʼs custom data types as a parameter, define a new structure in your
appʼs target to represent that type. Then update the structureʼs definition to adopt the AppEntity
protocol. Although custom types can directly conform to the protocol, prefer using distinct entity types
that are lightweight and provide only the information the system requires. Distinct types let you separate
your entities from the rest of your appʼs model and domain code. For example, the Accelerating app
interactions with App Intents sample code project uses a Trail type and defines a corresponding Trail
Entity type.
struct TrailEntity: AppEntity {
// ...
}
If your appʼs model code is lightweight and the amount of data is small enough to fit into device memory,
you can make your models conform to AppEntity to keep your code simple. However, models can
contain larger data like images or your app could operate on large amounts of data. For those cases, use
separate types for your entities so you can load only the data the entities need, and make the mechanism
that provides the entitiesʼ data more performant. For example, if your app uses CloudKit to manage its
data, set the desiredKeys property on your fetch operations to return only the data the entities need
instead of fetching entire records.
Specify a unique identifier for your entity
Every entity must have a stable, unique identifier. The framework uses that identifier as a concrete
reference to your entity while mediating between your app and other parts of the system. For example,
when someone selects the value for an entity-based parameter in the shortcut editor, the system asks your
app to resolve that parameter using the entityʼs identifier. The AppEntity protocol inherits the
Identifiable protocol to enforce this prerequisite.
To add a unique identifier to your entity type, implement the protocolʼs id requirement and set its type to
one of the three data types optimized for the framework: String, Int, or UUID.
var id: UUID
Note
Wherever possible, use one of the three optimized data types for entity identifiers. If you must use a
different data type, extend that type and implement the required support. For more information, see
EntityIdentifierConvertible.
Provide a visual representation for your entity
An entity represents a type and the data for that type. In your entity, describe how to display both elements
onscreen. For example, the Shortcuts app uses this information to show type details in the Actions Library
and to present entity data in the shortcut editor.
Add the typeDisplayRepresentation variable to your entityʼs structure and return a human-readable,
localized string that describes the entity. For example, the hiking app from the previous example displays
the number of trails. The system displays this string whenever it needs to present your entityʼs type
onscreen.
static var typeDisplayRepresentation: TypeDisplayRepresentation {
TypeDisplayRepresentation(
name: LocalizedStringResource("Trail", table: "AppIntents"),
numericFormat: LocalizedStringResource("\(placeholder: .int) trails", table: "AppIntents"
)
}
The required displayRepresentation variable describes how to display an entityʼs represented data at
runtime. Update your structure to include this variable and return an instance of Display
Representation. Specify a localized title that lets people recognize the data.
Create a visually rich display of your entity by setting the representationʼs subtitle and image variables.
For example, the Accelerating app interactions with App Intents sample code project displays the name of
the trail, a region description, and an image.
var displayRepresentation: DisplayRepresentation {
DisplayRepresentation(title: "\(name)"
,
subtitle: "\(regionDescription)"
,
image: DisplayRepresentation.Image(named: imageName))
}
For more information, see DisplayRepresentation.
Make your entity searchable
The framework requires entity types to be searchable so the system can resolve identifiers at runtime and
request a list of suggested entities to display onscreen. For example, when a person sets a parameter to a
specific entity in the shortcut editor, the system retains that entityʼs identifier. Later, when the intent runs,
the framework asks your type to materialize the entity from its identifier. The framework then updates the
relevant parameter with the materialized entity before invoking the intentʼs perform() function.
To make your entity searchable, define a new structure that adopts the EntityQuery protocol. Place this
structure in the appʼs target alongside your entity. Add the entities(for:) function, and update the
declaration so the element type of the identifiers array matches your entityʼs id variable. Use the
provided identifiers to materialize and return the relevant entities.
struct TrailEntityQuery: EntityQuery {
@Dependency
var trailManager: TrailDataManager
func entities(for identifiers: [TrailEntity.ID]) async throws -> [TrailEntity] {
Logger.entityQueryLogging.debug("[TrailEntityQuery] Query for IDs \(identifiers)")
return trailManager.trails(with: identifiers)
.map { TrailEntity(trail: $0) }
}
}
To offer a better user experience, provide a list of suggested entities that the system displays, at
appropriate times, to let people quickly make a selection. To provide those entities, add the suggested
Entities() method to your query structure. If your data generates a small number of entities, return
them all; otherwise, return a subset of those entities relevant to the current context. For example, the
Accelerating app interactions with App Intents sample code project suggests a personʼs favorite hiking
trails.
func suggestedEntities() async throws -> [TrailEntity] {
Logger.entityQueryLogging.debug("[TrailEntityQuery] Request for suggested entities")
return trailManager.trails(with: trailManager.favoritesCollection.members)
.map { TrailEntity(trail: $0) }
}
To let people use arbitrary text to find specific entities, adopt the EntityStringQuery protocol instead.
Queries that adopt this protocol cause the system to display a search field above the list of suggested
entities. Implement the required entities(matching:) function, and use the provided string to match
against your data. For example, the Accelerating app interactions with App Intents sample code project
allows people to search for a specific trail. The following code snippet from the sample code project
matches a personʼs search input to the appʼs trail information using the name property:
func entities(matching string: String) async throws -> [TrailEntity] {
return trailManager.trails { trail in
trail.name.localizedCaseInsensitiveContains(string)
}.map { TrailEntity(trail: $0) }
}
After you implement your query, update the related entityʼs definition to include the defaultQuery
variable, and specify an instance of your query type as the value. The system uses this variable at runtime
to determine which type it can query on behalf of the related entity.
static var defaultQuery = TrailEntityQuery()
There are several subprotocols to EntityQuery, each of which enables different types of functionality.
The Accelerating app interactions with App Intents sample code project implements all of them for
demonstration purposes, but for a real app, you can choose the ones that meet your needs.
Enable Find intents
Apps implementing either the EnumerableEntityQuery or EntityPropertyQuery protocols
automatically add a Find intent in the Shortcuts app. These intents enable people to build powerful new
features for themselves in Shortcuts, powered by the appʼs data — without requiring the app to implement
that feature itself. For example, the Accelerating app interactions with App Intents sample code project
focuses its UI on providing trail information, but people could also use its data to plan activities for a
vacation. The app doesnʼt need to build vacation-planning features because it implements these entity
query protocols to provide an interface to the data through an App Shortcut.
For more information about enabling Find intents, see Enable Find intents.
Enumerate your data typeʼs static values
If a type has known fixed values at build time, such as a Swift enumeration, expose those types to the
system by converting them to app enums, the static equivalent of entities. Because app enum values are
constant, the compiler introspects them at build time and optimizes their use. The framework provides
both an identity and a query by default, and the system can get type information at runtime without
launching the app. For example, a music app might use an app enum to associate an album with an album
type such as studio, live, or compilation.
To convert a common type to an app enum, update its declaration to adopt the AppEnum protocol. Thereʼs
no need to create a separate type because the existing type is inherently lightweight and doesnʼt store
additional data. The framework requires that app enums also conform to RawRepresentable and use
String as their storage type, so modify your type to satisfy those requirements. Like with entities, specify
a localized description of the type that the system can display onscreen.
enum ActivityStyle: String, Codable, Sendable {
case biking
case equestrian
case hiking
case jogging
case crossCountrySkiing
case snowshoeing
// ...
}
extension ActivityStyle: AppEnum {
static var typeDisplayRepresentation: TypeDisplayRepresentation {
TypeDisplayRepresentation(
name: LocalizedStringResource("Activity", table: "AppIntents"),
numericFormat: LocalizedStringResource("\(placeholder: .int) activities", table:
)
}
Important
Donʼt adopt both protocols in the same type; use AppEntity for types that provide dynamic values
and AppEnum for types that provide a limited set of static values.
To provide descriptions for each of your app enumʼs values, add the protocolʼs required caseDisplay
Representations variable. Return a dictionary that maps the values to their display representations.
static var caseDisplayRepresentations: [ActivityStyle: DisplayRepresentation] = [
.biking: DisplayRepresentation(title: "Biking",
subtitle: "Mountain bike ride",
image: imageRepresentation[.biking]),
.equestrian: DisplayRepresentation(title: "Equestrian",
subtitle: "Equestrian sports",
image: imageRepresentation[.equestrian]),
.hiking: DisplayRepresentation(title: "Hiking",
subtitle: "A lengthy outdoor walk",
image: imageRepresentation[.hiking]),
.jogging: DisplayRepresentation(title: "Jogging",
subtitle: "A gentle run",
image: imageRepresentation[.jogging]),
.crossCountrySkiing: DisplayRepresentation(title: "Skiing",
subtitle: "Cross-country skiing",
image: imageRepresentation[.crossCountrySkiing]),
.snowshoeing: DisplayRepresentation(title: "Snowshoeing",
subtitle: "Walking in the snow",
image: imageRepresentation[.snowshoeing])
The example above initializes each representation with a string literal. To help people quickly understand
the values, it also specifies a subtitle and an image.
For more information, see DisplayRepresentation.
]
See Also
Parameters, custom data types, and queries
Adding parameters to an app intent
Enable people to configure app intents with their custom input values.
Parameter resolution
Define the required parameters for your app intents and specify how to resolve those parameters at
runtime.
App entities
Make core types or concepts discoverable to the system by declaring them as app entities.
Entity queries
Help the system find the entities your app defines and use them to resolve parameters.
Resolvers
Resolve the parameters of your app intents, and extend the standard resolution types to include your
appʼs custom types.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

========================================
FILE: Transferable | Apple Developer Documentation.pdf
========================================
News Discover Design Develop Distribute Support Account
Documentation Language: Swift
All Technologies
Core Transferable Essentials
Transferabler P
Implementing a transfer representation
P
static var transferRepresentation: Self.R…
Representation
Initializers
M
init(importing: URL, contentType: UTTy…
M
init(importing: Data, contentType: UTTy…
Instance Properties
P
var suggestedFilename: String?
Instance Methods
M
func export(to: URL, contentType: UTTy…
M
func exported(as: UTType?) async thro…
M
func exportedContentTypes(TransferRe…
M
func importedContentTypes() -> [UTTy…
M
func withExportedFile<Result>(content…
Type Methods
M
static func exportedContentTypes(visibi…
M
static func importedContentTypes() -> …
TransferRepresentationr P
Choosing a transfer representation for a …
Filter
Data transfer
/
Core Transferable / Transferable
Protocol
Transferable
A protocol that describes how a type interacts with transport APIs such as drag and drop
or copy and paste.
iOS 16.0+ iPadOS 16.0+ Mac Catalyst 16.0+ macOS 13.0+ tvOS 16.0+ visionOS 1.0+ watchOS 9.0+
@preconcurrency
protocol Transferable : Sendable
S
CodableRepresentation
S
DataRepresentation
File transfer
S
FileRepresentation
Overview
To conform to the Transferable protocol, implement the transferRepresentation property. For
example, an image editing appʼs layer type might conform to Transferable to let people drag and drop
image layers to reorder them within a document.
struct ImageDocumentLayer {
init(data: Data) { }
func data() -> Data { Data() }
func pngData() -> Data { Data() }
}
The following shows how you can extend ImageDocumentLayer to conform to Transferable:
extension ImageDocumentLayer: Transferable {
static var transferRepresentation: some TransferRepresentation {
DataRepresentation(contentType: .layer) { layer in
layer.data()
} importing: { data in
ImageDocumentLayer(data: data)
}
DataRepresentation(exportedContentType: .png) { layer in
layer.pngData()
}
}
}
When people drag and drop a layer within the app or onto another app that recognizes the custom layer
content type, the app uses the first representation. When people drag and drop the layer onto a different
image editor, itʼs likely that the editor recognizes the PNG file type. The second transfer representation
adds support for PNG files.
The following declares the custom layer uniform type identifier:
extension UTType {
static let layer = UTType(exportedAs: "com.example.layer")
}
Important
If your app declares custom uniform type identifiers, include corresponding entries in the appʼs Info
.plist. For more information, see Defining file and data types for your app.
If one of your existing types conforms to Codable, Transferable automatically handles conversion to
and from Data. The following declares a simple Note structure thatʼs Codable and an extension to make
it Transferable:
struct Note: Codable {
let title: String
let body: String
}
extension Note: Transferable {
static var transferRepresentation: some TransferRepresentation {
CodableRepresentation(contentType: .note)
}
}
To ensure compatibility with other apps that donʼt know about the custom note type identifier, the
following adds an additional transfer representation that converts the note to text.
extension Note: Transferable {
static var transferRepresentation: some TransferRepresentation {
CodableRepresentation(contentType: .note)
ProxyRepresentation(\.title)
}
}
The order of the representations in the transfer representation matters; place the representation that most
accurately represents your type first, followed by a sequence of more compatible but less preferable
representations.
Topics
Implementing a transfer representation
static var transferRepresentation: Self.Representation
The representation used to import and export the item.
Required
associatedtype Representation : TransferRepresentation
The type of the representation used to import and export the item.
Required
Initializers
init(importing: URL, contentType: UTType?) async throws
Using the typeʼs Transferable conformance implementation, instantiates a value from the given
file.
init(importing: Data, contentType: UTType?) async throws
Using the typeʼs Transferable conformance implementation, instantiates a value from given data.
Instance Properties
var suggestedFilename: String?
A suggested filename of a Transferable value.
Instance Methods
func export(to: URL, contentType: UTType?) async throws -> URL
Using the typeʼs Transferable conformance implementation, exports a value by writing it to a
provided destination directory.
func exported(as: UTType?) async throws -> Data
Using the typeʼs Transferable conformance implementation, exports a value as binary data.
func exportedContentTypes(TransferRepresentationVisibility) -> [UTType]
Content types supported by a given valueʼs Transferable conformance for export (like drag or
copy).
func importedContentTypes() -> [UTType]
Content types supported by a given valueʼs Transferable conformance for import (like drop or
paste).
func withExportedFile<Result>(contentType: UTType?, fileHandler: (URL) async
throws -> Result) async throws -> Result
Using the typeʼs Transferable conformance implementation, exports a value by writing it to disk
and removes when not needed.
Type Methods
static func exportedContentTypes(visibility: TransferRepresentationVisibility)
-> [UTType]
The types that the instance of a Transferable is able to provide a representation for.
static func importedContentTypes() -> [UTType]
Content types statically supported by the Transferable conformance of the type for import (like
drop or paste).
Relationships
Inherits From
Sendable, SendableMetatype
See Also
Essentials
protocol TransferRepresentation
A declarative description of the process of importing and exporting a transferable item.
Choosing a transfer representation for a model type
Define a custom representation for your data using a combination of built-in types.
Developer Documentation
Platforms
iOS
iPadOS
macOS
tvOS
visionOS
watchOS
Tools
Swift
SwiftUI
Swift Playground
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning & AI
Open Source
Security
Safari & Web
To submit feedback on documentation, visit Feedback Assistant.
Resources
Documentation
Tutorials
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Meet with Apple
Apple Developer Centers
App Store Awards
Apple Design Awards
Apple Developer Academies
WWDC
Light Dark Auto
Copyright © 2025 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

